#!/usr/bin/env python3
# @CODE:HOOK-RESEARCH-003 | @SPEC:HOOK-RESEARCH-ANALYSIS-001 | @TEST: tests/hooks/test_research_analysis.py
"""ì‘ì—… í›„ ì—°êµ¬ ë¶„ì„ Hook

PostToolUse ë‹¨ê³„ì—ì„œ ì‘ì—… ê²°ê³¼ë¥¼ ë¶„ì„í•˜ê³  ì—°êµ¬ ì¸ì‚¬ì´íŠ¸ë¥¼ ì¶”ì¶œ.
ì§€ì‹ ë² ì´ìŠ¤ ì—…ë°ì´íŠ¸ì™€ ì—°êµ¬ ë°ì´í„° ë™ê¸°í™”.

ê¸°ëŠ¥:
- ì‘ì—… ê²°ê³¼ ì—°êµ¬ ë¶„ì„
- ì—°êµ¬ ì¸ì‚¬ì´íŠ¸ ì¶”ì¶œ
- ì§€ì‹ ë² ì´ìŠ¤ ìë™ ì—…ë°ì´íŠ¸
- ì—°êµ¬ ë°ì´í„° ë™ê¸°í™”
- ì„±ëŠ¥ ë° í’ˆì§ˆ ë¶„ì„

ì‚¬ìš©ë²•:
    python3 post_tool__research_analysis.py <tool_name> <tool_result_json> <execution_time_ms>
"""

import json
import os
import sys
import time
from pathlib import Path
from typing import Any, Dict, List, Optional

# ëª¨ë“ˆ ê²½ë¡œ ì¶”ê°€
sys.path.insert(0, str(Path(__file__).parent.parent.parent.parent / "src"))

from moai_adk.core.tags.validator import CentralValidationResult, CentralValidator, ValidationConfig
from moai_adk.statusline.version_reader import VersionReader

# Local hook configuration functions
from utils.hook_config import get_graceful_degradation, load_hook_timeout


def load_research_config() -> Dict[str, Any]:
    """ì—°êµ¬ ì„¤ì • ë¡œë“œ

    Returns:
        ì—°êµ¬ ì„¤ì • ë”•ì…”ë„ˆë¦¬
    """
    try:
        config_file = Path(".moai/config.json")
        if config_file.exists():
            with open(config_file, 'r', encoding='utf-8') as f:
                config = json.load(f)
                return config.get("tags", {}).get("research_tags", {})
    except Exception:
        pass

    return {
        "auto_discovery": True,
        "pattern_matching": True,
        "cross_reference": True,
        "knowledge_graph": True,
        "auto_update_knowledge": True,
        "research_categories": ["RESEARCH", "ANALYSIS", "KNOWLEDGE", "INSIGHT"]
    }


def analyze_tool_result(tool_name: str, tool_result: Dict[str, Any]) -> Dict[str, Any]:
    """ë„êµ¬ ê²°ê³¼ ë¶„ì„

    Args:
        tool_name: ë„êµ¬ ì´ë¦„
        tool_result: ë„êµ¬ ì‹¤í–‰ ê²°ê³¼

    Returns:
        ë¶„ì„ ê²°ê³¼
    """
    analysis = {
        "tool_name": tool_name,
        "result_type": type(tool_result).__name__,
        "execution_successful": True,
        "analysis_timestamp": time.strftime("%Y-%m-%d %H:%M:%S"),
        "insights": [],
        "patterns": [],
        "optimizations": [],
        "errors": []
    }

    # ì„±ê³µ/ì‹¤íŒ¨ ë¶„ì„
    if tool_result.get("continue", True) is False:
        analysis["execution_successful"] = False
        analysis["errors"].append("ë„êµ¬ ì‹¤í–‰ì´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤")

    # ì—ëŸ¬ ë¶„ì„
    if "error" in tool_result:
        analysis["execution_successful"] = False
        analysis["errors"].append(tool_result["error"])

    # íŒŒì¼ ì‘ì—… ê²°ê³¼ ë¶„ì„
    if tool_name in ["Edit", "Write", "MultiEdit"]:
        if "hookSpecificOutput" in tool_result:
            hook_output = tool_result["hookSpecificOutput"]
            if isinstance(hook_output, dict):
                if "file_path" in hook_output:
                    analysis["modified_files"] = [hook_output["file_path"]]
                if "changes_applied" in hook_output:
                    analysis["changes_applied"] = hook_output["changes_applied"]

    # íƒìƒ‰ ë„êµ¬ ê²°ê³¼ ë¶„ì„
    if tool_name in ["Task", "Explore", "Plan"]:
        if "result" in tool_result:
            result = tool_result["result"]
            if isinstance(result, dict):
                if "findings" in result:
                    analysis["insights"].extend(result["findings"])
                if "recommendations" in result:
                    analysis["optimizations"].extend(result["recommendations"])

    # ê²€ì¦ ë„êµ¬ ê²°ê³¼ ë¶„ì„
    if "validation_result" in tool_result:
        validation = tool_result["validation_result"]
        if isinstance(validation, dict):
            if "is_valid" in validation:
                analysis["validation_passed"] = validation["is_valid"]
            if "errors" in validation:
                analysis["errors"].extend(validation["errors"])

    return analysis


def extract_insights(analysis: Dict[str, Any]) -> List[str]:
    """ì¸ì‚¬ì´íŠ¸ ì¶”ì¶œ

    Args:
        analysis: ë¶„ì„ ê²°ê³¼

    Returns:
        ì¶”ì¶œëœ ì¸ì‚¬ì´íŠ¸ ëª©ë¡
    """
    insights = []

    # ì„±ê³µ ë¶„ì„ ì¸ì‚¬ì´íŠ¸
    if analysis["execution_successful"]:
        insights.append(f"{analysis['tool_name']} ì‘ì—…ì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤")

    # ì—ëŸ¬ ë¶„ì„ ì¸ì‚¬ì´íŠ¸
    if analysis["errors"]:
        insights.append(f"ì‘ì—… ì¤‘ ì—ëŸ¬ ë°œìƒ: {', '.join(analysis['errors'])}")
        insights.append("ì—ëŸ¬ íŒ¨í„´ ë¶„ì„ì´ í•„ìš”í•©ë‹ˆë‹¤")

    # íŒ¨í„´ ì¸ì‚¬ì´íŠ¸
    if analysis["patterns"]:
        insights.append(f"ë°œê²¬ëœ íŒ¨í„´: {', '.join(analysis['patterns'])}")

    # ìµœì í™” ì¸ì‚¬ì´íŠ¸
    if analysis["optimizations"]:
        insights.append(f"ì œì•ˆëœ ìµœì í™”: {', '.join(analysis['optimizations'])}")

    return insights


def update_knowledge_base(insights: List[str], tool_name: str, analysis: Dict[str, Any]) -> Dict[str, Any]:
    """ì§€ì‹ ë² ì´ìŠ¤ ì—…ë°ì´íŠ¸

    Args:
        insights: ì¸ì‚¬ì´íŠ¸ ëª©ë¡
        tool_name: ë„êµ¬ ì´ë¦„
        analysis: ë¶„ì„ ê²°ê³¼

    Returns:
        ì—…ë°ì´íŠ¸ ê²°ê³¼
    """
    try:
        # ì—°êµ¬ ì§€ì‹ ë””ë ‰í† ë¦¬ í™•ì¸
        knowledge_dir = Path(".moai/research/knowledge/")
        knowledge_dir.mkdir(parents=True, exist_ok=True)

        # ì§€ì‹ íŒŒì¼ ê²½ë¡œ
        knowledge_file = knowledge_dir / f"{tool_name}_insights.json"

        # ê¸°ì¡´ ì§€ì‹ ë¡œë“œ
        existing_knowledge = {}
        if knowledge_file.exists():
            with open(knowledge_file, 'r', encoding='utf-8') as f:
                existing_knowledge = json.load(f)

        # ìƒˆë¡œìš´ ì¸ì‚¬ì´íŠ¸ ì¶”ê°€
        current_timestamp = time.strftime("%Y-%m-%d %H:%M:%S")
        new_entry = {
            "timestamp": current_timestamp,
            "insights": insights,
            "analysis": analysis,
            "execution_successful": analysis["execution_successful"]
        }

        # ì§€ì‹ ë³‘í•© (ìµœëŒ€ 100ê°œ í•­ëª© ìœ ì§€)
        if "insights_history" not in existing_knowledge:
            existing_knowledge["insights_history"] = []

        existing_knowledge["insights_history"].append(new_entry)
        existing_knowledge["insights_history"] = existing_knowledge["insights_history"][-100:]

        # ì§€ì‹ íŒŒì¼ ì €ì¥
        with open(knowledge_file, 'w', encoding='utf-8') as f:
            json.dump(existing_knowledge, f, ensure_ascii=False, indent=2)

        return {
            "knowledge_updated": True,
            "knowledge_file": str(knowledge_file),
            "insights_count": len(insights),
            "total_history": len(existing_knowledge["insights_history"])
        }

    except Exception as e:
        return {
            "knowledge_updated": False,
            "error": f"ì§€ì‹ ë² ì´ìŠ¤ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {str(e)}"
        }


def generate_research_report(analysis: Dict[str, Any], knowledge_update: Dict[str, Any],
                           execution_time_ms: float) -> Dict[str, Any]:
    """ì—°êµ¬ ë³´ê³ ì„œ ìƒì„±

    Args:
        analysis: ë¶„ì„ ê²°ê³¼
        knowledge_update: ì§€ì‹ ì—…ë°ì´íŠ¸ ê²°ê³¼
        execution_time_ms: ì‹¤í–‰ ì‹œê°„

    Returns:
        ì—°êµ¬ ë³´ê³ ì„œ
    """
    report = {
        "research_analysis_completed": True,
        "tool_name": analysis["tool_name"],
        "execution_successful": analysis["execution_successful"],
        "execution_time_ms": execution_time_ms,
        "timestamp": analysis["analysis_timestamp"],
        "insights_count": len(analysis["insights"]),
        "errors_count": len(analysis["errors"]),
        "knowledge_update": knowledge_update,
        "recommendations": []
    }

    # ì¶”ì²œ ìƒì„±
    if not analysis["execution_successful"]:
        report["recommendations"].append("ì—ëŸ¬ íŒ¨í„´ ë¶„ì„ ë° ì¬ì‹œë„ ê¶Œì¥")

    if analysis["insights"]:
        report["recommendations"].append("ì¶”ì¶œëœ ì¸ì‚¬ì´íŠ¸ë¥¼ í”„ë¡œì íŠ¸ ë¬¸ì„œì— ë°˜ì˜")

    if analysis["patterns"]:
        report["recommendations"].append("ë°˜ë³µë˜ëŠ” íŒ¨í„´ì„ ìë™í™”ë¡œ ê°œì„ ")

    if analysis["optimizations"]:
        report["recommendations"].append("ì œì•ˆëœ ìµœì í™” ì‚¬í•­ ì ìš©")

    return report


def create_analysis_summary(report: Dict[str, Any]) -> str:
    """ë¶„ì„ ìš”ì•½ ìƒì„±

    Args:
        report: ì—°êµ¬ ë³´ê³ ì„œ

    Returns:
        í¬ë§·ëœ ìš”ì•½ ë©”ì‹œì§€
    """
    summary_parts = [
        f"ğŸ”¬ ì—°êµ¬ ë¶„ì„ ì™„ë£Œ",
        f"ğŸ“ ë„êµ¬: {report['tool_name']}",
        f"â±ï¸ ì‹¤í–‰ ì‹œê°„: {report['execution_time_ms']:.1f}ms",
        f"âœ… ì„±ê³µ: {'Yes' if report['execution_successful'] else 'No'}"
    ]

    if report["insights_count"] > 0:
        summary_parts.append(f"ğŸ’¡ ì¸ì‚¬ì´íŠ¸: {report['insights_count']}ê°œ")

    if report["errors_count"] > 0:
        summary_parts.append(f"âŒ ì—ëŸ¬: {report['errors_count']}ê°œ")

    if report["knowledge_update"]["knowledge_updated"]:
        summary_parts.append(f"ğŸ“š ì§€ì‹ ì—…ë°ì´íŠ¸: {report['knowledge_update']['insights_count']}ê°œ")

    if report["recommendations"]:
        summary_parts.append(f"ğŸ¯ ì¶”ì²œ: {len(report['recommendations'])}ê°œ")

    return "\n".join(summary_parts)


def main() -> None:
    """ë©”ì¸ í•¨ìˆ˜"""
    try:
        # ì„¤ì • ë¡œë“œ
        timeout_seconds = load_hook_timeout() / 1000
        graceful_degradation = get_graceful_degradation()

        # ì¸ì íŒŒì‹±
        if len(sys.argv) < 4:
            print(json.dumps({
                "research_analysis_completed": False,
                "error": "Invalid arguments. Usage: python3 post_tool__research_analysis.py <tool_name> <tool_result_json> <execution_time_ms>"
            }))
            sys.exit(1)

        tool_name = sys.argv[1]
        try:
            tool_result = json.loads(sys.argv[2])
            execution_time_ms = float(sys.argv[3])
        except (json.JSONDecodeError, ValueError) as e:
            print(json.dumps({
                "research_analysis_completed": False,
                "error": f"Invalid arguments: {str(e)}"
            }))
            sys.exit(1)

        # ì‹œì‘ ì‹œê°„ ê¸°ë¡
        start_time = time.time()

        # ì„¤ì • ë¡œë“œ
        research_config = load_research_config()

        # ë„êµ¬ ê²°ê³¼ ë¶„ì„
        analysis = analyze_tool_result(tool_name, tool_result)

        # ì¸ì‚¬ì´íŠ¸ ì¶”ì¶œ
        insights = extract_insights(analysis)

        # ì§€ì‹ ë² ì´ìŠ¤ ì—…ë°ì´íŠ¸
        knowledge_update = {}
        if research_config.get("auto_update_knowledge", True):
            knowledge_update = update_knowledge_base(insights, tool_name, analysis)

        # ì—°êµ¬ ë³´ê³ ì„œ ìƒì„±
        report = generate_research_report(analysis, knowledge_update, execution_time_ms)

        # íƒ€ì„ì•„ì›ƒ ì²´í¬
        if time.time() - start_time > timeout_seconds:
            error_response = {
                "research_analysis_completed": False,
                "error": "ì—°êµ¬ ë¶„ì„ íƒ€ì„ì•„ì›ƒ",
                "message": "ì—°êµ¬ ë¶„ì„ ì‹¤íŒ¨ - ì •ìƒ ì‘ë™ìœ¼ë¡œ ê°„ì£¼",
                "graceful_degradation": graceful_degradation
            }
            print(json.dumps(error_response, ensure_ascii=False))
            sys.exit(1)

        # ì‹¤í–‰ ì‹œê°„ ê³„ì‚°
        analysis_time_ms = (time.time() - start_time) * 1000

        # ìµœì¢… ì‘ë‹µ
        response = {
            **report,
            "analysis_time_ms": analysis_time_ms,
            "message": create_analysis_summary(report)
        }

        # ì„±ëŠ¥ ê²½ê³ 
        timeout_warning_ms = timeout_seconds * 1000 * 0.8
        if analysis_time_ms > timeout_warning_ms:
            response["performance_warning"] = f"ë¶„ì„ ì‹œê°„ì´ íƒ€ì„ì•„ì›ƒì˜ 80%ë¥¼ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤ ({analysis_time_ms:.0f}ms / {timeout_warning_ms:.0f}ms)"

        print(json.dumps(response, ensure_ascii=False, indent=2))

    except Exception as e:
        # ì˜ˆì™¸ ì²˜ë¦¬
        error_response = {
            "research_analysis_completed": False,
            "error": f"ì—°êµ¬ ë¶„ì„ ì˜¤ë¥˜: {str(e)}",
            "message": "ì—°êµ¬ ë¶„ì„ ì‹¤íŒ¨ - ì •ìƒ ì‘ë™ìœ¼ë¡œ ê°„ì£¼"
        }

        if graceful_degradation:
            error_response["graceful_degradation"] = True

        print(json.dumps(error_response, ensure_ascii=False))
        sys.exit(1)


if __name__ == "__main__":
    main()