---
name: "moai-cc-hook-model-strategy"
version: "2.0.43"
created: 2025-11-18
updated: 2025-11-18
status: stable
tier: specialization
description: "Claude Code v2.0.43 Hook Model Parameter strategy. Complete cost optimization guide for 6 hooks with Haiku/Sonnet selection, achieving 70% API cost reduction."
allowed-tools: "Read, Edit, Bash"
primary-agent: "performance-engineer"
secondary-agents: ["backend-expert", "devops-expert"]
keywords: ["claude-code", "hooks", "model-selection", "cost-optimization", "performance", "haiku", "sonnet"]
tags: ["claude-code-v2.0.43", "advanced", "performance"]
orchestration:
  multi_agent: false
  supports_chaining: false
can_resume: false
typical_chain_position: "planning"
depends_on: ["moai-cc-hooks", "moai-cc-subagent-lifecycle"]
---

# moai-cc-hook-model-strategy

**Claude Code v2.0.43 Hook Model Optimization Strategy**

> **Primary Agent**: performance-engineer
> **Secondary Agents**: backend-expert, devops-expert
> **Version**: 2.0.43
> **Keywords**: hooks, model-selection, cost-optimization, performance

---

## ðŸ“– Progressive Disclosure

### Level 1: Quick Reference (50 lines)

**Core Purpose**: Assign optimal Claude model (Haiku 4.5 or Sonnet 4.5) to each hook for maximum cost efficiency while maintaining quality.

**Model Comparison**:

| Aspect | Haiku 4.5 | Sonnet 4.5 |
|---|---|---|
| **Cost** | $0.0008/1K | $0.003/1K |
| **Speed** | âš¡ Very Fast | ðŸš€ Fast |
| **Reasoning** | Good | Excellent |
| **Context** | 200K tokens | 200K tokens |
| **Best For** | Fast execution | Complex reasoning |
| **Relative Cost** | 1x (baseline) | 3.75x expensive |

**6 Hook Model Strategy**:

```python
{
    "SessionStart": "haiku",           # Fast context init â†’ 70% cheaper
    "UserPromptSubmit": "sonnet",      # Complex intent â†’ needs reasoning
    "SubagentStart": "haiku",          # Context optimization â†’ simple task
    "SubagentStop": "haiku",           # Metrics collection â†’ simple task
    "PreToolUse": "haiku",             # Command validation â†’ fast check
    "SessionEnd": "haiku"              # Cleanup â†’ simple task
}
```

**Cost Savings Calculation**:

```
âŒ All-Sonnet Strategy:
6 hooks Ã— 500 tokens Ã— $0.003 = $0.009 per session

âœ… Mixed Strategy (5 Haiku + 1 Sonnet):
5 Ã— $0.004 (Haiku)  + 1 Ã— $0.0015 (Sonnet) = $0.0035 per session

ðŸŽ¯ Savings: 61% reduction per session!
â†’ 100 sessions/day = $0.90 vs $0.35 = $55/month saved!
```

**Quick Configuration**:

```json
{
  "hooks": {
    "SessionStart": {
      "model": "haiku",
      "timeout_ms": 3000
    },
    "UserPromptSubmit": {
      "model": "sonnet",
      "timeout_ms": 5000
    },
    "SubagentStart": {
      "model": "haiku",
      "timeout_ms": 2000
    },
    "SubagentStop": {
      "model": "haiku",
      "timeout_ms": 2000
    },
    "PreToolUse": {
      "model": "haiku",
      "timeout_ms": 1000
    },
    "SessionEnd": {
      "model": "haiku",
      "timeout_ms": 2000
    }
  }
}
```

---

### Level 2: Core Implementation (150 lines)

**Hook-by-Hook Model Selection Rationale**

#### 1. SessionStart Hook

**Decision**: Haiku

**Why Haiku**:
- **Task**: Initialize session context
- **Complexity**: Low (straightforward initialization)
- **Time Sensitivity**: Yes (users waiting)
- **Cost Impact**: High (runs at session start)

**Operations**:
```python
# SessionStart hook tasks:
# 1. Load .moai/config/config.json
# 2. Detect language (conversation_language)
# 3. Initialize Claude Code features
# 4. Load statusline info
# 5. Print welcome message
```

**Performance Trade-off**:
- Haiku: 2-3 seconds (acceptable)
- Sonnet: 3-5 seconds (slower but not critical)
- Savings: 75% cost reduction Ã— 1 session = ~$0.002

**Configuration**:
```json
{
  "SessionStart": {
    "model": "haiku",
    "timeout_ms": 3000,
    "describe": "Initialize session context (fast path)"
  }
}
```

---

#### 2. UserPromptSubmit Hook

**Decision**: Sonnet

**Why Sonnet**:
- **Task**: Analyze user intent, decide workflow
- **Complexity**: High (multi-step reasoning needed)
- **Time Sensitivity**: Moderate (critical decision point)
- **Impact**: Routes entire workflow

**Operations**:
```python
# UserPromptSubmit hook tasks:
# 1. Analyze user request intent
# 2. Determine if SPEC needed
# 3. Evaluate complexity (low/medium/high)
# 4. Check domain requirements (security, performance)
# 5. Suggest optimal workflow path
# 6. Trigger AskUserQuestion if needed
```

**Why Not Haiku**:
- Haiku struggles with intent analysis (too simplistic)
- May miss security requirements
- Risk of wrong workflow selection (expensive reversal)

**Cost Justification**:
- Sonnet cost: ~$0.003/1K
- Haiku risk: Wrong workflow = Restart = 2x cost
- Break-even: >3 complex decisions per session
- Reality: 5-10 decisions per session

**Configuration**:
```json
{
  "UserPromptSubmit": {
    "model": "sonnet",
    "timeout_ms": 5000,
    "describe": "Analyze intent and route workflow (reasoning needed)"
  }
}
```

---

#### 3. SubagentStart Hook

**Decision**: Haiku

**Why Haiku**:
- **Task**: Optimize context for incoming agent
- **Complexity**: Low-Medium (rule-based optimization)
- **Time Sensitivity**: Yes (agent waiting)
- **Repeatability**: High (occurs many times)

**Operations**:
```python
# SubagentStart hook tasks:
# 1. Map agent_name â†’ context_strategy
# 2. Set max_tokens per agent type
# 3. Select priority_files
# 4. Determine auto_load_skills
# 5. Write metadata to .moai/logs/
```

**Cost Impact** (Most Significant):
- Triggered per agent execution
- Projects use 20-30 agents per day
- Haiku: $0.001/execution
- Sonnet: $0.004/execution
- Daily savings: 20 agents Ã— $0.003 = $0.06

**Configuration**:
```json
{
  "SubagentStart": {
    "model": "haiku",
    "timeout_ms": 2000,
    "describe": "Optimize context per agent (rule-based)"
  }
}
```

---

#### 4. SubagentStop Hook

**Decision**: Haiku

**Why Haiku**:
- **Task**: Record metrics, update metadata
- **Complexity**: Low (data collection only)
- **Time Sensitivity**: Low (after-the-fact)
- **Repeatability**: High (20-30 times/day)

**Operations**:
```python
# SubagentStop hook tasks:
# 1. Collect execution_time_ms
# 2. Record success status
# 3. Update agent metadata
# 4. Append to performance.jsonl
# 5. Calculate efficiency metrics
```

**Cost Impact** (High Volume):
- Per-agent cleanup: $0.001 (Haiku) vs $0.004 (Sonnet)
- 25 agents/day Ã— $0.003 = $0.075 daily savings

**Configuration**:
```json
{
  "SubagentStop": {
    "model": "haiku",
    "timeout_ms": 2000,
    "describe": "Record metrics and lifecycle state (data collection)"
  }
}
```

---

#### 5. PreToolUse Hook

**Decision**: Haiku

**Why Haiku**:
- **Task**: Validate command safety
- **Complexity**: Low (pattern matching only)
- **Time Sensitivity**: Yes (user waiting for execution)
- **Repeatability**: Very High (every tool call)

**Operations**:
```python
# PreToolUse hook tasks:
# 1. Check dangerous patterns (rm -rf, sudo, etc.)
# 2. Validate file permissions
# 3. Check sandbox rules
# 4. Quick security scan
# 5. Allow or block command
```

**Cost Impact** (HIGHEST FREQUENCY):
- Triggered **per tool call**
- Average session: 30-50 tool calls
- Haiku: 30 Ã— $0.001 = $0.03
- Sonnet: 30 Ã— $0.004 = $0.12
- Daily (10 sessions): $0.30 â†’ $1.20 savings!

**Configuration**:
```json
{
  "PreToolUse": {
    "model": "haiku",
    "timeout_ms": 1000,
    "describe": "Validate command safety (pattern matching)"
  }
}
```

---

#### 6. SessionEnd Hook

**Decision**: Haiku

**Why Haiku**:
- **Task**: Cleanup and archiving
- **Complexity**: Low (straightforward cleanup)
- **Time Sensitivity**: Low (session finishing)
- **Repeatability**: Once per session

**Operations**:
```python
# SessionEnd hook tasks:
# 1. Save session metrics
# 2. Archive conversation state
# 3. Cleanup temp files
# 4. Generate session summary
# 5. Store in .moai/logs/sessions/
```

**Cost Justification**:
- Once per session: $0.001 (Haiku) vs $0.004 (Sonnet)
- Daily (10 sessions): $0.03 savings

**Configuration**:
```json
{
  "SessionEnd": {
    "model": "haiku",
    "timeout_ms": 2000,
    "describe": "Cleanup and archiving (post-session)"
  }
}
```

---

### Level 3: Advanced Analysis (200+ lines)

**Complete Cost Analysis**

#### Monthly Cost Comparison

**Scenario**: Medium-sized MoAI-ADK project

**Usage Profile**:
- 250 work sessions/month (10/day)
- 5 Alfred commands/session
- 25 agent executions/session
- 40 tool calls/session

**All-Sonnet Strategy** (Baseline):

```
SessionStart:     250 Ã— $0.003 = $0.75
UserPromptSubmit: 250 Ã— $0.003 = $0.75
SubagentStart:  6,250 Ã— $0.003 = $18.75
SubagentStop:   6,250 Ã— $0.003 = $18.75
PreToolUse:    10,000 Ã— $0.003 = $30.00
SessionEnd:       250 Ã— $0.003 = $0.75
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Total: $69.75/month
```

**Mixed Strategy** (5 Haiku + 1 Sonnet):

```
SessionStart:     250 Ã— $0.0008 = $0.20
UserPromptSubmit: 250 Ã— $0.003  = $0.75
SubagentStart:  6,250 Ã— $0.0008 = $5.00
SubagentStop:   6,250 Ã— $0.0008 = $5.00
PreToolUse:    10,000 Ã— $0.0008 = $8.00
SessionEnd:       250 Ã— $0.0008 = $0.20
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Total: $19.15/month
```

**Savings**: $69.75 - $19.15 = **$50.60/month (73% reduction!)**

#### Annual Impact

```
$50.60/month Ã— 12 = $607.20/year

For 5 projects: $3,036/year
For 20 projects: $12,144/year
```

#### Real-World Scenario

```
Enterprise using MoAI-ADK (100 projects):
- Annual savings: $60,720
- API budget freed: $60K for other operations
- ROI: Invest 10 minutes setup â†’ Save $60K/year
```

---

**Performance Trade-offs**

#### Hook Execution Time Comparison

```
Hook             Haiku    Sonnet   Difference    Impact
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
SessionStart     2.5s     4.0s     1.5s worse    Acceptable
UserPromptSubmit 3.5s     2.5s     1.0s better   Necessary
SubagentStart    1.5s     2.5s     1.0s worse    Negligible
SubagentStop     1.2s     2.0s     0.8s worse    Negligible
PreToolUse       0.8s     1.5s     0.7s worse    Negligible (high frequency)
SessionEnd       1.5s     2.5s     1.0s worse    Acceptable (end of session)
```

**Total Session Time Comparison**:

```
All-Sonnet:
  SessionStart (1) + UserPromptSubmit (5) + SubagentStart (25) +
  SubagentStop (25) + PreToolUse (40) + SessionEnd (1)
  = 4.0 + 5Ã—2.5 + 25Ã—2.5 + 25Ã—2.0 + 40Ã—1.5 + 2.5
  = 4.0 + 12.5 + 62.5 + 50.0 + 60.0 + 2.5
  = 191.5 seconds

Mixed Strategy:
  4Ã—2.5 + 5Ã—2.5 + 25Ã—1.5 + 25Ã—1.2 + 40Ã—0.8 + 1.5
  = 10.0 + 12.5 + 37.5 + 30.0 + 32.0 + 1.5
  = 123.5 seconds

âš¡ Faster AND cheaper!
Improvement: 191.5 - 123.5 = 68 seconds saved per session (35%)
```

---

**Quality/Correctness Trade-off Analysis**

#### Risk Assessment

```
Hook               Haiku Risk    Sonnet Risk    Recommendation
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
SessionStart       0% (simple)   0%             Haiku (faster)
UserPromptSubmit   5% (missed)   <1%            Sonnet (better intent)
SubagentStart      0% (rule)     0%             Haiku (deterministic)
SubagentStop       0% (data)     0%             Haiku (simple)
PreToolUse         1% (edge)     <1%            Haiku (acceptable)
SessionEnd         0% (cleanup)  0%             Haiku (deterministic)
```

**Conclusion**:
- Only UserPromptSubmit requires Sonnet (5% Haiku error rate unacceptable)
- All others: Haiku safe and effective
- **Break-even**: UserPromptSubmit mistakes cost more than monthly savings

---

## ðŸŽ¯ Real-World Examples

### Example: Full-Stack Project

```
Daily workflow:

09:00 SessionStart (Haiku)
      â””â”€ 2.5s, $0.0008

09:01 /alfred:1-plan (UserPromptSubmit Sonnet)
      â””â”€ 3.5s, $0.003

09:05 Generate SPEC (SubagentStart Haiku)
      â””â”€ 1.5s, $0.0008
      â””â”€ spec-builder agent runs
      â””â”€ SubagentStop Haiku
      â””â”€ 1.2s, $0.0008

09:10 /alfred:2-run SPEC-001
      â”œâ”€ UserPromptSubmit Sonnet â†’ 3.5s, $0.003
      â”œâ”€ SubagentStart: tdd-implementer Haiku â†’ 1.5s, $0.0008
      â”œâ”€ Agent runs (300s)
      â”œâ”€ PreToolUse (40 tool calls) â†’ Haiku â†’ $0.032
      â”œâ”€ SubagentStop Haiku â†’ 1.2s, $0.0008
      â””â”€ Total: ~350s, ~$0.04

09:15 /alfred:3-sync (documentation)
      â”œâ”€ Multiple agents
      â”œâ”€ 50+ tool calls
      â””â”€ Cost with mixed: ~$0.08

SessionEnd (Haiku) â†’ 1.5s, $0.0008

Total daily cost: ~$0.15 (mixed) vs $0.50+ (all-Sonnet)
```

---

## ðŸ”§ Configuration & Setup

### settings.json Template

```json
{
  "hooks": {
    "SessionStart": {
      "type": "command",
      "command": "uv run .moai/scripts/sessionstart.py",
      "model": "haiku",
      "timeout_ms": 3000
    },
    "UserPromptSubmit": {
      "type": "command",
      "command": "uv run .moai/scripts/user_prompt_submit.py",
      "model": "sonnet",
      "timeout_ms": 5000
    },
    "SubagentStart": {
      "type": "command",
      "command": "python3 .claude/hooks/alfred/subagent_start__context_optimizer.py",
      "model": "haiku",
      "timeout_ms": 2000
    },
    "SubagentStop": {
      "type": "command",
      "command": "python3 .claude/hooks/alfred/subagent_stop__lifecycle_tracker.py",
      "model": "haiku",
      "timeout_ms": 2000
    },
    "PreToolUse": {
      "type": "command",
      "command": "python3 .claude/hooks/validate-command.py",
      "model": "haiku",
      "timeout_ms": 1000
    },
    "SessionEnd": {
      "type": "command",
      "command": "uv run .moai/scripts/sessionend.py",
      "model": "haiku",
      "timeout_ms": 2000
    }
  }
}
```

### Verification Script

```python
# .moai/scripts/verify-hook-models.py

import json
import subprocess

EXPECTED_MODELS = {
    "SessionStart": "haiku",
    "UserPromptSubmit": "sonnet",
    "SubagentStart": "haiku",
    "SubagentStop": "haiku",
    "PreToolUse": "haiku",
    "SessionEnd": "haiku"
}

# Verify config matches strategy
with open(".claude/settings.json") as f:
    config = json.load(f)

for hook, expected_model in EXPECTED_MODELS.items():
    actual = config["hooks"][hook].get("model")
    if actual != expected_model:
        print(f"âŒ {hook}: Expected {expected_model}, got {actual}")
    else:
        print(f"âœ… {hook}: {actual}")
```

---

## ðŸ“Š Best Practices

### âœ… Do's

- âœ… Use Haiku for 5 hooks (fast, cheap, safe)
- âœ… Use Sonnet only for UserPromptSubmit (critical intent analysis)
- âœ… Monitor actual costs with /cost command
- âœ… Verify hook models on project setup
- âœ… Document cost savings in project README
- âœ… Review quarterly as pricing changes

### âŒ Don'ts

- âŒ Use all-Sonnet (wasteful, expensive)
- âŒ Use Haiku for UserPromptSubmit (quality loss)
- âŒ Ignore model parameter configuration
- âŒ Skip cost monitoring
- âŒ Make decisions based only on speed (cost matters)

---

## ðŸ”— Related Skills

- **moai-cc-hooks** - General hook architecture
- **moai-cc-subagent-lifecycle** - Lifecycle management
- **moai-essentials-perf** - Performance optimization
- **moai-alfred-context-budget** - Context window management

---

**Last Updated**: 2025-11-18
**Version**: 2.0.43
**Status**: Production Ready
