"""
TAG ì‹œìŠ¤í…œ ìµœì í™” ìœ í‹¸ë¦¬í‹°
ì´ ëª¨ë“ˆì€ ë¬¸ì„œ ì‹œìŠ¤í…œì˜ TAGë¥¼ ê´€ë¦¬í•˜ê³  ìµœì í™”í•©ë‹ˆë‹¤.

:TAG-OPTIMIZER
"""

import re
import json
from pathlib import Path
from typing import Dict, List, Optional, Set, Tuple
from dataclasses import dataclass


@dataclass
class TagInfo:
    """TAG ì •ë³´ ë°ì´í„° í´ë˜ìŠ¤"""
    full_tag: str
    code: str
    language: Optional[str]
    category: str
    line_number: int
    file_path: str


class TagOptimizer:
    """TAG ì‹œìŠ¤í…œ ìµœì í™” í´ë˜ìŠ¤"""

    def __init__(self, base_dir: str = "."):
        self.base_dir = Path(base_dir)
        self.document_manager = self._load_document_manager()

    def _load_document_manager(self):
        """ë¬¸ì„œ ê´€ë¦¬ì ë¡œë“œ (ê°„ë‹¨í•œ ë²„ì „)"""
        config_path = self.base_dir / "multilingual_config.json"
        if config_path.exists():
            with open(config_path, 'r', encoding='utf-8') as f:
                config = json.load(f)

            # ê°„ë‹¨í•œ ë¬¸ì„œ ê´€ë¦¬ì ìƒì„±
            class SimpleDocManager:
                def __init__(self, config):
                    self.tag_migration = config['document_system']['tag_system']['tag_migration']
                    self.deprecated_tags = config['document_system']['tag_system']['deprecated_tags']
                    self.language_tags = config['document_system']['tag_system']['language_tags']

            return SimpleDocManager(config)
        return None

    def find_all_tags(self) -> List[TagInfo]:
        """ëª¨ë“  íŒŒì¼ì—ì„œ TAGë¥¼ ê²€ìƒ‰"""
        all_tags = []

        # ë¬¸ì„œ íŒŒì¼ë§Œ ê²€ìƒ‰
        doc_files = list(self.base_dir.glob("*.md"))
        doc_files.extend(self.base_dir.glob("README-*.md"))

        for file_path in doc_files:
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()

                tags = self._extract_tags_from_content(content, str(file_path))
                all_tags.extend(tags)
            except (FileNotFoundError, PermissionError):
                continue

        return all_tags

    def _extract_tags_from_content(self, content: str, file_path: str) -> List[TagInfo]:
        """ì½˜í…ì¸ ì—ì„œ TAG ì¶”ì¶œ"""
        tags = []

        # @CODE: íŒ¨í„´ ê²€ìƒ‰
        pattern = r'#\s*@CODE:([^\s\n]+)'
        matches = re.finditer(pattern, content)

        for match in matches:
            full_tag = match.group(0)
            tag_code = match.group(1)

            # TAG ë¶„ì„
            tag_parts = tag_code.split(':')
            language = None

            if len(tag_parts) >= 3:
                # DOC-ONLINE-001:KO í˜•ì‹
                category = tag_parts[0]
                spec_id = tag_parts[1]
                language = tag_parts[2]
            elif len(tag_parts) == 2:
                # DOCS-002 í˜•ì‹
                category = tag_parts[0]
                spec_id = tag_parts[1]
            else:
                # ë‹¨ì¼ TAG
                category = tag_parts[0]
                spec_id = None

            # ë¼ì¸ ë²ˆí˜¸ ê³„ì‚°
            line_number = content[:match.start()].count('\n') + 1

            tag_info = TagInfo(
                full_tag=full_tag,
                code=tag_code,
                language=language,
                category=category,
                line_number=line_number,
                file_path=file_path
            )
            tags.append(tag_info)

        return tags

    def analyze_tag_usage(self) -> Dict[str, any]:
        """TAG ì‚¬ìš© í˜„ ë¶„ì„"""
        all_tags = self.find_all_tags()

        analysis = {
            'total_tags': len(all_tags),
            'unique_tags': len(set(tag.code for tag in all_tags)),
            'tag_by_category': {},
            'tag_by_language': {},
            'deprecated_tags': [],
            'duplicate_tags': [],
            'unused_tags': [],
            'files_with_tags': {}
        }

        # ì¹´í…Œê³ ë¦¬ë³„ ë¶„ë¥˜
        for tag in all_tags:
            category = tag.category
            if category not in analysis['tag_by_category']:
                analysis['tag_by_category'][category] = 0
            analysis['tag_by_category'][category] += 1

            # ì–¸ì–´ë³„ ë¶„ë¥˜
            if tag.language:
                if tag.language not in analysis['tag_by_language']:
                    analysis['tag_by_language'][tag.language] = 0
                analysis['tag_by_language'][tag.language] += 1

            # íŒŒì¼ë³„ ë¶„ë¥˜
            if tag.file_path not in analysis['files_with_tags']:
                analysis['files_with_tags'][tag.file_path] = []
            analysis['files_with_tags'][tag.file_path].append(tag.code)

        # ì‚¬ìš©ë˜ì§€ ì•ŠëŠ” íƒœê·¸ ì‹ë³„
        if self.document_manager:
            expected_tags = set()
            expected_tags.update(self.document_manager.language_tags)
            expected_tags.add("DOC-ONLINE-001:MAIN")

            used_tags = set(tag.code for tag in all_tags)
            analysis['unused_tags'] = list(expected_tags - used_tags)

            # ì‚¬ìš©ë˜ì§€ ì•ŠëŠ” ì˜ˆì „ íƒœê·¸ ì‹ë³„
            analysis['deprecated_tags'] = [
                tag for tag in all_tags
                if tag.code in self.document_manager.deprecated_tags
            ]

            # ì¤‘ë³µëœ íƒœê·¸ ì‹ë³„
            tag_counts = {}
            for tag in all_tags:
                tag_counts[tag.code] = tag_counts.get(tag.code, 0) + 1

            analysis['duplicate_tags'] = [
                tag.code for tag, count in tag_counts.items()
                if count > 1
            ]

        return analysis

    def optimize_tags(self) -> Dict[str, any]:
        """TAG ìµœì í™” ìˆ˜í–‰"""
        analysis = self.analyze_tag_usage()
        optimization_results = {
            'files_processed': 0,
            'tags_migrated': 0,
            'tags_cleaned': 0,
            'errors': []
        }

        # ëª¨ë“  ë¬¸ì„œ íŒŒì¼ ì²˜ë¦¬
        doc_files = list(self.base_dir.glob("*.md"))
        doc_files.extend(self.base_dir.glob("README-*.md"))

        for file_path in doc_files:
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()

                # TAG ë§ˆì´ê·¸ë ˆì´ì…˜
                migrated_count = self._migrate_tags_in_content(content)
                if migrated_count > 0:
                    optimization_results['tags_migrated'] += migrated_count

                # ì‚¬ìš©ë˜ì§€ ì•ŠëŠ” íƒœê·¸ ì •ë¦¬
                cleaned_count = self._clean_deprecated_tags_in_content(content)
                if cleaned_count > 0:
                    optimization_results['tags_cleaned'] += cleaned_count

                optimization_results['files_processed'] += 1

            except (FileNotFoundError, PermissionError) as e:
                optimization_results['errors'].append(f"Error processing {file_path}: {str(e)}")

        return optimization_results

    def _migrate_tags_in_content(self, content: str) -> int:
        """ì½˜í…ì¸  ë‚´ì—ì„œ TAG ë§ˆì´ê·¸ë ˆì´ì…˜"""
        if not self.document_manager:
            return 0

        migrated_count = 0
        for old_tag, new_tag in self.document_manager.tag_migration.items():
            if old_tag in content:
                content = content.replace(old_tag, new_tag)
                migrated_count += 1

        return migrated_count

    def _clean_deprecated_tags_in_content(self, content: str) -> int:
        """ì½˜í…ì¸  ë‚´ì—ì„œ ì‚¬ìš©ë˜ì§€ ì•ŠëŠ” íƒœê·¸ ì •ë¦¬"""
        if not self.document_manager:
            return 0

        cleaned_count = 0
        for deprecated_tag in self.document_manager.deprecated_tags:
            if deprecated_tag in content:
                # ì ì ˆí•œ ìƒˆ íƒœê·¸ë¡œ êµì²´
                if deprecated_tag == "@CODE:DOCS-003":
                    content = content.replace(deprecated_tag, ":KO")
                elif deprecated_tag in ["@CODE:DOCS-001", "@CODE:DOCS-002"]:
                    content = content.replace(deprecated_tag, ":MAIN")
                cleaned_count += 1

        return cleaned_count

    def generate_tag_report(self) -> str:
        """TAG ì‚¬ìš© í˜„í™© ë³´ê³ ì„œ ìƒì„±"""
        analysis = self.analyze_tag_usage()

        report = f"""# TAG ì‹œìŠ¤í…œ í˜„í™© ë³´ê³ ì„œ

**ìƒì„±ì¼**: 2025-11-05
**ëŒ€ìƒ ë””ë ‰í† ë¦¬**: {self.base_dir}
**ì´ íŒŒì¼ ìˆ˜**: {len(list(self.base_dir.glob("*.md")) + list(self.base_dir.glob("README-*.md")))}

## ğŸ“Š TAG ì‚¬ìš© í˜„í™©

- **ì´ TAG ìˆ˜**: {analysis['total_tags']}
- **ê³ ìœ  TAG ìˆ˜**: {analysis['unique_tags']}
- **íŒŒì¼ ìˆ˜**: {len(analysis['files_with_tags'])}

### ğŸ—‚ï¸ ì¹´í…Œê³ ë¦¬ë³„ ë¶„ë¥˜
"""

        for category, count in analysis['tag_by_category'].items():
            report += f"- **{category}**: {count}ê°œ\n"

        if analysis['tag_by_language']:
            report += "\n### ğŸŒ ì–¸ì–´ë³„ ë¶„ë¥˜\n"
            for language, count in analysis['tag_by_language'].items():
                report += f"- **{language}**: {count}ê°œ\n"

        if analysis['deprecated_tags']:
            report += "\n### âš ï¸ ì‚¬ìš©ë˜ì§€ ì•ŠëŠ” TAG\n"
            for tag in analysis['deprecated_tags']:
                report += f"- `{tag.code}` ({Path(tag.file_path).name}:{tag.line_number})\n"

        if analysis['duplicate_tags']:
            report += "\n### ğŸ”„ ì¤‘ë³µëœ TAG\n"
            for tag in analysis['duplicate_tags']:
                report += f"- `{tag}`\n"

        if analysis['unused_tags']:
            report += "\n### ğŸ“¦ ì‚¬ìš©ë˜ì§€ ì•ŠëŠ” ì˜ˆìƒ TAG\n"
            for tag in analysis['unused_tags']:
                report += f"- `{tag}`\n"

        report += "\n## ğŸ“ íŒŒì¼ë³„ TAG í˜„í™©\n"
        for file_path, tags in analysis['files_with_tags'].items():
            file_name = Path(file_path).name
            report += f"### {file_name}\n"
            report += f"TAG ìˆ˜: {len(tags)}\n"
            for tag in tags:
                report += f"- `{tag}`\n"
            report += "\n"

        return report

    def validate_tag_consistency(self) -> Dict[str, any]:
        """TAG ì¼ê´€ì„± ê²€ì‚¬"""
        analysis = self.analyze_tag_usage()

        validation = {
            'is_consistent': True,
            'warnings': [],
            'errors': [],
            'recommendations': []
        }

        # ì¤‘ë³µëœ TAG í™•ì¸
        if analysis['duplicate_tags']:
            validation['warnings'].append(
                f"ì¤‘ë³µëœ TAG ë°œê²¬: {', '.join(analysis['duplicate_tags'])}"
            )
            validation['is_consistent'] = False

        # ì‚¬ìš©ë˜ì§€ ì•ŠëŠ” ì˜ˆìƒ TAG í™•ì¸
        if analysis['unused_tags']:
            validation['recommendations'].append(
                f"ì‚¬ìš©ë˜ì§€ ì•ŠëŠ” ì˜ˆìƒ TAG: {', '.join(analysis['unused_tags'])}"
            )

        # ì‚¬ìš©ë˜ì§€ ì•ŠëŠ” ì˜ˆì „ TAG í™•ì¸
        if analysis['deprecated_tags']:
            validation['errors'].append(
                f"ì‚¬ìš©ë˜ì§€ ì•ŠëŠ” ì˜ˆì „ TAG ë°œê²¬: {', '.join([tag.code for tag in analysis['deprecated_tags']])}"
            )
            validation['is_consistent'] = False

        # ì–¸ì–´ TAG ê· í˜• ê²€ì‚¬
        if analysis['tag_by_language']:
            max_count = max(analysis['tag_by_language'].values())
            min_count = min(analysis['tag_by_language'].values())

            if max_count - min_count > 2:
                validation['warnings'].append(
                    f"ì–¸ì–´ë³„ TAG ìˆ˜ ì°¨ì´ê°€ í¼: {max_count} vs {min_count}"
                )

        return validation


# ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
tag_optimizer = TagOptimizer()

# í•¨ìˆ˜ë“¤ì„ ëª¨ë“ˆ ë ˆë²¨ì—ì„œ ì œê³µ
def analyze_tag_usage() -> Dict[str, any]:
    """TAG ì‚¬ìš© í˜„í™© ë¶„ì„"""
    return tag_optimizer.analyze_tag_usage()

def optimize_tags() -> Dict[str, any]:
    """TAG ìµœì í™” ìˆ˜í–‰"""
    return tag_optimizer.optimize_tags()

def generate_tag_report() -> str:
    """TAG ì‹œìŠ¤í…œ ë³´ê³ ì„œ ìƒì„±"""
    return tag_optimizer.generate_tag_report()

def validate_tag_consistency() -> Dict[str, any]:
    """TAG ì¼ê´€ì„± ê²€ì‚¬"""
    return tag_optimizer.validate_tag_consistency()