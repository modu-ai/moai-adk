# ë°°í¬ ì™„ì „ ê°€ì´ë“œ

MoAI-ADK í”„ë¡œì íŠ¸ì˜ ë°°í¬ ê³¼ì •ì„ í¬ê´„ì ìœ¼ë¡œ ë‹¤ë£¨ëŠ” ê°€ì´ë“œì…ë‹ˆë‹¤. Docker ì»¨í…Œì´ë„ˆ ë°°í¬ë¶€í„° í´ë¼ìš°ë“œ ì„œë¹„ìŠ¤, CI/CD íŒŒì´í”„ë¼ì¸ êµ¬ì¶•ê¹Œì§€ ë‹¤ì–‘í•œ ë°°í¬ í™˜ê²½ê³¼ í˜„ëŒ€ì ì¸ DevOps ê´€í–‰ì„ ìƒì„¸í•˜ê²Œ ì„¤ëª…í•©ë‹ˆë‹¤.

## ëª©ì°¨

1. [ê°œìš”](#ê°œìš”)
2. [ë°°í¬ ì•„í‚¤í…ì²˜](#ë°°í¬-ì•„í‚¤í…ì²˜)
3. [Docker ì»¨í…Œì´ë„ˆ ë°°í¬](#docker-ì»¨í…Œì´ë„ˆ-ë°°í¬)
4. [í´ë¼ìš°ë“œ í”Œë«í¼ ë°°í¬](#í´ë¼ìš°ë“œ-í”Œë«í¼-ë°°í¬)
5. [CI/CD íŒŒì´í”„ë¼ì¸ êµ¬ì¶•](#cicd-íŒŒì´í”„ë¼ì¸-êµ¬ì¶•)
6. [í™˜ê²½ë³„ ë°°í¬ ì „ëµ](#í™˜ê²½ë³„-ë°°í¬-ì „ëµ)
7. [ë¡¤ì•„ì›ƒ ì „ëµ](#ë¡¤ì•„ì›ƒ-ì „ëµ)
8. [ëª¨ë‹ˆí„°ë§ê³¼ ë¡œê¹…](#ëª¨ë‹ˆí„°ë§ê³¼-ë¡œê¹…)
9. [ë³´ì•ˆ ë° ê·œì œ ì¤€ìˆ˜](#ë³´ì•ˆ-ë°-ê·œì œ-ì¤€ìˆ˜)
10. [ë°°í¬ ìë™í™”](#ë°°í¬-ìë™í™”)
11. [ì„±ëŠ¥ ìµœì í™”](#ì„±ëŠ¥-ìµœì í™”)
12. [ë¬¸ì œ í•´ê²° ë° ë³µêµ¬](#ë¬¸ì œ-í•´ê²°-ë°-ë³µêµ¬)
13. [ëª¨ë²” ì‚¬ë¡€](#ëª¨ë²”-ì‚¬ë¡€)

## ê°œìš”

MoAI-ADK í”„ë¡œì íŠ¸ì˜ ë°°í¬ëŠ” ë‹¨ìˆœíˆ ì½”ë“œë¥¼ ì„œë²„ì— ì˜¬ë¦¬ëŠ” ê²ƒì„ ë„˜ì–´, ì•ˆì •ì ì´ê³  í™•ì¥ ê°€ëŠ¥í•˜ë©° ì•ˆì „í•œ ì‹œìŠ¤í…œì„ êµ¬ì¶•í•˜ëŠ” ê³¼ì •ì…ë‹ˆë‹¤. Alfredì˜ SPEC-first ê°œë°œ ë°©ì‹ì€ ë°°í¬ ê³¼ì •ì—ì„œë„ ì¼ê´€ì„±ê³¼ ì¶”ì ì„±ì„ ë³´ì¥í•©ë‹ˆë‹¤.

### ë°°í¬ ì‹œìŠ¤í…œì˜ í•µì‹¬ ì›ì¹™

1. **Automation First**: ëª¨ë“  ë°°í¬ ê³¼ì •ì€ ìë™í™”ë˜ì–´ì•¼ í•¨
2. **Zero Downtime**: ì‚¬ìš©ìì—ê²Œ ì„œë¹„ìŠ¤ ì¤‘ë‹¨ì´ ì—†ì–´ì•¼ í•¨
3. **Rollback Ready**: ì–¸ì œë“ ì§€ ì´ì „ ë²„ì „ìœ¼ë¡œ ë¡¤ë°± ê°€ëŠ¥í•´ì•¼ í•¨
4. **Observable**: ë°°í¬ ìƒíƒœì™€ ì‹œìŠ¤í…œ ê±´ê°• ìƒíƒœë¥¼ ì‹¤ì‹œê°„ìœ¼ë¡œ íŒŒì•… ê°€ëŠ¥í•´ì•¼ í•¨
5. **Secure**: ë°°í¬ ê³¼ì • ì „ì²´ê°€ ë³´ì•ˆ ê·œì •ì„ ì¤€ìˆ˜í•´ì•¼ í•¨

### MoAI-ADK ë°°í¬ì˜ íŠ¹ì§•

- **SPEC-Driven Deployment**: SPEC ë¬¸ì„œë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•œ ë°°í¬ ê³„íš
- **TAG-Based Tracking**: ë°°í¬ëœ ëª¨ë“  êµ¬ì„±ìš”ì†Œì˜ TAG ì¶”ì 
- **Automated Quality Gates**: ë°°í¬ ì „ ìë™ í’ˆì§ˆ ê²€ì¦
- **Progressive Deployment**: ì ì§„ì  ë°°í¬ ì§€ì›
- **Environment Consistency**: ëª¨ë“  í™˜ê²½ì˜ ì¼ê´€ì„± ë³´ì¥

## ë°°í¬ ì•„í‚¤í…ì²˜

### í˜„ëŒ€ì ì¸ ë°°í¬ ì•„í‚¤í…ì²˜

```mermaid
graph TD
    A[ê°œë°œì] --> B[Git Push]
    B --> C[CI/CD Pipeline]
    C --> D[Build & Test]
    D --> E[Security Scan]
    E --> F[Container Build]
    F --> G[Artifact Registry]
    G --> H[Deployment Strategy]
    H --> I[Staging]
    I --> J[Automated Tests]
    J --> K{Approval?}
    K -->|Yes| L[Production Deployment]
    K -->|No| M[Rollback]
    L --> N[Health Check]
    N --> O[Monitoring]
    O --> P[Alerting]
```

### MoAI-ADK ë°°í¬ ì›Œí¬í”Œë¡œìš°

```mermaid
sequenceDiagram
    participant Dev as ê°œë°œì
    participant Git as Git Repository
    participant CI as CI/CD Pipeline
    participant QA as Quality Gate
    participant Deploy as Deployment System
    participant Prod as Production

    Dev->>Git: /alfred:3-sync
    Git->>CI: Trigger Pipeline
    CI->>CI: Build Application
    CI->>CI: Run Tests (TRUST ê²€ì¦)
    CI->>QA: Quality Gate Check
    QA->>CI: Pass/Fail
    CI->>Deploy: Create Docker Image
    Deploy->>Deploy: Deploy to Staging
    Deploy->>QA: Automated E2E Tests
    QA->>Deploy: Approval
    Deploy->>Prod: Blue-Green Deployment
    Prod->>Deploy: Health Check
    Deploy->>Dev: Deployment Report
```

## Docker ì»¨í…Œì´ë„ˆ ë°°í¬

### ê¸°ë³¸ Dockerfile ì„¤ì •

MoAI-ADK í”„ë¡œì íŠ¸ë¥¼ ìœ„í•œ ìµœì í™”ëœ Dockerfile:

```dockerfile
# Multi-stage build for production optimization
FROM python:3.13-slim as builder

# Set environment variables
ENV PYTHONDONTWRITEBYTECODE=1
ENV PYTHONUNBUFFERED=1
ENV PIP_NO_CACHE_DIR=1
ENV PIP_DISABLE_PIP_VERSION_CHECK=1

# Install system dependencies
RUN apt-get update && apt-get install -y \
    build-essential \
    curl \
    && rm -rf /var/lib/apt/lists/*

# Install uv for fast package management
RUN pip install uv

# Create virtual environment
RUN uv venv /opt/venv
ENV PATH="/opt/venv/bin:$PATH"

# Copy dependency files
COPY pyproject.toml uv.lock ./

# Install dependencies
RUN uv pip install --system -e .

# Production stage
FROM python:3.13-slim as production

# Create non-root user
RUN groupadd -r appuser && useradd -r -g appuser appuser

# Set environment variables
ENV PYTHONDONTWRITEBYTECODE=1
ENV PYTHONUNBUFFERED=1
ENV PATH="/opt/venv/bin:$PATH"

# Install runtime dependencies
RUN apt-get update && apt-get install -y \
    curl \
    && rm -rf /var/lib/apt/lists/*

# Copy virtual environment from builder stage
COPY --from=builder /opt/venv /opt/venv

# Copy application code
WORKDIR /app
COPY src/ ./src/
COPY .moai/ ./.moai/
COPY CLAUDE.md ./

# Set ownership
RUN chown -R appuser:appuser /app
USER appuser

# Health check
HEALTHCHECK --interval=30s --timeout=30s --start-period=5s --retries=3 \
    CMD curl -f http://localhost:8000/health || exit 1

# Expose port
EXPOSE 8000

# Run application
CMD ["uvicorn", "src.main:app", "--host", "0.0.0.0", "--port", "8000"]
```

### Docker Compose ì„¤ì •

#### ê°œë°œ í™˜ê²½ìš© Docker Compose

```yaml
# docker-compose.dev.yml
version: '3.8'

services:
  app:
    build:
      context: .
      dockerfile: Dockerfile
      target: builder
    ports:
      - "8000:8000"
    environment:
      - DEBUG=true
      - DATABASE_URL=postgresql://postgres:password@db:5432/myapp_dev
      - REDIS_URL=redis://redis:6379/0
    volumes:
      - ./src:/app/src
      - ./.moai:/app/.moai
      - ./CLAUDE.md:/app/CLAUDE.md
    depends_on:
      - db
      - redis
    command: uvicorn src.main:app --host 0.0.0.0 --port 8000 --reload

  db:
    image: postgres:15
    environment:
      - POSTGRES_DB=myapp_dev
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=password
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data

  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data

  nginx:
    image: nginx:alpine
    ports:
      - "80:80"
    volumes:
      - ./nginx/dev.conf:/etc/nginx/nginx.conf
    depends_on:
      - app

volumes:
  postgres_data:
  redis_data:
```

#### í”„ë¡œë•ì…˜ í™˜ê²½ìš© Docker Compose

```yaml
# docker-compose.prod.yml
version: '3.8'

services:
  app:
    image: ${REGISTRY}/myapp:${VERSION}
    restart: unless-stopped
    environment:
      - DEBUG=false
      - DATABASE_URL=${DATABASE_URL}
      - REDIS_URL=${REDIS_URL}
      - SECRET_KEY=${SECRET_KEY}
    depends_on:
      - db
      - redis
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    deploy:
      replicas: 3
      resources:
        limits:
          cpus: '1.0'
          memory: 512M
        reservations:
          cpus: '0.5'
          memory: 256M

  db:
    image: postgres:15
    restart: unless-stopped
    environment:
      - POSTGRES_DB=${POSTGRES_DB}
      - POSTGRES_USER=${POSTGRES_USER}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./backups:/backups
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER} -d ${POSTGRES_DB}"]
      interval: 30s
      timeout: 10s
      retries: 3

  redis:
    image: redis:7-alpine
    restart: unless-stopped
    command: redis-server --appendonly yes
    volumes:
      - redis_data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 30s
      timeout: 10s
      retries: 3

  nginx:
    image: nginx:alpine
    restart: unless-stopped
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx/prod.conf:/etc/nginx/nginx.conf
      - ./ssl:/etc/nginx/ssl
    depends_on:
      - app
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost/health"]
      interval: 30s
      timeout: 10s
      retries: 3

volumes:
  postgres_data:
  redis_data:
```

### Kubernetes ë°°í¬ ì„¤ì •

#### ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ë° ConfigMap

```yaml
# k8s/namespace.yaml
apiVersion: v1
kind: Namespace
metadata:
  name: myapp-prod
  labels:
    name: myapp-prod
    environment: production

---
# k8s/configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: myapp-config
  namespace: myapp-prod
data:
  DEBUG: "false"
  LOG_LEVEL: "INFO"
  REDIS_URL: "redis://redis-service:6379/0"
  SPEC_VERSION: "v1.0.0"
  TRUST_LEVEL: "strict"
```

#### Secret ì„¤ì •

```yaml
# k8s/secret.yaml
apiVersion: v1
kind: Secret
metadata:
  name: myapp-secrets
  namespace: myapp-prod
type: Opaque
data:
  DATABASE_URL: <base64-encoded-database-url>
  SECRET_KEY: <base64-encoded-secret-key>
  JWT_SECRET: <base64-encoded-jwt-secret>
```

#### Deployment ì„¤ì •

```yaml
# k8s/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: myapp-deployment
  namespace: myapp-prod
  labels:
    app: myapp
    version: v1.0.0
    spec-id: SPEC-DEPLOY-001
spec:
  replicas: 3
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 1
      maxUnavailable: 0
  selector:
    matchLabels:
      app: myapp
  template:
    metadata:
      labels:
        app: myapp
        version: v1.0.0
        spec-id: SPEC-DEPLOY-001
    spec:
      containers:
      - name: myapp
        image: myregistry.com/myapp:v1.0.0
        ports:
        - containerPort: 8000
        env:
        - name: DATABASE_URL
          valueFrom:
            secretKeyRef:
              name: myapp-secrets
              key: DATABASE_URL
        - name: SECRET_KEY
          valueFrom:
            secretKeyRef:
              name: myapp-secrets
              key: SECRET_KEY
        envFrom:
        - configMapRef:
            name: myapp-config
        resources:
          requests:
            memory: "256Mi"
            cpu: "250m"
          limits:
            memory: "512Mi"
            cpu: "500m"
        livenessProbe:
          httpGet:
            path: /health
            port: 8000
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /ready
            port: 8000
          initialDelaySeconds: 5
          periodSeconds: 5
        lifecycle:
          preStop:
            exec:
              command: ["/bin/sh", "-c", "sleep 15"]
```

#### Service ë° Ingress ì„¤ì •

```yaml
# k8s/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: myapp-service
  namespace: myapp-prod
  labels:
    app: myapp
spec:
  selector:
    app: myapp
  ports:
  - protocol: TCP
    port: 80
    targetPort: 8000
  type: ClusterIP

---
# k8s/ingress.yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: myapp-ingress
  namespace: myapp-prod
  annotations:
    kubernetes.io/ingress.class: nginx
    cert-manager.io/cluster-issuer: letsencrypt-prod
    nginx.ingress.kubernetes.io/rate-limit: "100"
    nginx.ingress.kubernetes.io/rate-limit-window: "1m"
spec:
  tls:
  - hosts:
    - api.myapp.com
    secretName: myapp-tls
  rules:
  - host: api.myapp.com
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: myapp-service
            port:
              number: 80
```

## í´ë¼ìš°ë“œ í”Œë«í¼ ë°°í¬

### AWS ë°°í¬

#### ECS Fargate ì„¤ì •

```json
{
  "family": "myapp-task-definition",
  "networkMode": "awsvpc",
  "requiresCompatibilities": ["FARGATE"],
  "cpu": "512",
  "memory": "1024",
  "executionRoleArn": "arn:aws:iam::ACCOUNT:role/ecsTaskExecutionRole",
  "taskRoleArn": "arn:aws:iam::ACCOUNT:role/ecsTaskRole",
  "containerDefinitions": [
    {
      "name": "myapp",
      "image": "ACCOUNT.dkr.ecr.REGION.amazonaws.com/myapp:v1.0.0",
      "portMappings": [
        {
          "containerPort": 8000,
          "protocol": "tcp"
        }
      ],
      "environment": [
        {
          "name": "DEBUG",
          "value": "false"
        }
      ],
      "secrets": [
        {
          "name": "DATABASE_URL",
          "valueFrom": "arn:aws:secretsmanager:REGION:ACCOUNT:secret:myapp/database-url"
        }
      ],
      "logConfiguration": {
        "logDriver": "awslogs",
        "options": {
          "awslogs-group": "/ecs/myapp",
          "awslogs-region": "us-west-2",
          "awslogs-stream-prefix": "ecs"
        }
      },
      "healthCheck": {
        "command": ["CMD-SHELL", "curl -f http://localhost:8000/health || exit 1"],
        "interval": 30,
        "timeout": 5,
        "retries": 3,
        "startPeriod": 60
      }
    }
  ]
}
```

#### CloudFormation í…œí”Œë¦¿

```yaml
# cloudformation.yml
AWSTemplateFormatVersion: '2010-09-09'
Description: 'MoAI-ADK Application Infrastructure'

Parameters:
  Environment:
    Type: String
    Default: production
    AllowedValues: [development, staging, production]
  Version:
    Type: String
    Default: v1.0.0

Resources:
  VPC:
    Type: AWS::EC2::VPC
    Properties:
      CidrBlock: 10.0.0.0/16
      EnableDnsHostnames: true
      EnableDnsSupport: true
      Tags:
        - Key: Name
          Value: !Sub '${Environment}-myapp-vpc'
        - Key: Project
          Value: myapp
        - Key: SPEC
          Value: SPEC-INFRA-001

  PublicSubnet1:
    Type: AWS::EC2::Subnet
    Properties:
      VpcId: !Ref VPC
      CidrBlock: 10.0.1.0/24
      AvailabilityZone: !Select [0, !GetAZs '']
      MapPublicIpOnLaunch: true
      Tags:
        - Key: Name
          Value: !Sub '${Environment}-public-subnet-1'

  PublicSubnet2:
    Type: AWS::EC2::Subnet
    Properties:
      VpcId: !Ref VPC
      CidrBlock: 10.0.2.0/24
      AvailabilityZone: !Select [1, !GetAZs '']
      MapPublicIpOnLaunch: true
      Tags:
        - Key: Name
          Value: !Sub '${Environment}-public-subnet-2'

  ECSCluster:
    Type: AWS::ECS::Cluster
    Properties:
      ClusterName: !Sub '${Environment}-myapp-cluster'
      CapacityProviders:
        - FARGATE
        - FARGATE_SPOT
      DefaultCapacityProviderStrategy:
        - CapacityProvider: FARGATE
          Weight: 1

  TaskDefinition:
    Type: AWS::ECS::TaskDefinition
    Properties:
      Family: !Sub '${Environment}-myapp'
      Cpu: 512
      Memory: 1024
      NetworkMode: awsvpc
      RequiresCompatibilities:
        - FARGATE
      ExecutionRoleArn: !Ref ECSExecutionRole
      TaskRoleArn: !Ref ECSTaskRole
      ContainerDefinitions:
        - Name: myapp
          Image: !Sub '${AWS::AccountId}.dkr.ecr.${AWS::Region}.amazonaws.com/myapp:${Version}'
          PortMappings:
            - ContainerPort: 8000
          Environment:
            - Name: ENVIRONMENT
              Value: !Ref Environment
          LogConfiguration:
            LogDriver: awslogs
            Options:
              awslogs-group: !Ref CloudWatchLogsGroup
              awslogs-region: !Ref AWS::Region
              awslogs-stream-prefix: ecs

  Service:
    Type: AWS::ECS::Service
    Properties:
      ServiceName: !Sub '${Environment}-myapp-service'
      Cluster: !Ref ECSCluster
      TaskDefinition: !Ref TaskDefinition
      DesiredCount: 2
      LaunchType: FARGATE
      NetworkConfiguration:
        AwsvpcConfiguration:
          SecurityGroups:
            - !Ref SecurityGroup
          Subnets:
            - !Ref PublicSubnet1
            - !Ref PublicSubnet2
          AssignPublicIp: ENABLED
      LoadBalancers:
        - ContainerName: myapp
          ContainerPort: 8000
          TargetGroupArn: !Ref TargetGroup

  LoadBalancer:
    Type: AWS::ElasticLoadBalancingV2::LoadBalancer
    Properties:
      Name: !Sub '${Environment}-myapp-alb'
      Scheme: internet-facing
      Type: application
      Subnets:
        - !Ref PublicSubnet1
        - !Ref PublicSubnet2
      SecurityGroups:
        - !Ref LoadBalancerSecurityGroup

  TargetGroup:
    Type: AWS::ElasticLoadBalancingV2::TargetGroup
    Properties:
      Name: !Sub '${Environment}-myapp-tg'
      Port: 80
      Protocol: HTTP
      VpcId: !Ref VPC
      HealthCheckProtocol: HTTP
      HealthCheckPort: traffic-port
      HealthCheckPath: /health
      Matcher:
        HttpCode: '200'
      TargetType: ip

Outputs:
  LoadBalancerDNS:
    Description: Load Balancer DNS Name
    Value: !GetAtt LoadBalancer.DNSName
    Export:
      Name: !Sub '${Environment}-LoadBalancerDNS'
```

### Google Cloud ë°°í¬

#### Cloud Run ì„¤ì •

```yaml
# cloudrun.yaml
apiVersion: serving.knative.dev/v1
kind: Service
metadata:
  name: myapp
  namespace: production
  annotations:
    run.googleapis.com/ingress: all
    run.googleapis.com/execution-environment: gen2
spec:
  template:
    metadata:
      annotations:
        run.googleapis.com/cpu-throttling: "false"
        run.googleapis.com/memory: "512Mi"
        run.googleapis.com/cpu: "1"
        autoscaling.knative.dev/minScale: "1"
        autoscaling.knative.dev/maxScale: "10"
    spec:
      containerConcurrency: 100
      timeoutSeconds: 300
      containers:
      - image: gcr.io/PROJECT_ID/myapp:v1.0.0
        ports:
        - containerPort: 8000
        env:
        - name: ENVIRONMENT
          value: "production"
        - name: DATABASE_URL
          valueFrom:
            secretKeyRef:
              name: myapp-secrets
              key: database-url
        resources:
          limits:
            cpu: "1"
            memory: "512Mi"
        livenessProbe:
          httpGet:
            path: /health
            port: 8000
          initialDelaySeconds: 10
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /ready
            port: 8000
          initialDelaySeconds: 5
          periodSeconds: 5
```

#### Terraform êµ¬ì„±

```hcl
# main.tf
terraform {
  required_version = ">= 1.0"
  required_providers {
    google = {
      source  = "hashicorp/google"
      version = "~> 4.0"
    }
  }
}

provider "google" {
  project = var.project_id
  region  = var.region
}

# VPC ë„¤íŠ¸ì›Œí¬
resource "google_compute_network" "vpc" {
  name                    = "${var.environment}-myapp-vpc"
  auto_create_subnetworks = false
}

# ì„œë¸Œë„·
resource "google_compute_subnetwork" "subnet" {
  name          = "${var.environment}-myapp-subnet"
  ip_cidr_range = "10.0.0.0/24"
  region        = var.region
  network       = google_compute_network.vpc.id
}

# Cloud Run ì„œë¹„ìŠ¤
resource "google_cloud_run_service" "myapp" {
  name     = "${var.environment}-myapp"
  location = var.region

  template {
    metadata {
      annotations = {
        "run.googleapis.com/ingress"                    = "all"
        "run.googleapis.com/execution-environment"     = "gen2"
        "autoscaling.knative.dev/minScale"             = "1"
        "autoscaling.knative.dev/maxScale"             = "10"
      }
    }

    spec {
      container_concurrency = 100
      timeout_seconds        = 300

      containers {
        image = "gcr.io/${var.project_id}/myapp:${var.version}"

        ports {
          container_port = 8000
        }

        env {
          name  = "ENVIRONMENT"
          value = var.environment
        }

        env {
          name = "DATABASE_URL"
          value_from {
            secret_key_ref {
              name = google_secret_manager_secret_version.db_url.secret_id
              key  = "latest"
            }
          }
        }

        resources {
          limits = {
            cpu    = "1"
            memory = "512Mi"
          }
        }

        liveness_probe {
          http_get {
            path = "/health"
            port = 8000
          }
          initial_delay_seconds = 10
          period_seconds        = 10
        }

        readiness_probe {
          http_get {
            path = "/ready"
            port = 8000
          }
          initial_delay_seconds = 5
          period_seconds        = 5
        }
      }
    }
  }

  traffic {
    percent         = 100
    latest_revision = true
  }
}

# IAM ì •ì±…
resource "google_cloud_run_service_iam_member" "public" {
  location = google_cloud_run_service.myapp.location
  project  = google_cloud_run_service.myapp.project
  service  = google_cloud_run_service.myapp.name
  role     = "roles/run.invoker"
  member   = "allUsers"
}

# Secret Manager
resource "google_secret_manager_secret" "db_url" {
  provider = google-beta
  secret_id = "${var.environment}-myapp-db-url"

  replication {
    automatic = true
  }
}

resource "google_secret_manager_secret_version" "db_url" {
  secret      = google_secret_manager_secret.db_url.id
  secret_data = var.database_url
}
```

### Azure ë°°í¬

#### ARM í…œí”Œë¦¿

```json
{
  "$schema": "https://schema.management.azure.com/schemas/2019-04-01/deploymentTemplate.json#",
  "contentVersion": "1.0.0.0",
  "parameters": {
    "environment": {
      "type": "string",
      "defaultValue": "production",
      "allowedValues": ["development", "staging", "production"]
    },
    "version": {
      "type": "string",
      "defaultValue": "v1.0.0"
    }
  },
  "resources": [
    {
      "type": "Microsoft.ContainerInstance/containerGroups",
      "apiVersion": "2021-09-01",
      "name": "[concat(parameters('environment'), '-myapp-container-group')]",
      "location": "[resourceGroup().location]",
      "properties": {
        "containers": [
          {
            "name": "myapp",
            "properties": {
              "image": "[concat('.acr.io/myapp:', parameters('version'))]",
              "ports": [
                {
                  "port": 8000,
                  "protocol": "TCP"
                }
              ],
              "environmentVariables": [
                {
                  "name": "ENVIRONMENT",
                  "value": "[parameters('environment')]"
                },
                {
                  "name": "DATABASE_URL",
                  "secureValue": "[reference(resourceId('Microsoft.KeyVault/vaults/secrets', 'myapp-kv', 'database-url'), '2021-06-01-preview').value]"
                }
              ],
              "resources": {
                "requests": {
                  "cpu": 1.0,
                  "memoryInGB": 1.0
                }
              },
              "livenessProbe": {
                "exec": {
                  "command": [
                    "/bin/sh",
                    "-c",
                    "curl -f http://localhost:8000/health || exit 1"
                  ]
                },
                "periodSeconds": 30,
                "timeoutSeconds": 10,
                "failureThreshold": 3
              }
            }
          }
        ],
        "osType": "Linux",
        "restartPolicy": "Always",
        "ipAddress": {
          "type": "Public",
          "ports": [
            {
              "port": 8000,
              "protocol": "TCP"
            }
          ]
        }
      }
    }
  ],
  "outputs": {
    "containerGroupIP": {
      "type": "string",
      "value": "[reference(resourceId('Microsoft.ContainerInstance/containerGroups', concat(parameters('environment'), '-myapp-container-group')), '2021-09-01').ipAddress.ip]"
    }
  }
}
```

## CI/CD íŒŒì´í”„ë¼ì¸ êµ¬ì¶•

### GitHub Actions ì›Œí¬í”Œë¡œìš°

#### ë©”ì¸ CI/CD íŒŒì´í”„ë¼ì¸

```yaml
# .github/workflows/deploy.yml
name: Deploy Application

on:
  push:
    branches: [main, develop]
  pull_request:
    branches: [main]

env:
  REGISTRY: ghcr.io
  IMAGE_NAME: ${{ github.repository }}

jobs:
  # ì½”ë“œ í’ˆì§ˆ ë° ë³´ì•ˆ ê²€ì‚¬
  quality-check:
    runs-on: ubuntu-latest
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.13'

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install -r requirements-dev.txt

    - name: Run linting
      run: |
        ruff check src/
        ruff format --check src/

    - name: Run type checking
      run: mypy src/

    - name: Run security scan
      run: |
        bandit -r src/
        safety check

    - name: Run tests
      run: |
        pytest tests/ --cov=src/ --cov-report=xml

    - name: Upload coverage
      uses: codecov/codecov-action@v3
      with:
        file: ./coverage.xml

  # Docker ì´ë¯¸ì§€ ë¹Œë“œ
  build-image:
    needs: quality-check
    runs-on: ubuntu-latest
    permissions:
      contents: read
      packages: write
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Docker Buildx
      uses: docker/setup-buildx-action@v3

    - name: Log in to Container Registry
      uses: docker/login-action@v3
      with:
        registry: ${{ env.REGISTRY }}
        username: ${{ github.actor }}
        password: ${{ secrets.GITHUB_TOKEN }}

    - name: Extract metadata
      id: meta
      uses: docker/metadata-action@v5
      with:
        images: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}
        tags: |
          type=ref,event=branch
          type=ref,event=pr
          type=sha,prefix={{branch}}-
          type=raw,value=latest,enable={{is_default_branch}}

    - name: Build and push Docker image
      uses: docker/build-push-action@v5
      with:
        context: .
        push: true
        tags: ${{ steps.meta.outputs.tags }}
        labels: ${{ steps.meta.outputs.labels }}
        cache-from: type=gha
        cache-to: type=gha,mode=max

  # Staging í™˜ê²½ ë°°í¬
  deploy-staging:
    needs: build-image
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/develop'
    environment: staging
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: us-west-2

    - name: Deploy to ECS Staging
      run: |
        aws ecs update-service \
          --cluster myapp-staging-cluster \
          --service myapp-staging-service \
          --force-new-deployment

    - name: Wait for deployment
      run: |
        aws ecs wait services-stable \
          --cluster myapp-staging-cluster \
          --services myapp-staging-service

    - name: Run smoke tests
      run: |
        chmod +x ./scripts/smoke-tests.sh
        ./scripts/smoke-tests.sh staging

  # í”„ë¡œë•ì…˜ í™˜ê²½ ë°°í¬
  deploy-production:
    needs: build-image
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main'
    environment: production
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: us-west-2

    - name: Deploy to ECS Production
      run: |
        aws ecs update-service \
          --cluster myapp-production-cluster \
          --service myapp-production-service \
          --force-new-deployment

    - name: Wait for deployment
      run: |
        aws ecs wait services-stable \
          --cluster myapp-production-cluster \
          --services myapp-production-service

    - name: Run health checks
      run: |
        chmod +x ./scripts/health-checks.sh
        ./scripts/health-checks.sh production

    - name: Notify deployment
      uses: 8398a7/action-slack@v3
      with:
        status: ${{ job.status }}
        channel: '#deployments'
        webhook_url: ${{ secrets.SLACK_WEBHOOK }}
```

#### Blue-Green ë°°í¬ ì›Œí¬í”Œë¡œìš°

```yaml
# .github/workflows/blue-green-deploy.yml
name: Blue-Green Deployment

on:
  workflow_dispatch:
    inputs:
      environment:
        description: 'Target environment'
        required: true
        default: 'staging'
        type: choice
        options:
        - staging
        - production
      version:
        description: 'Application version'
        required: true
        default: 'latest'

env:
  CLUSTER_NAME: myapp-cluster
  SERVICE_NAME: myapp-service

jobs:
  deploy:
    runs-on: ubuntu-latest
    environment: ${{ github.event.inputs.environment }}
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: us-west-2

    - name: Get current task definition
      id: current-task
      run: |
        TASK_DEF=$(aws ecs describe-services \
          --cluster ${{ env.CLUSTER_NAME }} \
          --services ${{ env.SERVICE_NAME }} \
          --query 'services[0].taskDefinition' \
          --output text)
        echo "task-definition=$TASK_DEF" >> $GITHUB_OUTPUT

    - name: Create new task definition
      id: new-task
      run: |
        # Create new task definition with new image version
        NEW_TASK_DEF=$(aws ecs register-task-definition \
          --cli-input-json "$(cat task-definition.json | \
          jq '.containerDefinitions[0].image = "${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:${{ github.event.inputs.version }}"')" \
          --query 'taskDefinition.taskDefinitionArn' \
          --output text)
        echo "task-definition=$NEW_TASK_DEF" >> $GITHUB_OUTPUT

    - name: Update service with new task definition
      run: |
        aws ecs update-service \
          --cluster ${{ env.CLUSTER_NAME }} \
          --service ${{ env.SERVICE_NAME }} \
          --task-definition ${{ steps.new-task.outputs.task-definition }} \
          --force-new-deployment

    - name: Wait for new tasks to start
      run: |
        aws ecs wait services-stable \
          --cluster ${{ env.CLUSTER_NAME }} \
          --services ${{ env.SERVICE_NAME }}

    - name: Run smoke tests
      run: |
        chmod +x ./scripts/smoke-tests.sh
        ./scripts/smoke-tests.sh ${{ github.event.inputs.environment }}

    - name: Update DNS to point to new version
      if: success()
      run: |
        # Update Route53 or load balancer target
        ./scripts/update-dns.sh ${{ github.event.inputs.environment }} new

    - name: Rollback on failure
      if: failure()
      run: |
        aws ecs update-service \
          --cluster ${{ env.CLUSTER_NAME }} \
          --service ${{ env.SERVICE_NAME }} \
          --task-definition ${{ steps.current-task.outputs.task-definition }} \
          --force-new-deployment

        aws ecs wait services-stable \
          --cluster ${{ env.CLUSTER_NAME }} \
          --services ${{ env.SERVICE_NAME }}

        ./scripts/update-dns.sh ${{ github.event.inputs.environment }} old
```

### GitLab CI/CD ì„¤ì •

```yaml
# .gitlab-ci.yml
stages:
  - validate
  - test
  - build
  - deploy-staging
  - deploy-production

variables:
  DOCKER_DRIVER: overlay2
  DOCKER_TLS_CERTDIR: "/certs"

# ì½”ë“œ í’ˆì§ˆ ê²€ì¦
validate:
  stage: validate
  image: python:3.13
  before_script:
    - pip install -r requirements-dev.txt
  script:
    - ruff check src/
    - ruff format --check src/
    - mypy src/
  artifacts:
    reports:
      junit: reports/junit.xml
    paths:
      - reports/
    expire_in: 1 week

# í…ŒìŠ¤íŠ¸ ì‹¤í–‰
test:
  stage: test
  image: python:3.13
  services:
    - postgres:15
    - redis:7
  variables:
    POSTGRES_DB: test_db
    POSTGRES_USER: test_user
    POSTGRES_PASSWORD: test_pass
    DATABASE_URL: postgresql://test_user:test_pass@postgres:5432/test_db
    REDIS_URL: redis://redis:6379/0
  before_script:
    - pip install -r requirements.txt
    - pip install -r requirements-dev.txt
  script:
    - pytest tests/ --cov=src/ --cov-report=xml --cov-report=html --junitxml=reports/junit.xml
  coverage: '/TOTAL.+?(\d+\%)$/'
  artifacts:
    reports:
      junit: reports/junit.xml
      coverage_report:
        coverage_format: cobertura
        path: coverage.xml
    paths:
      - htmlcov/
      - coverage.xml
    expire_in: 1 week

# Docker ì´ë¯¸ì§€ ë¹Œë“œ
build:
  stage: build
  image: docker:24.0.5
  services:
    - docker:24.0.5-dind
  before_script:
    - echo $CI_REGISTRY_PASSWORD | docker login -u $CI_REGISTRY_USER --password-stdin $CI_REGISTRY
  script:
    - docker build -t $CI_REGISTRY_IMAGE:$CI_COMMIT_SHA .
    - docker build -t $CI_REGISTRY_IMAGE:latest .
    - docker push $CI_REGISTRY_IMAGE:$CI_COMMIT_SHA
    - docker push $CI_REGISTRY_IMAGE:latest
  only:
    - main
    - develop

# Staging í™˜ê²½ ë°°í¬
deploy-staging:
  stage: deploy-staging
  image: alpine:latest
  before_script:
    - apk add --no-cache curl
    - curl -L https://github.com/aws/aws-cli/releases/download/v2.13.25/awscliv2.zip -o awscliv2.zip
    - unzip awscliv2.zip
    - ./aws/install
  script:
    - aws ecs update-service --cluster myapp-staging --service myapp-service --force-new-deployment
    - aws ecs wait services-stable --cluster myapp-staging --services myapp-service
  environment:
    name: staging
    url: https://staging-api.myapp.com
  only:
    - develop

# í”„ë¡œë•ì…˜ í™˜ê²½ ë°°í¬
deploy-production:
  stage: deploy-production
  image: alpine:latest
  before_script:
    - apk add --no-cache curl
    - curl -L https://github.com/aws/aws-cli/releases/download/v2.13.25/awscliv2.zip -o awscliv2.zip
    - unzip awscliv2.zip
    - ./aws/install
  script:
    - aws ecs update-service --cluster myapp-production --service myapp-service --force-new-deployment
    - aws ecs wait services-stable --cluster myapp-production --services myapp-service
  environment:
    name: production
    url: https://api.myapp.com
  when: manual
  only:
    - main
```

## í™˜ê²½ë³„ ë°°í¬ ì „ëµ

### ê°œë°œ í™˜ê²½ (Development)

#### ëª©ì  ë° íŠ¹ì§•
- **ëª©ì **: ê°œë°œì ë¹ ë¥¸ í”¼ë“œë°± ë£¨í”„
- **íŠ¹ì§•**: ë¹ ë¥¸ ë°°í¬, ìë™ ì¬ì‹œì‘, ìƒì„¸ ë¡œê¹…

#### ì„¤ì • ì˜ˆì‹œ

```yaml
# docker-compose.dev.yml
version: '3.8'

services:
  app:
    build:
      context: .
      dockerfile: Dockerfile.dev
    ports:
      - "8000:8000"
    environment:
      - DEBUG=true
      - LOG_LEVEL=DEBUG
      - RELOAD=true
    volumes:
      - ./src:/app/src
      - ./.moai:/app/.moai
    depends_on:
      - db
      - redis
    command: uvicorn src.main:app --host 0.0.0.0 --port 8000 --reload

  db:
    image: postgres:15
    environment:
      - POSTGRES_DB=myapp_dev
      - POSTGRES_USER=dev
      - POSTGRES_PASSWORD=dev123
    ports:
      - "5432:5432"
    volumes:
      - postgres_dev_data:/var/lib/postgresql/data

  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"

  # ê°œë°œ ë„êµ¬ë“¤
  adminer:
    image: adminer
    ports:
      - "8080:8080"
    depends_on:
      - db

  redis-commander:
    image: rediscommander/redis-commander:latest
    environment:
      - REDIS_HOSTS=local:redis:6379
    ports:
      - "8081:8081"
    depends_on:
      - redis

volumes:
  postgres_dev_data:
```

#### ê°œë°œ í™˜ê²½ ë°°í¬ ìŠ¤í¬ë¦½íŠ¸

```bash
#!/bin/bash
# scripts/deploy-dev.sh

set -e

echo "<span class="material-icons">rocket_launch</span> Deploying to development environment..."

# í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
export COMPOSE_PROJECT_NAME="myapp-dev"
export COMPOSE_FILE="docker-compose.dev.yml"

# ê¸°ì¡´ ì»¨í…Œì´ë„ˆ ì •ë¦¬
echo "ğŸ§¹ Cleaning up existing containers..."
docker-compose down --remove-orphans

# ìµœì‹  ì´ë¯¸ì§€ ë¹Œë“œ
echo "ğŸ”¨ Building development images..."
docker-compose build

# ë°ì´í„°ë² ì´ìŠ¤ ë§ˆì´ê·¸ë ˆì´ì…˜
echo "<span class="material-icons">analytics</span> Running database migrations..."
docker-compose run --rm app alembic upgrade head

# ì„œë¹„ìŠ¤ ì‹œì‘
echo "<span class="material-icons">rocket_launch</span> Starting development services..."
docker-compose up -d

# ìƒíƒœ í™•ì¸
echo "ğŸ“‹ Checking service status..."
sleep 10
docker-compose ps

# ìƒíƒœ ê²€ì‚¬
echo "<span class="material-icons">search</span> Running health checks..."
./scripts/health-checks.sh dev

echo "<span class="material-icons">check_circle</span> Development environment deployed successfully!"
echo "<span class="material-icons">analytics</span> App available at: http://localhost:8000"
echo "<span class="material-icons">storage</span>  Database available at: localhost:5432"
echo "<span class="material-icons">settings</span> Redis available at: localhost:6379"
echo "ğŸ›ï¸  Adminer available at: http://localhost:8080"
echo "ğŸ“± Redis Commander available at: http://localhost:8081"
```

### ìŠ¤í…Œì´ì§• í™˜ê²½ (Staging)

#### ëª©ì  ë° íŠ¹ì§•
- **ëª©ì **: í”„ë¡œë•ì…˜ ì „ ìµœì¢… ê²€ì¦
- **íŠ¹ì§•**: í”„ë¡œë•ì…˜ê³¼ ìœ ì‚¬í•œ í™˜ê²½, ìë™í™”ëœ í…ŒìŠ¤íŠ¸

#### ì„¤ì • ì˜ˆì‹œ

```yaml
# docker-compose.staging.yml
version: '3.8'

services:
  app:
    image: ${REGISTRY}/myapp:${VERSION}
    restart: unless-stopped
    environment:
      - DEBUG=false
      - LOG_LEVEL=INFO
      - ENVIRONMENT=staging
      - DATABASE_URL=${DATABASE_URL}
      - REDIS_URL=${REDIS_URL}
      - SECRET_KEY=${SECRET_KEY}
    depends_on:
      - db
      - redis
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  db:
    image: postgres:15
    restart: unless-stopped
    environment:
      - POSTGRES_DB=${POSTGRES_DB}
      - POSTGRES_USER=${POSTGRES_USER}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
    volumes:
      - postgres_staging_data:/var/lib/postgresql/data
      - ./backups:/backups
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER}"]
      interval: 30s
      timeout: 10s
      retries: 3

  redis:
    image: redis:7-alpine
    restart: unless-stopped
    command: redis-server --appendonly yes
    volumes:
      - redis_staging_data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 30s
      timeout: 10s
      retries: 3

  nginx:
    image: nginx:alpine
    restart: unless-stopped
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx/staging.conf:/etc/nginx/nginx.conf
      - ./ssl/staging:/etc/nginx/ssl
    depends_on:
      - app
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  # ëª¨ë‹ˆí„°ë§
  prometheus:
    image: prom/prometheus:latest
    restart: unless-stopped
    ports:
      - "9090:9090"
    volumes:
      - ./monitoring/prometheus-staging.yml:/etc/prometheus/prometheus.yml
      - prometheus_staging_data:/prometheus

  grafana:
    image: grafana/grafana:latest
    restart: unless-stopped
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_PASSWORD}
    volumes:
      - grafana_staging_data:/var/lib/grafana
      - ./monitoring/grafana/dashboards:/etc/grafana/provisioning/dashboards

volumes:
  postgres_staging_data:
  redis_staging_data:
  prometheus_staging_data:
  grafana_staging_data:
```

#### ìŠ¤í…Œì´ì§• ë°°í¬ ìŠ¤í¬ë¦½íŠ¸

```bash
#!/bin/bash
# scripts/deploy-staging.sh

set -e

VERSION=${1:-latest}
ENVIRONMENT="staging"

echo "<span class="material-icons">rocket_launch</span> Deploying version $VERSION to staging environment..."

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
source .env.staging

# ì´ë¯¸ì§€ í’€
echo "ğŸ“¦ Pulling application image..."
docker pull ${REGISTRY}/myapp:${VERSION}

# ë°ì´í„°ë² ì´ìŠ¤ ë°±ì—…
echo "ğŸ’¾ Creating database backup..."
./scripts/backup-db.sh $ENVIRONMENT

# ë¸”ë£¨-ê·¸ë¦° ë°°í¬
echo "ğŸ”„ Starting blue-green deployment..."

# í˜„ì¬ ì‹¤í–‰ ì¤‘ì¸ ì„œë¹„ìŠ¤ í™•ì¸
CURRENT_SERVICE=$(docker-compose -f docker-compose.staging.yml ps -q app)

if [ -n "$CURRENT_SERVICE" ]; then
    echo "ğŸ“‹ Current service found: $CURRENT_SERVICE"

    # ìƒˆ ì„œë¹„ìŠ¤ ì‹œì‘ (green)
    echo "ğŸŒ± Starting new service (green)..."
    VERSION=$VERSION docker-compose -f docker-compose.staging.yml up -d app

    # ìƒíƒœ ê²€ì‚¬
    echo "<span class="material-icons">search</span> Running health checks on new service..."
    ./scripts/wait-for-health.sh http://staging-api.myapp.com/health

    # ìŠ¤ëª¨í¬ í…ŒìŠ¤íŠ¸
    echo "ğŸ§ª Running smoke tests..."
    ./scripts/smoke-tests.sh $ENVIRONMENT

    # íŠ¸ë˜í”½ ì „í™˜
    echo "ğŸ”„ Switching traffic to new service..."
    ./scripts/switch-traffic.sh $ENVIRONMENT new

    # ì´ì „ ì„œë¹„ìŠ¤ ì •ë¦¬
    echo "ğŸ§¹ Cleaning up old service (blue)..."
    docker-compose -f docker-compose.staging.yml stop app
else
    echo "ğŸŒ± Starting initial service..."
    VERSION=$VERSION docker-compose -f docker-compose.staging.yml up -d
fi

# ë°°í¬ í™•ì¸
echo "<span class="material-icons">check_circle</span> Deployment completed successfully!"
echo "<span class="material-icons">language</span> Application available at: https://staging-api.myapp.com"
echo "<span class="material-icons">analytics</span> Monitoring available at: https://staging-grafana.myapp.com"

# ì•Œë¦¼ ë°œì†¡
./scripts/notify-deployment.sh $ENVIRONMENT $VERSION success
```

### í”„ë¡œë•ì…˜ í™˜ê²½ (Production)

#### ëª©ì  ë° íŠ¹ì§•
- **ëª©ì **: ì‹¤ì œ ì„œë¹„ìŠ¤ ìš´ì˜
- **íŠ¹ì§•**: ê³ ê°€ìš©ì„±, ëª¨ë‹ˆí„°ë§, ë³´ì•ˆ, ë¡¤ë°± ì¤€ë¹„

#### ì„¤ì • ì˜ˆì‹œ

```yaml
# docker-compose.prod.yml
version: '3.8'

services:
  app:
    image: ${REGISTRY}/myapp:${VERSION}
    restart: unless-stopped
    environment:
      - DEBUG=false
      - LOG_LEVEL=WARNING
      - ENVIRONMENT=production
      - DATABASE_URL=${DATABASE_URL}
      - REDIS_URL=${REDIS_URL}
      - SECRET_KEY=${SECRET_KEY}
      - SENTRY_DSN=${SENTRY_DSN}
    depends_on:
      - db
      - redis
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    deploy:
      replicas: 3
      resources:
        limits:
          cpus: '1.0'
          memory: 1G
        reservations:
          cpus: '0.5'
          memory: 512M
      restart_policy:
        condition: on-failure
        delay: 5s
        max_attempts: 3
        window: 120s

  # ë¡œë“œ ë°¸ëŸ°ì„œ ë° ë¦¬ë²„ìŠ¤ í”„ë¡ì‹œ
  nginx:
    image: nginx:alpine
    restart: unless-stopped
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx/prod.conf:/etc/nginx/nginx.conf
      - ./ssl/prod:/etc/nginx/ssl
      - ./logs/nginx:/var/log/nginx
    depends_on:
      - app
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 256M

  # ë°ì´í„°ë² ì´ìŠ¤ (PostgreSQL)
  db:
    image: postgres:15
    restart: unless-stopped
    environment:
      - POSTGRES_DB=${POSTGRES_DB}
      - POSTGRES_USER=${POSTGRES_USER}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
    volumes:
      - postgres_prod_data:/var/lib/postgresql/data
      - ./backups:/backups
      - ./postgresql/postgresql.conf:/etc/postgresql/postgresql.conf
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER}"]
      interval: 30s
      timeout: 10s
      retries: 3
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 4G
        reservations:
          cpus: '1.0'
          memory: 2G

  # Redis (ìºì‹œ ë° ì„¸ì…˜)
  redis:
    image: redis:7-alpine
    restart: unless-stopped
    command: redis-server /usr/local/etc/redis/redis.conf
    volumes:
      - redis_prod_data:/data
      - ./redis/redis.conf:/usr/local/etc/redis/redis.conf
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 30s
      timeout: 10s
      retries: 3
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M

  # ëª¨ë‹ˆí„°ë§ ìŠ¤íƒ
  prometheus:
    image: prom/prometheus:latest
    restart: unless-stopped
    ports:
      - "9090:9090"
    volumes:
      - ./monitoring/prometheus-prod.yml:/etc/prometheus/prometheus.yml
      - prometheus_prod_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--storage.tsdb.retention.time=30d'
      - '--web.enable-lifecycle'

  grafana:
    image: grafana/grafana:latest
    restart: unless-stopped
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_PASSWORD}
      - GF_INSTALL_PLUGINS=grafana-piechart-panel
    volumes:
      - grafana_prod_data:/var/lib/grafana
      - ./monitoring/grafana/dashboards:/etc/grafana/provisioning/dashboards
      - ./monitoring/grafana/datasources:/etc/grafana/provisioning/datasources

  # ë¡œê·¸ ìˆ˜ì§‘
  loki:
    image: grafana/loki:latest
    restart: unless-stopped
    ports:
      - "3100:3100"
    volumes:
      - ./monitoring/loki-config.yml:/etc/loki/local-config.yaml
      - loki_prod_data:/loki
    command: -config.file=/etc/loki/local-config.yaml

  promtail:
    image: grafana/promtail:latest
    restart: unless-stopped
    volumes:
      - ./monitoring/promtail-config.yml:/etc/promtail/config.yml
      - ./logs:/var/log/app
    command: -config.file=/etc/promtail/config.yml

volumes:
  postgres_prod_data:
  redis_prod_data:
  prometheus_prod_data:
  grafana_prod_data:
  loki_prod_data:
```

## ë¡¤ì•„ì›ƒ ì „ëµ

### Blue-Green ë°°í¬

Blue-Green ë°°í¬ëŠ” ë‘ ê°œì˜ ë™ì¼í•œ í™˜ê²½ì„ ìœ ì§€í•˜ë©° íŠ¸ë˜í”½ì„ ì „í™˜í•˜ëŠ” ë°©ì‹ì…ë‹ˆë‹¤.

#### Blue-Green ë°°í¬ íë¦„

```mermaid
graph TD
    A[í˜„ì¬ Blue í™˜ê²½] --> B[Green í™˜ê²½ êµ¬ì¶•]
    B --> C[Green í™˜ê²½ í…ŒìŠ¤íŠ¸]
    C --> D{í…ŒìŠ¤íŠ¸ í†µê³¼?}
    D -->|Yes| E[íŠ¸ë˜í”½ì„ Greenìœ¼ë¡œ ì „í™˜]
    D -->|No| F[Green í™˜ê²½ íê¸°]
    E --> G[Blue í™˜ê²½ ëŒ€ê¸°]
    G --> H[ë¬¸ì œ ë°œìƒ ì‹œ]
    H --> I[íŠ¸ë˜í”½ì„ Blueë¡œ ë¡¤ë°±]
    E --> J[Greenì„ ìƒˆë¡œìš´ Blueë¡œ]
    F --> A
    I --> A
    J --> A
```

#### Blue-Green ë°°í¬ ìŠ¤í¬ë¦½íŠ¸

```bash
#!/bin/bash
# scripts/blue-green-deploy.sh

set -e

VERSION=${1:-latest}
ENVIRONMENT=${2:-staging}

echo "ğŸ”„ Starting Blue-Green deployment of version $VERSION to $ENVIRONMENT"

# ì„¤ì • ë¡œë“œ
source .env.$ENVIRONMENT

# í˜„ì¬ í™œì„± í™˜ê²½ í™•ì¸
CURRENT_ENV=$(curl -s https://api.myapp.com/info | jq -r '.environment')
echo "ğŸ“‹ Current active environment: $CURRENT_ENV"

if [ "$CURRENT_ENV" = "blue" ]; then
    NEW_ENV="green"
    OLD_ENV="blue"
else
    NEW_ENV="blue"
    OLD_ENV="green"
fi

echo "ğŸŒ± Deploying to $NEW_ENV environment"

# ìƒˆ í™˜ê²½ ì„¤ì • ì—…ë°ì´íŠ¸
sed -i "s/ENVIRONMENT=.*/ENVIRONMENT=$NEW_ENV/" .env.$ENVIRONMENT
sed -i "s/VERSION=.*/VERSION=$VERSION/" .env.$ENVIRONMENT

# ìƒˆ í™˜ê²½ ë°°í¬
echo "<span class="material-icons">rocket_launch</span> Starting $NEW_ENV environment..."
docker-compose -f docker-compose.$ENVIRONMENT.yml up -d

# ìƒíƒœ ê²€ì‚¬ ëŒ€ê¸°
echo "â³ Waiting for $NEW_ENV to be healthy..."
./scripts/wait-for-health.sh https://$NEW_ENV-api.myapp.com/health

# ìŠ¤ëª¨í¬ í…ŒìŠ¤íŠ¸
echo "ğŸ§ª Running smoke tests on $NEW_ENV..."
./scripts/smoke-tests.sh $NEW_ENV

# íŠ¸ë˜í”½ ì „í™˜
echo "ğŸ”„ Switching traffic to $NEW_ENV..."
./scripts/switch-traffic.sh $ENVIRONMENT $NEW_ENV

# íŠ¸ë˜í”½ ì „í™˜ í™•ì¸
echo "<span class="material-icons">check_circle</span> Traffic switched to $NEW_ENV"
sleep 30

# ìµœì¢… ìƒíƒœ ê²€ì‚¬
echo "<span class="material-icons">search</span> Final health check..."
curl -f https://api.myapp.com/health || {
    echo "<span class="material-icons">cancel</span> Health check failed, rolling back..."
    ./scripts/switch-traffic.sh $ENVIRONMENT $OLD_ENV
    exit 1
}

# ì´ì „ í™˜ê²½ ì •ë¦¬ (ì„ íƒì )
echo "ğŸ§¹ Cleaning up $OLD_ENV environment..."
docker-compose -f docker-compose.$ENVIRONMENT.yml stop

echo "<span class="material-icons">check_circle</span> Blue-Green deployment completed successfully!"
echo "<span class="material-icons">language</span> Application running on: https://api.myapp.com"
echo "<span class="material-icons">analytics</span> Environment: $NEW_ENV"
```

### Canary ë°°í¬

Canary ë°°í¬ëŠ” ì ì§„ì ìœ¼ë¡œ ìƒˆ ë²„ì „ì„ ì¼ë¶€ ì‚¬ìš©ìì—ê²Œë§Œ ë…¸ì¶œí•˜ëŠ” ë°©ì‹ì…ë‹ˆë‹¤.

#### Canary ë°°í¬ íë¦„

```mermaid
graph TD
    A[í˜„ì¬ ë²„ì „ 100%] --> B[Canary 5% ë°°í¬]
    B --> C[ëª¨ë‹ˆí„°ë§]
    C --> D{ìƒíƒœ ì–‘í˜¸?}
    D -->|Yes| E[Canary 25%]
    D -->|No| F[ë¡¤ë°±]
    E --> G[ëª¨ë‹ˆí„°ë§]
    G --> H{ìƒíƒœ ì–‘í˜¸?}
    H -->|Yes| I[Canary 50%]
    H -->|No| F
    I --> J[ëª¨ë‹ˆí„°ë§]
    J --> K{ìƒíƒœ ì–‘í˜¸?}
    K -->|Yes| L[ì „ì²´ ë°°í¬ 100%]
    K -->|No| F
    F --> A
    L --> M[Canary ì œê±°]
```

#### Canary ë°°í¬ ì„¤ì •

```yaml
# k8s/canary-deployment.yaml
apiVersion: argoproj.io/v1alpha1
kind: Rollout
metadata:
  name: myapp-canary
  namespace: production
spec:
  replicas: 5
  strategy:
    canary:
      steps:
      - setWeight: 5
      - pause: {duration: 5m}
      - setWeight: 25
      - pause: {duration: 10m}
      - setWeight: 50
      - pause: {duration: 15m}
      - setWeight: 75
      - pause: {duration: 20m}
      canaryService: myapp-canary
      stableService: myapp-stable
      trafficRouting:
        istio:
          virtualService:
            name: myapp-vsvc
            routes:
            - primary
  selector:
    matchLabels:
      app: myapp
      version: canary
  template:
    metadata:
      labels:
        app: myapp
        version: canary
    spec:
      containers:
      - name: myapp
        image: myregistry.com/myapp:${CANARY_VERSION}
        ports:
        - containerPort: 8000
        env:
        - name: VERSION
          value: "${CANARY_VERSION}"
        - name: ENVIRONMENT
          value: "production"
        livenessProbe:
          httpGet:
            path: /health
            port: 8000
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /ready
            port: 8000
          initialDelaySeconds: 5
          periodSeconds: 5
        resources:
          requests:
            memory: "256Mi"
            cpu: "250m"
          limits:
            memory: "512Mi"
            cpu: "500m"
```

### Rolling ë°°í¬

Rolling ë°°í¬ëŠ” ì ì§„ì ìœ¼ë¡œ ì¸ìŠ¤í„´ìŠ¤ë¥¼ êµì²´í•˜ëŠ” ê°€ì¥ ì¼ë°˜ì ì¸ ë°°í¬ ë°©ì‹ì…ë‹ˆë‹¤.

#### Rolling ë°°í¬ ì„¤ì •

```yaml
# k8s/rolling-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: myapp-rolling
  namespace: production
spec:
  replicas: 5
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 1        # í•œ ë²ˆì— ì¶”ê°€ë˜ëŠ” ìµœëŒ€ Pod ìˆ˜
      maxUnavailable: 0  # í•œ ë²ˆì— ì¤‘ì§€ë˜ëŠ” ìµœëŒ€ Pod ìˆ˜
  selector:
    matchLabels:
      app: myapp
      deployment: rolling
  template:
    metadata:
      labels:
        app: myapp
        deployment: rolling
        version: v1.0.0
    spec:
      containers:
      - name: myapp
        image: myregistry.com/myapp:v1.0.0
        ports:
        - containerPort: 8000
        env:
        - name: ENVIRONMENT
          value: "production"
        livenessProbe:
          httpGet:
            path: /health
            port: 8000
          initialDelaySeconds: 30
          periodSeconds: 10
          timeoutSeconds: 5
          successThreshold: 1
          failureThreshold: 3
        readinessProbe:
          httpGet:
            path: /ready
            port: 8000
          initialDelaySeconds: 5
          periodSeconds: 5
          timeoutSeconds: 3
          successThreshold: 1
          failureThreshold: 3
        lifecycle:
          preStop:
            exec:
              command: ["/bin/sh", "-c", "sleep 15"]
        resources:
          requests:
            memory: "256Mi"
            cpu: "250m"
          limits:
            memory: "512Mi"
            cpu: "500m"
      terminationGracePeriodSeconds: 30
```

## ëª¨ë‹ˆí„°ë§ê³¼ ë¡œê¹…

### Prometheus ëª¨ë‹ˆí„°ë§ ì„¤ì •

```yaml
# monitoring/prometheus.yml
global:
  scrape_interval: 15s
  evaluation_interval: 15s

rule_files:
  - "alert_rules.yml"

scrape_configs:
  - job_name: 'myapp'
    static_configs:
      - targets: ['app:8000']
    metrics_path: '/metrics'
    scrape_interval: 5s

  - job_name: 'nginx'
    static_configs:
      - targets: ['nginx:9113']

  - job_name: 'postgres'
    static_configs:
      - targets: ['postgres-exporter:9187']

  - job_name: 'redis'
    static_configs:
      - targets: ['redis-exporter:9121']

alerting:
  alertmanagers:
    - static_configs:
        - targets:
          - alertmanager:9093
```

#### ì•Œë¦¼ ê·œì¹™ ì„¤ì •

```yaml
# monitoring/alert_rules.yml
groups:
  - name: myapp_alerts
    rules:
      - alert: ApplicationDown
        expr: up{job="myapp"} == 0
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "Application is down"
          description: "Application {{ $labels.instance }} has been down for more than 1 minute."

      - alert: HighErrorRate
        expr: rate(http_requests_total{status=~"5.."}[5m]) > 0.1
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High error rate detected"
          description: "Error rate is {{ $value }} errors per second."

      - alert: HighResponseTime
        expr: histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m])) > 1
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High response time detected"
          description: "95th percentile response time is {{ $value }} seconds."

      - alert: DatabaseConnectionsHigh
        expr: pg_stat_activity_count > 80
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High database connections"
          description: "Database has {{ $value }} active connections."
```

### Grafana ëŒ€ì‹œë³´ë“œ ì„¤ì •

```json
{
  "dashboard": {
    "title": "MyApp Application Dashboard",
    "panels": [
      {
        "title": "Request Rate",
        "type": "graph",
        "targets": [
          {
            "expr": "rate(http_requests_total[5m])",
            "legendFormat": "{{method}} {{status}}"
          }
        ]
      },
      {
        "title": "Response Time",
        "type": "graph",
        "targets": [
          {
            "expr": "histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m]))",
            "legendFormat": "95th percentile"
          },
          {
            "expr": "histogram_quantile(0.50, rate(http_request_duration_seconds_bucket[5m]))",
            "legendFormat": "50th percentile"
          }
        ]
      },
      {
        "title": "Error Rate",
        "type": "singlestat",
        "targets": [
          {
            "expr": "rate(http_requests_total{status=~\"5..\"}[5m]) / rate(http_requests_total[5m])",
            "legendFormat": "Error Rate"
          }
        ]
      },
      {
        "title": "Application Health",
        "type": "stat",
        "targets": [
          {
            "expr": "up{job=\"myapp\"}",
            "legendFormat": "Health Status"
          }
        ]
      }
    ]
  }
}
```

### êµ¬ì¡°í™”ëœ ë¡œê¹…

#### Python ì• í”Œë¦¬ì¼€ì´ì…˜ ë¡œê¹… ì„¤ì •

```python
# src/logging_config.py
import logging
import logging.config
import json
from datetime import datetime

# êµ¬ì¡°í™”ëœ ë¡œê·¸ í¬ë§¤í„°
class StructuredFormatter(logging.Formatter):
    def format(self, record):
        log_entry = {
            "timestamp": datetime.utcnow().isoformat(),
            "level": record.levelname,
            "logger": record.name,
            "message": record.getMessage(),
            "module": record.module,
            "function": record.funcName,
            "line": record.lineno
        }

        # ì¶”ê°€ ì»¨í…ìŠ¤íŠ¸ ì •ë³´
        if hasattr(record, 'request_id'):
            log_entry['request_id'] = record.request_id
        if hasattr(record, 'user_id'):
            log_entry['user_id'] = record.user_id
        if hasattr(record, 'spec_id'):
            log_entry['spec_id'] = record.spec_id

        # ì˜ˆì™¸ ì •ë³´
        if record.exc_info:
            log_entry['exception'] = self.formatException(record.exc_info)

        return json.dumps(log_entry)

# ë¡œê¹… ì„¤ì •
LOGGING_CONFIG = {
    "version": 1,
    "disable_existing_loggers": False,
    "formatters": {
        "structured": {
            "()": StructuredFormatter
        },
        "detailed": {
            "format": "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
        }
    },
    "handlers": {
        "console": {
            "class": "logging.StreamHandler",
            "level": "INFO",
            "formatter": "structured",
            "stream": "ext://sys.stdout"
        },
        "file": {
            "class": "logging.handlers.RotatingFileHandler",
            "level": "DEBUG",
            "formatter": "structured",
            "filename": "/var/log/app/app.log",
            "maxBytes": 10485760,  # 10MB
            "backupCount": 5
        }
    },
    "loggers": {
        "": {
            "level": "INFO",
            "handlers": ["console", "file"],
            "propagate": False
        },
        "uvicorn": {
            "level": "INFO",
            "handlers": ["console", "file"],
            "propagate": False
        },
        "sqlalchemy.engine": {
            "level": "WARNING",
            "handlers": ["file"],
            "propagate": False
        }
    }
}
```

## ë³´ì•ˆ ë° ê·œì œ ì¤€ìˆ˜

### ì»¨í…Œì´ë„ˆ ë³´ì•ˆ ì„¤ì •

```dockerfile
# Dockerfile.security
FROM python:3.13-slim as security-base

# ë¹„root ì‚¬ìš©ì ìƒì„±
RUN groupadd -r appuser && useradd -r -g appuser appuser

# ì‹œìŠ¤í…œ íŒ¨í‚¤ì§€ ì„¤ì¹˜ (ìµœì†Œí•œ)
RUN apt-get update && apt-get install -y \
    ca-certificates \
    curl \
    && rm -rf /var/lib/apt/lists/* \
    && apt-get clean

# Python íŒ¨í‚¤ì§€ ì„¤ì¹˜
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# ì• í”Œë¦¬ì¼€ì´ì…˜ ë³µì‚¬
COPY src/ /app/src/
COPY --chown=appuser:appuser . /app/

# ì‘ì—… ë””ë ‰í† ë¦¬
WORKDIR /app

# ë¹„root ì‚¬ìš©ìë¡œ ì „í™˜
USER appuser

# ë³´ì•ˆ ê´€ë ¨ í™˜ê²½ ë³€ìˆ˜
ENV PYTHONUNBUFFERED=1 \
    PYTHONDONTWRITEBYTECODE=1 \
    PATH="/app/.venv/bin:$PATH"

# í¬íŠ¸ (ë³€ê²½ ê°€ëŠ¥)
EXPOSE 8000

# í—¬ìŠ¤ ì²´í¬
HEALTHCHECK --interval=30s --timeout=10s --start-period=5s --retries=3 \
    CMD curl -f http://localhost:8000/health || exit 1

# ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹œì‘
CMD ["python", "-m", "uvicorn", "src.main:app", "--host", "0.0.0.0", "--port", "8000"]
```

### ë„¤íŠ¸ì›Œí¬ ë³´ì•ˆ ì„¤ì •

```yaml
# docker-compose.security.yml
version: '3.8'

services:
  app:
    build:
      context: .
      dockerfile: Dockerfile.security
    networks:
      - frontend
      - backend
    user: "1000:1000"
    read_only: true
    tmpfs:
      - /tmp
      - /var/log/app
    security_opt:
      - no-new-privileges:true
    cap_drop:
      - ALL
    cap_add:
      - CHOWN
      - SETGID
      - SETUID

  nginx:
    image: nginx:alpine
    networks:
      - frontend
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf:ro
      - ./ssl:/etc/nginx/ssl:ro
      - ./static:/var/www/static:ro
    security_opt:
      - no-new-privileges:true
    cap_drop:
      - ALL
    cap_add:
      - CHOWN
      - SETGID
      - NET_BIND_SERVICE

  db:
    image: postgres:15
    networks:
      - backend
    environment:
      - POSTGRES_DB_FILE=/run/secrets/postgres_db
      - POSTGRES_USER_FILE=/run/secrets/postgres_user
      - POSTGRES_PASSWORD_FILE=/run/secrets/postgres_password
    secrets:
      - postgres_db
      - postgres_user
      - postgres_password
    volumes:
      - postgres_data:/var/lib/postgresql/data
    security_opt:
      - no-new-privileges:true

networks:
  frontend:
    driver: bridge
  backend:
    driver: bridge
    internal: true

secrets:
  postgres_db:
    file: ./secrets/postgres_db.txt
  postgres_user:
    file: ./secrets/postgres_user.txt
  postgres_password:
    file: ./secrets/postgres_password.txt

volumes:
  postgres_data:
    driver: local
```

### OWASP ë³´ì•ˆ ê²€ì‚¬

```yaml
# .github/workflows/security.yml
name: Security Scan

on:
  push:
    branches: [main, develop]
  pull_request:
    branches: [main]
  schedule:
    - cron: '0 2 * * 1'  # ë§¤ì£¼ ì›”ìš”ì¼ ìƒˆë²½ 2ì‹œ

jobs:
  security-scan:
    runs-on: ubuntu-latest
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.13'

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install bandit safety safety-db

    - name: Run Bandit security scan
      run: |
        bandit -r src/ -f json -o bandit-report.json
        bandit -r src/

    - name: Check dependencies for known vulnerabilities
      run: |
        safety check --json --output safety-report.json
        safety check

    - name: Run Trivy vulnerability scanner
      uses: aquasecurity/trivy-action@master
      with:
        scan-type: 'fs'
        scan-ref: '.'
        format: 'sarif'
        output: 'trivy-results.sarif'

    - name: OWASP ZAP Baseline Scan
      uses: zaproxy/action-baseline@v0.7.0
      with:
        target: 'http://localhost:8000'
        rules_file_name: '.zap/rules.tsv'
        cmd_options: '-a'

    - name: Upload security scan results
      uses: github/codeql-action/upload-sarif@v2
      with:
        sarif_file: 'trivy-results.sarif'

    - name: Comment security findings
      uses: actions/github-script@v6
      with:
        script: |
          const fs = require('fs');

          if (fs.existsSync('bandit-report.json')) {
            const bandit = JSON.parse(fs.readFileSync('bandit-report.json', 'utf8'));
            if (bandit.results.length > 0) {
              const comment = `## <span class="material-icons">lock</span> Security Scan Results\n\n**Bandit found ${bandit.results.length} issues:**\n\n${bandit.results.map(issue => `- **${issue.test_name}**: ${issue.issue_text} (${issue.filename}:${issue.line_number})`).join('\n')}`;
              github.rest.issues.createComment({
                issue_number: context.issue.number,
                owner: context.repo.owner,
                repo: context.repo.repo,
                body: comment
              });
            }
          }
```

## ë°°í¬ ìë™í™”

### ë°°í¬ íŒŒì´í”„ë¼ì¸ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜

```bash
#!/bin/bash
# scripts/deploy-pipeline.sh

set -e

# ì¸ì ì²˜ë¦¬
ENVIRONMENT=${1:-staging}
VERSION=${2:-latest}
STRATEGY=${3:-rolling}

echo "<span class="material-icons">rocket_launch</span> Starting deployment pipeline"
echo "ğŸ“‹ Environment: $ENVIRONMENT"
echo "<span class="material-icons">label</span>  Version: $VERSION"
echo "ğŸ”„ Strategy: $STRATEGY"

# 1. ì‚¬ì „ ê²€ì‚¬
echo "<span class="material-icons">search</span> Running pre-deployment checks..."
./scripts/pre-deployment-checks.sh $ENVIRONMENT

# 2. ë°±ì—… ìƒì„±
echo "ğŸ’¾ Creating backups..."
./scripts/backup-system.sh $ENVIRONMENT

# 3. í…ŒìŠ¤íŠ¸ í™˜ê²½ ë°°í¬
if [ "$ENVIRONMENT" != "production" ]; then
    echo "ğŸ§ª Deploying to test environment first..."
    ./scripts/deploy-to-test.sh $VERSION

    echo "ğŸ§ª Running integration tests..."
    ./scripts/integration-tests.sh test
fi

# 4. ëŒ€ìƒ í™˜ê²½ ë°°í¬
echo "<span class="material-icons">rocket_launch</span> Deploying to $ENVIRONMENT environment..."

case $STRATEGY in
    "rolling")
        ./scripts/rolling-deploy.sh $ENVIRONMENT $VERSION
        ;;
    "blue-green")
        ./scripts/blue-green-deploy.sh $ENVIRONMENT $VERSION
        ;;
    "canary")
        ./scripts/canary-deploy.sh $ENVIRONMENT $VERSION
        ;;
    *)
        echo "<span class="material-icons">cancel</span> Unknown deployment strategy: $STRATEGY"
        exit 1
        ;;
esac

# 5. ë°°í¬ í›„ ê²€ì¦
echo "<span class="material-icons">search</span> Running post-deployment validation..."
./scripts/post-deployment-checks.sh $ENVIRONMENT

# 6. ì„±ëŠ¥ í…ŒìŠ¤íŠ¸
if [ "$ENVIRONMENT" = "staging" ]; then
    echo "<span class="material-icons">analytics</span> Running performance tests..."
    ./scripts/performance-tests.sh $ENVIRONMENT
fi

# 7. ë³´ì•ˆ ê²€ì‚¬
echo "<span class="material-icons">lock</span> Running security validation..."
./scripts/security-validation.sh $ENVIRONMENT

# 8. ì•Œë¦¼ ë°œì†¡
echo "ğŸ“§ Sending deployment notifications..."
./scripts/notify-deployment.sh $ENVIRONMENT $VERSION success

echo "<span class="material-icons">check_circle</span> Deployment pipeline completed successfully!"
```

### ë©€í‹° í™˜ê²½ ë°°í¬ ê´€ë¦¬

```yaml
# deploy-config.yml
environments:
  development:
    type: "compose"
    config_file: "docker-compose.dev.yml"
    auto_deploy: true
    health_check_timeout: 60
    rollback_on_failure: false

  staging:
    type: "kubernetes"
    namespace: "staging"
    config_file: "k8s/staging/"
    auto_deploy: true
    health_check_timeout: 300
    rollback_on_failure: true
    tests:
      - smoke
      - integration
      - performance

  production:
    type: "kubernetes"
    namespace: "production"
    config_file: "k8s/production/"
    auto_deploy: false
    health_check_timeout: 600
    rollback_on_failure: true
    approvals_required: 2
    tests:
      - smoke
      - integration
      - security
      - performance

strategies:
  rolling:
    default: true
    max_unavailable: 0
    max_surge: 1

  blue_green:
    default: false
    switch_traffic_automatically: true
    health_check_duration: 300

  canary:
    default: false
    steps:
      - weight: 5
        duration: 300
      - weight: 25
        duration: 600
      - weight: 50
        duration: 900
      - weight: 100
        duration: 0

notifications:
  slack:
    webhook_url: "${SLACK_WEBHOOK}"
    channels:
      development: "#dev-deployments"
      staging: "#staging-deployments"
      production: "#prod-deployments"

  email:
    smtp_server: "${SMTP_SERVER}"
    recipients:
      development: ["dev-team@company.com"]
      staging: ["qa-team@company.com"]
      production: ["ops-team@company.com", "management@company.com"]
```

### ë°°í¬ ìƒíƒœ ì¶”ì 

```python
# scripts/deployment_tracker.py
import json
import time
import requests
from datetime import datetime
from typing import Dict, List, Optional

class DeploymentTracker:
    def __init__(self, config_file: str = "deploy-config.yml"):
        self.config = self.load_config(config_file)

    def load_config(self, config_file: str) -> Dict:
        """ë°°í¬ ì„¤ì • ë¡œë“œ"""
        with open(config_file, 'r') as f:
            return yaml.safe_load(f)

    def start_deployment(self, environment: str, version: str, strategy: str) -> str:
        """ë°°í¬ ì‹œì‘ ì¶”ì """
        deployment_id = f"{environment}-{version}-{int(time.time())}"

        deployment = {
            "id": deployment_id,
            "environment": environment,
            "version": version,
            "strategy": strategy,
            "status": "in_progress",
            "started_at": datetime.utcnow().isoformat(),
            "steps": []
        }

        self.save_deployment(deployment)
        return deployment_id

    def add_step(self, deployment_id: str, step_name: str, status: str,
                  details: Optional[Dict] = None):
        """ë°°í¬ ë‹¨ê³„ ì¶”ê°€"""
        deployment = self.get_deployment(deployment_id)

        step = {
            "name": step_name,
            "status": status,
            "timestamp": datetime.utcnow().isoformat(),
            "details": details or {}
        }

        deployment["steps"].append(step)
        self.save_deployment(deployment)

    def complete_deployment(self, deployment_id: str, status: str):
        """ë°°í¬ ì™„ë£Œ"""
        deployment = self.get_deployment(deployment_id)
        deployment["status"] = status
        deployment["completed_at"] = datetime.utcnow().isoformat()

        # ì„±ê³µ ë©”íŠ¸ë¦­ ê³„ì‚°
        if status == "success":
            deployment["duration"] = self.calculate_duration(deployment)
            deployment["success_rate"] = self.calculate_success_rate(deployment)

        self.save_deployment(deployment)

        # ì•Œë¦¼ ë°œì†¡
        self.send_notification(deployment)

    def get_deployment(self, deployment_id: str) -> Dict:
        """ë°°í¬ ì •ë³´ ì¡°íšŒ"""
        deployments_file = "deployments.json"

        if not os.path.exists(deployments_file):
            return {}

        with open(deployments_file, 'r') as f:
            deployments = json.load(f)

        return deployments.get(deployment_id, {})

    def save_deployment(self, deployment: Dict):
        """ë°°í¬ ì •ë³´ ì €ì¥"""
        deployments_file = "deployments.json"

        deployments = {}
        if os.path.exists(deployments_file):
            with open(deployments_file, 'r') as f:
                deployments = json.load(f)

        deployments[deployment["id"]] = deployment

        with open(deployments_file, 'w') as f:
            json.dump(deployments, f, indent=2)

    def send_notification(self, deployment: Dict):
        """ë°°í¬ ì•Œë¦¼ ë°œì†¡"""
        message = self.format_notification_message(deployment)

        # Slack ì•Œë¦¼
        if "slack" in self.config.get("notifications", {}):
            self.send_slack_notification(message)

        # Email ì•Œë¦¼
        if "email" in self.config.get("notifications", {}):
            self.send_email_notification(deployment, message)

    def format_notification_message(self, deployment: Dict) -> str:
        """ì•Œë¦¼ ë©”ì‹œì§€ í¬ë§·íŒ…"""
        status_emoji = "<span class="material-icons">check_circle</span>" if deployment["status"] == "success" else "<span class="material-icons">cancel</span>"

        message = f"""
{status_emoji} Deployment {deployment['status'].upper()}

ğŸ“‹ Environment: {deployment['environment']}
<span class="material-icons">label</span>  Version: {deployment['version']}
ğŸ”„ Strategy: {deployment['strategy']}
â° Duration: {deployment.get('duration', 'N/A')}
<span class="material-icons">analytics</span> Success Rate: {deployment.get('success_rate', 'N/A')}%

Steps:
"""

        for step in deployment["steps"]:
            step_emoji = "<span class="material-icons">check_circle</span>" if step["status"] == "success" else "<span class="material-icons">cancel</span>"
            message += f"{step_emoji} {step['name']}\n"

        return message
```

## ì„±ëŠ¥ ìµœì í™”

### ì• í”Œë¦¬ì¼€ì´ì…˜ ì„±ëŠ¥ ìµœì í™”

```python
# src/performance.py
import asyncio
import time
from functools import wraps
from typing import Callable, Any

def performance_monitor(func: Callable) -> Callable:
    """ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ë°ì½”ë ˆì´í„°"""
    @wraps(func)
    async def async_wrapper(*args, **kwargs):
        start_time = time.time()
        try:
            result = await func(*args, **kwargs)
            execution_time = time.time() - start_time

            # ì„±ëŠ¥ ë©”íŠ¸ë¦­ ê¸°ë¡
            record_performance_metric(func.__name__, execution_time, "success")

            return result
        except Exception as e:
            execution_time = time.time() - start_time
            record_performance_metric(func.__name__, execution_time, "error")
            raise

    @wraps(func)
    def sync_wrapper(*args, **kwargs):
        start_time = time.time()
        try:
            result = func(*args, **kwargs)
            execution_time = time.time() - start_time

            # ì„±ëŠ¥ ë©”íŠ¸ë¦­ ê¸°ë¡
            record_performance_metric(func.__name__, execution_time, "success")

            return result
        except Exception as e:
            execution_time = time.time() - start_time
            record_performance_metric(func.__name__, execution_time, "error")
            raise

    return async_wrapper if asyncio.iscoroutinefunction(func) else sync_wrapper

def record_performance_metric(function_name: str, execution_time: float, status: str):
    """ì„±ëŠ¥ ë©”íŠ¸ë¦­ ê¸°ë¡"""
    # Prometheus ë©”íŠ¸ë¦­ ê¸°ë¡
    from prometheus_client import Histogram, Counter

    REQUEST_DURATION = Histogram(
        'request_duration_seconds',
        'Request duration',
        ['function_name', 'status']
    )

    REQUEST_COUNT = Counter(
        'request_count_total',
        'Total requests',
        ['function_name', 'status']
    )

    REQUEST_DURATION.labels(function_name=function_name, status=status).observe(execution_time)
    REQUEST_COUNT.labels(function_name=function_name, status=status).inc()
```

### ë°ì´í„°ë² ì´ìŠ¤ ì„±ëŠ¥ ìµœì í™”

```sql
-- database/performance-optimizations.sql

-- ì¸ë±ìŠ¤ ìµœì í™”
CREATE INDEX CONCURRENTLY idx_users_email ON users(email);
CREATE INDEX CONCURRENTLY idx_users_created_at ON users(created_at);
CREATE INDEX CONCURRENTLY idx_posts_author_id ON posts(author_id);

-- íŒŒí‹°ì…”ë‹ (ëŒ€ìš©ëŸ‰ í…Œì´ë¸”)
CREATE TABLE logs (
    id SERIAL,
    message TEXT,
    level VARCHAR(10),
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
) PARTITION BY RANGE (created_at);

-- ì›”ë³„ íŒŒí‹°ì…˜
CREATE TABLE logs_2024_01 PARTITION OF logs
    FOR VALUES FROM ('2024-01-01') TO ('2024-02-01');

-- ì¿¼ë¦¬ ìµœì í™”
EXPLAIN (ANALYZE, BUFFERS)
SELECT u.id, u.name, COUNT(p.id) as post_count
FROM users u
LEFT JOIN posts p ON u.id = p.author_id
WHERE u.created_at >= '2024-01-01'
GROUP BY u.id, u.name
ORDER BY post_count DESC;

-- ì»¤ë„¥ì…˜ í’€ë§ ì„¤ì •
-- postgresql.conf
max_connections = 200
shared_buffers = 256MB
effective_cache_size = 1GB
work_mem = 4MB
maintenance_work_mem = 64MB
```

### ìºì‹± ì „ëµ

```python
# src/cache.py
import redis
import json
import pickle
from typing import Any, Optional, Union
from functools import wraps

class CacheManager:
    def __init__(self, redis_url: str):
        self.redis_client = redis.from_url(redis_url)

    def cache_result(self, key_prefix: str, ttl: int = 3600):
        """ê²°ê³¼ ìºì‹± ë°ì½”ë ˆì´í„°"""
        def decorator(func):
            @wraps(func)
            async def wrapper(*args, **kwargs):
                # ìºì‹œ í‚¤ ìƒì„±
                cache_key = f"{key_prefix}:{hash(str(args) + str(kwargs))}"

                # ìºì‹œ ì¡°íšŒ
                cached_result = self.get(cache_key)
                if cached_result is not None:
                    return cached_result

                # í•¨ìˆ˜ ì‹¤í–‰
                result = await func(*args, **kwargs)

                # ê²°ê³¼ ìºì‹±
                self.set(cache_key, result, ttl)

                return result
            return wrapper
        return decorator

    def get(self, key: str) -> Optional[Any]:
        """ìºì‹œì—ì„œ ê°’ ì¡°íšŒ"""
        try:
            value = self.redis_client.get(key)
            if value:
                return pickle.loads(value)
        except Exception as e:
            print(f"Cache get error: {e}")
        return None

    def set(self, key: str, value: Any, ttl: int = 3600):
        """ìºì‹œì— ê°’ ì €ì¥"""
        try:
            serialized_value = pickle.dumps(value)
            self.redis_client.setex(key, ttl, serialized_value)
        except Exception as e:
            print(f"Cache set error: {e}")

    def delete(self, key: str):
        """ìºì‹œì—ì„œ ê°’ ì‚­ì œ"""
        try:
            self.redis_client.delete(key)
        except Exception as e:
            print(f"Cache delete error: {e}")

    def clear_pattern(self, pattern: str):
        """íŒ¨í„´ìœ¼ë¡œ ìºì‹œ ì •ë¦¬"""
        try:
            keys = self.redis_client.keys(pattern)
            if keys:
                self.redis_client.delete(*keys)
        except Exception as e:
            print(f"Cache clear error: {e}")

# ì‚¬ìš© ì˜ˆì‹œ
cache_manager = CacheManager("redis://localhost:6379/0")

@cache_manager.cache_result("user_profile", ttl=1800)
async def get_user_profile(user_id: int):
    """ì‚¬ìš©ì í”„ë¡œí•„ ì¡°íšŒ (30ë¶„ ìºì‹œ)"""
    # ë°ì´í„°ë² ì´ìŠ¤ ì¡°íšŒ ë¡œì§
    pass

@cache_manager.cache_result("popular_posts", ttl=3600)
async def get_popular_posts(limit: int = 10):
    """ì¸ê¸° í¬ìŠ¤íŠ¸ ì¡°íšŒ (1ì‹œê°„ ìºì‹œ)"""
    # ë³µì¡í•œ ì¿¼ë¦¬ ì‹¤í–‰
    pass
```

## ë¬¸ì œ í•´ê²° ë° ë³µêµ¬

### ë¡¤ë°± ì „ëµ

```bash
#!/bin/bash
# scripts/rollback.sh

set -e

ENVIRONMENT=${1:-staging}
TARGET_VERSION=${2:-previous}

echo "ğŸ”„ Starting rollback for $ENVIRONMENT environment"
echo "<span class="material-icons">target</span> Target version: $TARGET_VERSION"

# í˜„ì¬ ìƒíƒœ ë°±ì—…
echo "ğŸ’¾ Backing up current state..."
./scripts/backup-current-state.sh $ENVIRONMENT

# ë¡¤ë°± ë°©ì‹ ì„ íƒ
case $TARGET_VERSION in
    "previous")
        VERSION=$(git describe --tags --abbrev=0 HEAD~1)
        ;;
    "stable")
        VERSION=$(git tag --sort=-version:refname | head -n 1)
        ;;
    *)
        VERSION=$TARGET_VERSION
        ;;
esac

echo "<span class="material-icons">label</span>  Rolling back to version: $VERSION"

# ë¡¤ë°± ì‹¤í–‰
echo "ğŸ”„ Executing rollback..."

# 1. ë°°í¬ ì¤‘ì§€
echo "â¸ï¸  Stopping current deployment..."
./scripts/stop-deployment.sh $ENVIRONMENT

# 2. ì´ì „ ë²„ì „ ë°°í¬
echo "<span class="material-icons">rocket_launch</span> Deploying previous version..."
./scripts/deploy-version.sh $ENVIRONMENT $VERSION

# 3. ìƒíƒœ ê²€ì¦
echo "<span class="material-icons">search</span> Validating rollback..."
./scripts/validate-rollback.sh $ENVIRONMENT $VERSION

# 4. ë°ì´í„°ë² ì´ìŠ¤ ë§ˆì´ê·¸ë ˆì´ì…˜ (í•„ìš”ì‹œ)
echo "<span class="material-icons">analytics</span> Running database migrations..."
./scripts/migrate-database.sh $ENVIRONMENT rollback

# 5. ë¡¤ë°± ì™„ë£Œ í™•ì¸
echo "<span class="material-icons">check_circle</span> Rollback completed successfully!"
echo "<span class="material-icons">language</span> Application running on: https://api.myapp.com"
echo "<span class="material-icons">label</span>  Current version: $VERSION"

# ì•Œë¦¼ ë°œì†¡
./scripts/notify-rollback.sh $ENVIRONMENT $VERSION
```

### ì¥ì•  ëŒ€ì‘ ì ˆì°¨

```yaml
# incident-response.yml
incident_response:
  severity_levels:
    critical:
      response_time: 15  # ë¶„
      escalation_time: 30  # ë¶„
      notification_channels: ["slack", "email", "sms", "call"]

    high:
      response_time: 30
      escalation_time: 60
      notification_channels: ["slack", "email"]

    medium:
      response_time: 60
      escalation_time: 120
      notification_channels: ["slack"]

    low:
      response_time: 240
      escalation_time: 480
      notification_channels: ["slack"]

  playbooks:
    application_down:
      detection:
        - health_check_failure
        - error_rate_threshold
        - user_reports

      immediate_actions:
        - check_logs
        - verify_system_resources
        - check_external_dependencies

      recovery_actions:
        - restart_services
        - rollback_deployment
        - scale_up_resources

      post_incident:
        - root_cause_analysis
        - prevention_measures
        - documentation_update

    performance_degradation:
      detection:
        - response_time_threshold
        - cpu_memory_threshold
        - database_slow_queries

      immediate_actions:
        - check_system_metrics
        - identify_bottlenecks
        - scale_resources

      recovery_actions:
        - optimize_queries
        - add_caching
        - scale_horizontally

    security_incident:
      detection:
        - unusual_access_patterns
        - security_scan_alerts
        - data_breach_indicators

      immediate_actions:
        - isolate_affected_systems
        - preserve_evidence
        - notify_security_team

      recovery_actions:
        - patch_vulnerabilities
        - reset_credentials
        - restore_from_backup

  communication_templates:
    initial_alert: |
      ğŸš¨ **Incident Alert**

      **Severity**: {severity}
      **Service**: {service}
      **Impact**: {impact}
      **Started**: {timestamp}

      **Next Update**: {next_update_time}

      **Response Team**: {team}

    progress_update: |
      ğŸ“‹ **Incident Update**

      **Incident ID**: {incident_id}
      **Status**: {status}
      **Actions Taken**: {actions}
      **ETA**: {eta}

      **Next Update**: {next_update_time}

    resolution: |
      <span class="material-icons">check_circle</span> **Incident Resolved**

      **Incident ID**: {incident_id}
      **Resolution Time**: {resolution_time}
      **Root Cause**: {root_cause}
      **Prevention Measures**: {prevention}

      **Post-Mortem**: {post_mortem_link}
```

## ëª¨ë²” ì‚¬ë¡€

### ë°°í¬ ì²´í¬ë¦¬ìŠ¤íŠ¸

#### ì‚¬ì „ ë°°í¬ í™•ì¸ì‚¬í•­

```markdown
## ğŸ“‹ Pre-Deployment Checklist

### <span class="material-icons">check_circle</span> ì½”ë“œ ì¤€ë¹„
- [ ] ëª¨ë“  í…ŒìŠ¤íŠ¸ í†µê³¼ (ë‹¨ìœ„, í†µí•©, E2E)
- [ ] ì½”ë“œ ë¦¬ë·° ì™„ë£Œ ë° ìŠ¹ì¸
- [ ] ë³´ì•ˆ ìŠ¤ìº” í†µê³¼
- [ ] ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ í†µê³¼
- [ ] ë¬¸ì„œ ì—…ë°ì´íŠ¸ ì™„ë£Œ

### <span class="material-icons">check_circle</span> í™˜ê²½ ì¤€ë¹„
- [ ] íƒ€ê²Ÿ í™˜ê²½ ìƒíƒœ ì •ìƒ
- [ ] ë°ì´í„°ë² ì´ìŠ¤ ë°±ì—… ì™„ë£Œ
- [ ] ì„¤ì • íŒŒì¼ ê²€ì¦ ì™„ë£Œ
- [ ] ë¦¬ì†ŒìŠ¤ ìš©ëŸ‰ í™•ì¸
- [ ] ë„¤íŠ¸ì›Œí¬ ì—°ê²° í™•ì¸

### <span class="material-icons">check_circle</span> ë°°í¬ ê³„íš
- [ ] ë¡¤ë°± ê³„íš ìˆ˜ë¦½
- [ ] ë°°í¬ ì‹œê°„ ì°½ í™•ë³´
- [ ] ê´€ë ¨íŒ€ í†µì§€ ì™„ë£Œ
- [ ] ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ ì¤€ë¹„
- [ ] ì•Œë¦¼ ì±„ë„ ì„¤ì •

### <span class="material-icons">check_circle</span> ë³´ì•ˆ ë° ê·œì œ
- [ ] ì ‘ê·¼ ê¶Œí•œ í™•ì¸
- [ ] ë³´ì•ˆ ì •ì±… ì¤€ìˆ˜
- [ ] ê·œì œ ìš”êµ¬ì‚¬í•­ ê²€ì¦
- [ ] ê°ì‚¬ ë¡œê·¸ í™œì„±í™”
- [ ] ë¯¼ê°ì •ë³´ ì²˜ë¦¬ í™•ì¸
```

#### ë°°í¬ í›„ í™•ì¸ì‚¬í•­

```markdown
## <span class="material-icons">check_circle</span> Post-Deployment Checklist

### <span class="material-icons">rocket_launch</span> ë°°í¬ ìƒíƒœ í™•ì¸
- [ ] ì• í”Œë¦¬ì¼€ì´ì…˜ ì •ìƒ ì‹œì‘
- [ ] í—¬ìŠ¤ ì²´í¬ í†µê³¼
- [ ] ë¡œê·¸ ì—ëŸ¬ ì—†ìŒ
- [ ] ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì •ìƒ
- [ ] ì™¸ë¶€ API ì—°ë™ ì •ìƒ

### <span class="material-icons">analytics</span> ê¸°ëŠ¥ ê²€ì¦
- [ ] ì£¼ìš” ê¸°ëŠ¥ ë™ì‘ í™•ì¸
- [ ] API ì—”ë“œí¬ì¸íŠ¸ ì‘ë‹µ ì •ìƒ
- [ ] ì‚¬ìš©ì ì¸ì¦ ì‘ë™
- [ ] ë°ì´í„° CRUD ì‘ì—… ì •ìƒ
- [ ] íŒŒì¼ ì—…ë¡œë“œ/ë‹¤ìš´ë¡œë“œ ì •ìƒ

### <span class="material-icons">search</span> ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
- [ ] ì‘ë‹µ ì‹œê°„ ì •ìƒ ë²”ìœ„
- [ ] CPU/ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì •ìƒ
- [ ] ë°ì´í„°ë² ì´ìŠ¤ ì¿¼ë¦¬ ì„±ëŠ¥ ì–‘í˜¸
- [ ] ìºì‹œ ì ì¤‘ë¥  ì •ìƒ
- [ ] ì—ëŸ¬ë¥  ì„ê³„ì¹˜ ì´í•˜

### <span class="material-icons">trending_up</span> ëª¨ë‹ˆí„°ë§ ì•Œë¦¼
- [ ] Prometheus ë©”íŠ¸ë¦­ ìˆ˜ì§‘
- [ ] Grafana ëŒ€ì‹œë³´ë“œ ì •ìƒ
- [ ] ë¡œê·¸ ìˆ˜ì§‘ ë° ë¶„ì„
- [ ] ì•Œë¦¼ ê·œì¹™ ë™ì‘ í™•ì¸
- [ ] SLA ì§€í‘œ ì¶©ì¡±

### ğŸ”„ ë¡¤ë°± ì¤€ë¹„
- [ ] ì´ì „ ë²„ì „ ì´ë¯¸ì§€ ë³´ê´€
- [ ] ë¡¤ë°± ìŠ¤í¬ë¦½íŠ¸ ê²€ì¦
- [ ] ë°ì´í„°ë² ì´ìŠ¤ ë§ˆì´ê·¸ë ˆì´ì…˜ ìŠ¤í¬ë¦½íŠ¸ ì¤€ë¹„
- [ ] ë¡¤ë°± ì‹œë‚˜ë¦¬ì˜¤ í…ŒìŠ¤íŠ¸ ì™„ë£Œ
- [ ] ê¸´ê¸‰ ì—°ë½ë§ í™•ì¸
```

### ë°°í¬ ì„±ê³µ ì§€í‘œ

```yaml
# deployment-metrics.yml
success_metrics:
  deployment_success_rate:
    target: 95%
    measurement: "Successful deployments / Total deployments"

  deployment_time:
    target: 15  # minutes
    measurement: "Time from commit to production"

  rollback_rate:
    target: 5%
    measurement: "Rollbacks / Total deployments"

  downtime_per_deployment:
    target: 30  # seconds
    measurement: "Service unavailability during deployment"

  post_deployment_issues:
    target: 2
    measurement: "Critical issues in first 24 hours"

  performance_regression:
    target: 5%
    measurement: "Performance degradation after deployment"

monitoring:
  real_time_alerts:
    - deployment_failure
    - health_check_failure
    - error_rate_spike
    - response_time_degradation

  daily_reports:
    - deployment_summary
    - performance_metrics
    - error_analysis
    - user_impact_assessment

  weekly_reviews:
    - deployment_process_review
    - incident_postmortem
    - optimization_opportunities
    - team_feedback
```

---

ì´ ê°€ì´ë“œë¥¼ í†µí•´ MoAI-ADK í”„ë¡œì íŠ¸ë¥¼ ì•ˆì „í•˜ê³  íš¨ìœ¨ì ìœ¼ë¡œ ë°°í¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. í˜„ëŒ€ì ì¸ DevOps ê´€í–‰ê³¼ ìë™í™”ëœ ì›Œí¬í”Œë¡œìš°ë¥¼ í†µí•´ ì•ˆì •ì ì¸ ì„œë¹„ìŠ¤ ìš´ì˜ì„ ë‹¬ì„±í•  ìˆ˜ ìˆì„ ê²ƒì…ë‹ˆë‹¤.