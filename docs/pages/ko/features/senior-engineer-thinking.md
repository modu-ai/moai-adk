# Senior Engineer Thinking í†µí•©

## ê°œìš”

MoAI-ADK v0.22.0ì€ **Senior Engineer Thinking**ì„ í•µì‹¬ ê¸°ëŠ¥ìœ¼ë¡œ í†µí•©í•˜ì—¬ AI ì—ì´ì „íŠ¸ê°€ ì‹œë‹ˆì–´ ì—”ì§€ë‹ˆì–´ì²˜ëŸ¼ ì‚¬ê³ í•˜ê³  ë¬¸ì œë¥¼ í•´ê²°í•  ìˆ˜ ìˆë„ë¡ í•©ë‹ˆë‹¤. ì´ëŠ” ë‹¨ìˆœíˆ ì½”ë“œë¥¼ ìƒì„±í•˜ëŠ” ê²ƒì„ ë„˜ì–´, ë¬¸ì œì˜ ê·¼ë³¸ ì›ì¸ì„ íŒŒì•…í•˜ê³ , ë‹¤ì–‘í•œ ì†”ë£¨ì…˜ì„ íƒìƒ‰í•˜ë©°, ê²€ì¦ ê°€ëŠ¥í•œ ìµœì„ ì˜ ì ‘ê·¼ë²•ì„ ì„ íƒí•˜ëŠ” ì²´ê³„ì ì¸ ì—°êµ¬ í”„ë¡œì„¸ìŠ¤ì…ë‹ˆë‹¤.

### í•µì‹¬ ê°€ì¹˜

- **ê¹Šì´ ìˆëŠ” ë¬¸ì œ ë¶„ì„**: í‘œë©´ì  ì¦ìƒì´ ì•„ë‹Œ ê·¼ë³¸ ì›ì¸ íŒŒì•…
- **ì¦ê±° ê¸°ë°˜ ì˜ì‚¬ê²°ì •**: ë¬¸ì„œ, ì½”ë“œë² ì´ìŠ¤, Git íˆìŠ¤í† ë¦¬ ë¶„ì„
- **ë‹¤ì¤‘ ì†”ë£¨ì…˜ íƒìƒ‰**: ì—¬ëŸ¬ ì ‘ê·¼ë²• ë¹„êµ ë° ìµœì ì•ˆ ì„ íƒ
- **ì§€ì‹ ì¶•ì  íš¨ê³¼**: í”„ë¡œì íŠ¸ ì§„í–‰ì— ë”°ë¼ ì»¨í…ìŠ¤íŠ¸ ì´í•´ë„ ì¦ê°€

```mermaid
graph TB
    A[ë¬¸ì œ ì¸ì‹] --> B{ë³µì¡ë„ í‰ê°€}
    B -->|ë‹¨ìˆœ| C[ì§ì ‘ í•´ê²°]
    B -->|ë³µì¡| D[Research Strategies í™œì„±í™”]
    D --> E[Strategy 1-8 ì„ íƒ]
    E --> F[ë³‘ë ¬ ì—°êµ¬ ìˆ˜í–‰]
    F --> G[Knowledge Synthesis]
    G --> H[ê²€ì¦ëœ ì†”ë£¨ì…˜]
    H --> I[ì‹¤í–‰ ë° í…ŒìŠ¤íŠ¸]
    I --> J[í•™ìŠµ íš¨ê³¼ ëˆ„ì ]
    J --> A
```

## ì™œ í•„ìš”í•œê°€?

### ì „í†µì  AI ì ‘ê·¼ë²•ì˜ í•œê³„

```python
# ì „í†µì  AI: ì¦‰ê° ì‹¤í–‰
user: "ì´ë©”ì¼ 53,000ê°œë¥¼ ì•„ì¹´ì´ë¸Œ í•´ì¤˜"
ai: "ì•Œê² ìŠµë‹ˆë‹¤" â†’ [ì¦‰ì‹œ ì‹¤í–‰] â†’ [ì‹¤íŒ¨/ë¶ˆì™„ì „]

# ë¬¸ì œì :
# - API ì†ë„ ì œí•œ ê³ ë ¤ ì—†ìŒ
# - ë°°ì¹˜ ì²˜ë¦¬ ì „ëµ ë¶€ì¬
# - ë¡¤ë°± ë©”ì»¤ë‹ˆì¦˜ ì—†ìŒ
# - ì§„í–‰ ìƒí™© ì¶”ì  ë¶ˆê°€
```

### Senior Engineer Alfred ì ‘ê·¼ë²•

```python
# Senior Engineer Alfred: ì—°êµ¬ í›„ ì‹¤í–‰
user: "ì´ë©”ì¼ 53,000ê°œë¥¼ ì•„ì¹´ì´ë¸Œ í•´ì¤˜"

alfred: "ì´ ì‘ì—…ì€ ë³µì¡í•©ë‹ˆë‹¤. ì—°êµ¬ê°€ í•„ìš”í•©ë‹ˆë‹¤."
  â†’ Strategy 1: Gmail API ë¬¸ì„œ ì¬í˜„ ë° ë¶„ì„
  â†’ Strategy 2: ì´ë©”ì¼ ëŒ€ëŸ‰ ì²˜ë¦¬ Best Practices
  â†’ Strategy 3: ê¸°ì¡´ ì½”ë“œë² ì´ìŠ¤ì˜ ë°°ì¹˜ ì²˜ë¦¬ íŒ¨í„´
  â†’ Strategy 7: 3ê°€ì§€ ì ‘ê·¼ë²• ë¹„êµ
     - ë‹¨ì¼ ìŠ¤ë ˆë“œ ìˆœì°¨ ì²˜ë¦¬
     - ë©€í‹°ìŠ¤ë ˆë“œ ë³‘ë ¬ ì²˜ë¦¬ (ì„ íƒë¨)
     - í ê¸°ë°˜ ë¹„ë™ê¸° ì²˜ë¦¬

alfred: [ê²€ì¦ëœ ê³„íš ì œì‹œ]
  - ë°°ì¹˜ í¬ê¸°: 100ê°œ
  - ë³‘ë ¬ ì›Œì»¤: 5ê°œ
  - Rate limit: 250 req/s
  - ì§„í–‰ ì¶”ì : SQLite DB
  - ë¡¤ë°±: ì²´í¬í¬ì¸íŠ¸ ì‹œìŠ¤í…œ
```

### ì°¨ì´ì  ë¹„êµ

| ì¸¡ë©´ | ì „í†µì  AI | Senior Engineer Alfred |
|------|----------|------------------------|
| **ì ‘ê·¼ë²•** | ì¦‰ê° ì‹¤í–‰ | ì—°êµ¬ â†’ ê³„íš â†’ ì‹¤í–‰ |
| **ë¬¸ì œ ë¶„ì„** | í‘œë©´ì  | ê·¼ë³¸ ì›ì¸ íŒŒì•… |
| **ì†”ë£¨ì…˜ íƒìƒ‰** | ë‹¨ì¼ ê²½ë¡œ | ë‹¤ì¤‘ ì˜µì…˜ ë¹„êµ |
| **ê²€ì¦** | ì‚¬í›„ í™•ì¸ | ì‚¬ì „ ê²€ì¦ |
| **í•™ìŠµ íš¨ê³¼** | ì—†ìŒ | ëˆ„ì  í–¥ìƒ |
| **ì‹¤íŒ¨ ì²˜ë¦¬** | ì¬ì‹œë„ | ì˜ˆë°© ì„¤ê³„ |

## 8ê°€ì§€ ì—°êµ¬ ì „ëµ

### Strategy 1: Reproduce & Document

**ëª©ì **: ì™¸ë¶€ ë¬¸ì„œë¥¼ ì½ê³  ì¬í˜„í•˜ì—¬ ì •í™•ì„± ê²€ì¦

**ì–¸ì œ ì‚¬ìš©í•˜ëŠ”ê°€?**
- ìƒˆë¡œìš´ ë¼ì´ë¸ŒëŸ¬ë¦¬/API í†µí•© ì‹œ
- ê³µì‹ ë¬¸ì„œê°€ ëª¨í˜¸í•˜ê±°ë‚˜ ì˜¤ë˜ëœ ê²½ìš°
- ì˜ˆì œ ì½”ë“œê°€ ì‘ë™í•˜ì§€ ì•Šì„ ë•Œ

**êµ¬í˜„ ë°©ì‹**:

```python
# research-orchestratorê°€ í˜¸ì¶œ
research_task = {
    "strategy": "reproduce_and_document",
    "target": "Gmail API batch operations",
    "actions": [
        "fetch_official_docs",
        "create_minimal_reproduction",
        "verify_examples",
        "document_findings"
    ]
}

# ì‹¤í–‰ ê²°ê³¼
reproduction_report = {
    "docs_url": "https://developers.google.com/gmail/api/guides/batch",
    "reproduction_success": True,
    "findings": [
        "ë°°ì¹˜ ìš”ì²­ì€ ìµœëŒ€ 100ê°œê¹Œì§€ ê°€ëŠ¥",
        "multipart/mixed content-type í•„ìˆ˜",
        "ê° í•˜ìœ„ ìš”ì²­ì€ ë…ë¦½ì  HTTP ìš”ì²­ í¬ë§·"
    ],
    "code_example": """
import httplib2
from googleapiclient.http import BatchHttpRequest

def archive_emails_batch(service, message_ids):
    batch = service.new_batch_http_request()
    for msg_id in message_ids[:100]:
        batch.add(
            service.users().messages().modify(
                userId='me',
                id=msg_id,
                body={'removeLabelIds': ['INBOX']}
            )
        )
    batch.execute()
    """
}
```

**Mermaid í”Œë¡œìš°**:

```mermaid
sequenceDiagram
    participant User
    participant Alfred
    participant Research
    participant Docs

    User->>Alfred: ìƒˆ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì‚¬ìš© ìš”ì²­
    Alfred->>Research: Strategy 1 í™œì„±í™”
    Research->>Docs: ê³µì‹ ë¬¸ì„œ ê²€ìƒ‰
    Docs-->>Research: API ë¬¸ì„œ ë°˜í™˜
    Research->>Research: ìµœì†Œ ì¬í˜„ ì½”ë“œ ì‘ì„±
    Research->>Research: ì˜ˆì œ ì‹¤í–‰ ë° ê²€ì¦
    Research-->>Alfred: ê²€ì¦ëœ íŒ¨í„´ ë³´ê³ 
    Alfred->>User: ì‘ë™ í™•ì¸ëœ ì†”ë£¨ì…˜ ì œì‹œ
```

### Strategy 2: Ground in Best Practices

**ëª©ì **: ì‚°ì—… í‘œì¤€ ë° ê²€ì¦ëœ íŒ¨í„´ ì ìš©

**ì–¸ì œ ì‚¬ìš©í•˜ëŠ”ê°€?**
- ì•„í‚¤í…ì²˜ ê²°ì •ì´ í•„ìš”í•  ë•Œ
- ì„±ëŠ¥/ë³´ì•ˆì´ ì¤‘ìš”í•œ ê²½ìš°
- ìœ ì§€ë³´ìˆ˜ì„±ì„ ê³ ë ¤í•´ì•¼ í•  ë•Œ

**êµ¬í˜„ ë°©ì‹**:

```python
# Context7 MCPë¥¼ í†µí•œ Best Practices ê²€ìƒ‰
best_practices_query = {
    "domain": "email_processing",
    "topics": [
        "batch processing patterns",
        "rate limiting strategies",
        "error recovery mechanisms"
    ]
}

# Context7 ê²°ê³¼
practices = {
    "batch_processing": {
        "pattern": "Producer-Consumer with bounded queue",
        "rationale": "ë©”ëª¨ë¦¬ ì œì–´ + ë°±í”„ë ˆì…” ì²˜ë¦¬",
        "reference": "Google SRE Book Chapter 21"
    },
    "rate_limiting": {
        "pattern": "Token Bucket Algorithm",
        "implementation": """
from threading import Lock
import time

class RateLimiter:
    def __init__(self, rate, capacity):
        self.rate = rate
        self.capacity = capacity
        self.tokens = capacity
        self.last_update = time.time()
        self.lock = Lock()

    def acquire(self, tokens=1):
        with self.lock:
            now = time.time()
            elapsed = now - self.last_update
            self.tokens = min(
                self.capacity,
                self.tokens + elapsed * self.rate
            )
            self.last_update = now

            if self.tokens >= tokens:
                self.tokens -= tokens
                return True
            return False
        """
    },
    "error_recovery": {
        "pattern": "Exponential Backoff with Jitter",
        "reference": "AWS Architecture Blog"
    }
}
```

**Best Practices ì ìš© ì²´í¬ë¦¬ìŠ¤íŠ¸**:

- [ ] ê´€ë ¨ ì‚°ì—… í‘œì¤€ í™•ì¸ (RFC, W3C, ISO)
- [ ] ì£¼ìš” í´ë¼ìš°ë“œ ì œê³µìì˜ ê¶Œì¥ì‚¬í•­ ê²€í†  (AWS, GCP, Azure)
- [ ] ì˜¤í”ˆì†ŒìŠ¤ ëŒ€í˜• í”„ë¡œì íŠ¸ì˜ íŒ¨í„´ ë¶„ì„
- [ ] ì„±ëŠ¥/ë³´ì•ˆ íŠ¸ë ˆì´ë“œì˜¤í”„ ë¬¸ì„œí™”
- [ ] ê¸°ìˆ  ë¶€ì±„ ê°€ëŠ¥ì„± í‰ê°€

### Strategy 3: Ground in Your Codebase

**ëª©ì **: ê¸°ì¡´ í”„ë¡œì íŠ¸ì˜ íŒ¨í„´ ë° ìŠ¤íƒ€ì¼ ìœ ì§€

**ì–¸ì œ ì‚¬ìš©í•˜ëŠ”ê°€?**
- ê¸°ì¡´ ì‹œìŠ¤í…œì— ìƒˆ ê¸°ëŠ¥ ì¶”ê°€ ì‹œ
- ì½”ë“œ ì¼ê´€ì„±ì´ ì¤‘ìš”í•  ë•Œ
- ë ˆê±°ì‹œ ì½”ë“œì™€ í†µí•©í•´ì•¼ í•  ë•Œ

**êµ¬í˜„ ë°©ì‹**:

```python
# ì½”ë“œë² ì´ìŠ¤ ë¶„ì„
codebase_analysis = {
    "existing_patterns": [
        {
            "pattern": "Repository Pattern for data access",
            "files": [
                "src/repositories/user_repository.py",
                "src/repositories/email_repository.py"
            ],
            "example": """
class EmailRepository:
    def __init__(self, db_session):
        self.db = db_session

    def get_by_id(self, email_id):
        return self.db.query(Email).filter_by(id=email_id).first()

    def batch_update(self, email_ids, updates):
        # ê¸°ì¡´ ë°°ì¹˜ ì²˜ë¦¬ íŒ¨í„´ ë°œê²¬!
        chunk_size = 100
        for i in range(0, len(email_ids), chunk_size):
            chunk = email_ids[i:i+chunk_size]
            self.db.bulk_update_mappings(Email, [
                {'id': eid, **updates} for eid in chunk
            ])
        self.db.commit()
            """
        },
        {
            "pattern": "Task Queue with Celery",
            "files": ["src/tasks/email_tasks.py"],
            "insight": "í”„ë¡œì íŠ¸ì— ì´ë¯¸ Celery ì„¤ì •ë¨ - ì¬ì‚¬ìš© ê°€ëŠ¥"
        }
    ],
    "naming_conventions": {
        "functions": "snake_case",
        "classes": "PascalCase",
        "constants": "UPPER_SNAKE_CASE"
    },
    "testing_patterns": {
        "framework": "pytest",
        "fixtures": "conftest.pyì— ê³µí†µ fixture",
        "mocking": "pytest-mock ì‚¬ìš©"
    }
}

# ê¸°ì¡´ íŒ¨í„´ ì ìš©í•œ ìƒˆ ì½”ë“œ
new_feature = """
# ê¸°ì¡´ Repository íŒ¨í„´ ì¤€ìˆ˜
class GmailArchiveRepository:
    def __init__(self, db_session):
        self.db = db_session

    def batch_archive(self, message_ids):
        # ê¸°ì¡´ batch_update íŒ¨í„´ ì¬ì‚¬ìš©
        chunk_size = 100
        for i in range(0, len(message_ids), chunk_size):
            chunk = message_ids[i:i+chunk_size]
            self._archive_chunk(chunk)

    def _archive_chunk(self, chunk):
        # ê¸°ì¡´ Celery task íŒ¨í„´ ì‚¬ìš©
        from src.tasks.email_tasks import archive_email_task
        for msg_id in chunk:
            archive_email_task.delay(msg_id)
"""
```

**ì½”ë“œë² ì´ìŠ¤ í†µí•© í”Œë¡œìš°**:

```mermaid
graph LR
    A[ìƒˆ ê¸°ëŠ¥ ìš”êµ¬ì‚¬í•­] --> B[ê¸°ì¡´ ì½”ë“œ ë¶„ì„]
    B --> C{ìœ ì‚¬ íŒ¨í„´ ì¡´ì¬?}
    C -->|Yes| D[íŒ¨í„´ ì¬ì‚¬ìš©]
    C -->|No| E[í”„ë¡œì íŠ¸ ìŠ¤íƒ€ì¼ ë”°ë¼ ì‹ ê·œ ì‘ì„±]
    D --> F[ê¸°ì¡´ í…ŒìŠ¤íŠ¸ íŒ¨í„´ ì ìš©]
    E --> F
    F --> G[ì½”ë“œ ë¦¬ë·° ì²´í¬ë¦¬ìŠ¤íŠ¸]
    G --> H[ì¼ê´€ì„± ê²€ì¦ í†µê³¼]
```

### Strategy 4: Ground in Your Libraries

**ëª©ì **: í”„ë¡œì íŠ¸ì— ì´ë¯¸ ì„¤ì¹˜ëœ ë¼ì´ë¸ŒëŸ¬ë¦¬ ìµœëŒ€ í™œìš©

**ì–¸ì œ ì‚¬ìš©í•˜ëŠ”ê°€?**
- ìƒˆ ì˜ì¡´ì„± ì¶”ê°€ ì „
- ê¸°ì¡´ ë¼ì´ë¸ŒëŸ¬ë¦¬ì˜ ìˆ¨ê²¨ì§„ ê¸°ëŠ¥ íƒìƒ‰
- ì˜ì¡´ì„± ë¹„ìš© ìµœì†Œí™” í•„ìš” ì‹œ

**êµ¬í˜„ ë°©ì‹**:

```python
# requirements.txt ë˜ëŠ” pyproject.toml ë¶„ì„
installed_libraries = {
    "httpx": {
        "version": "0.24.1",
        "capabilities": [
            "HTTP/2 support",
            "async/await native",
            "connection pooling",
            "retry mechanism built-in"
        ],
        "usage_in_project": [
            "src/api/client.py: ê¸°ë³¸ HTTP í´ë¼ì´ì–¸íŠ¸ë¡œ ì‚¬ìš©"
        ]
    },
    "tenacity": {
        "version": "8.2.3",
        "capabilities": [
            "retry with exponential backoff",
            "custom retry conditions",
            "async retry support"
        ],
        "potential_use": "Gmail API í˜¸ì¶œ ì¬ì‹œë„ ë¡œì§ì— í™œìš© ê°€ëŠ¥"
    },
    "sqlalchemy": {
        "version": "2.0.19",
        "capabilities": [
            "ORM with relationship loading",
            "bulk operations",
            "connection pooling"
        ],
        "current_use": "ì „ì²´ ë°ì´í„° ë ˆì´ì–´"
    }
}

# ê¸°ì¡´ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¡œ êµ¬í˜„
solution_with_existing = """
import httpx
from tenacity import retry, stop_after_attempt, wait_exponential

class GmailClient:
    def __init__(self):
        # ì´ë¯¸ ì‚¬ìš© ì¤‘ì¸ httpx í™œìš©
        self.client = httpx.AsyncClient(
            timeout=30.0,
            limits=httpx.Limits(
                max_keepalive_connections=5,
                max_connections=10
            )
        )

    @retry(
        stop=stop_after_attempt(3),
        wait=wait_exponential(multiplier=1, min=4, max=10)
    )
    async def archive_email(self, message_id):
        # tenacityë¡œ ìë™ ì¬ì‹œë„ (ìƒˆ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¶ˆí•„ìš”)
        response = await self.client.post(
            f'https://gmail.googleapis.com/gmail/v1/users/me/messages/{message_id}/modify',
            json={'removeLabelIds': ['INBOX']}
        )
        response.raise_for_status()
        return response.json()
"""

# ìƒˆ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì¶”ê°€ ë¶ˆí•„ìš”!
avoidable_dependencies = [
    "requests (httpxë¡œ ëŒ€ì²´ ê°€ëŠ¥)",
    "backoff (tenacityë¡œ ëŒ€ì²´ ê°€ëŠ¥)",
    "custom retry logic (tenacity í™œìš©)"
]
```

**ë¼ì´ë¸ŒëŸ¬ë¦¬ í™œìš© ê²°ì • íŠ¸ë¦¬**:

```mermaid
graph TB
    A[ìƒˆ ê¸°ëŠ¥ í•„ìš”] --> B{ê¸°ì¡´ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¡œ ê°€ëŠ¥?}
    B -->|Yes| C[ê¸°ì¡´ ë¼ì´ë¸ŒëŸ¬ë¦¬ ê¸°ëŠ¥ íƒìƒ‰]
    B -->|No| D{ì •ë§ ìƒˆ ì˜ì¡´ì„± í•„ìš”?}
    C --> E[ë¬¸ì„œ ë° ì˜ˆì œ í™•ì¸]
    E --> F[POC ì‘ì„±]
    F --> G{ì„±ëŠ¥/ê¸°ëŠ¥ ì¶©ì¡±?}
    G -->|Yes| H[ê¸°ì¡´ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì‚¬ìš©]
    G -->|No| D
    D -->|Yes| I[ìƒˆ ë¼ì´ë¸ŒëŸ¬ë¦¬ í‰ê°€]
    D -->|No| J[ì§ì ‘ êµ¬í˜„ ê³ ë ¤]
    I --> K[ì˜ì¡´ì„± ì¶”ê°€]
```

### Strategy 5: Study Git History

**ëª©ì **: ê³¼ê±° ì˜ì‚¬ê²°ì • ë° ë³€ê²½ ì´ìœ  íŒŒì•…

**ì–¸ì œ ì‚¬ìš©í•˜ëŠ”ê°€?**
- ë ˆê±°ì‹œ ì½”ë“œ ì´í•´ í•„ìš” ì‹œ
- ë²„ê·¸ì˜ ì›ì¸ ì¶”ì 
- ë¦¬íŒ©í† ë§ ì „ ì»¨í…ìŠ¤íŠ¸ íŒŒì•…

**êµ¬í˜„ ë°©ì‹**:

```bash
# Git history ë¶„ì„ ëª…ë ¹ì–´
git log --all --oneline --graph --decorate src/email/

# íŠ¹ì • íŒŒì¼ì˜ ë³€ê²½ ì´ë ¥
git log -p --follow src/email/archive.py

# í•¨ìˆ˜ë³„ ë³€ê²½ ì´ë ¥
git log -L :archive_emails:src/email/archive.py

# ëˆ„ê°€, ì™œ ë³€ê²½í–ˆëŠ”ì§€
git blame src/email/archive.py
```

```python
# Git history ë¶„ì„ ê²°ê³¼
git_analysis = {
    "file": "src/email/archive.py",
    "findings": [
        {
            "commit": "a3b5c7d",
            "date": "2023-08-15",
            "author": "senior-dev",
            "message": "Fix: Gmail API rate limit exceeded",
            "changes": """
- def archive_emails(ids):
-     for email_id in ids:
-         api.archive(email_id)  # ìˆœì°¨ ì²˜ë¦¬ â†’ ëŠë¦¼
+ def archive_emails(ids):
+     batch_size = 100
+     for i in range(0, len(ids), batch_size):
+         api.batch_archive(ids[i:i+batch_size])  # ë°°ì¹˜ ì²˜ë¦¬
            """,
            "lesson": "ìˆœì°¨ ì²˜ë¦¬ëŠ” rate limit ë°œìƒ â†’ ë°°ì¹˜ ì²˜ë¦¬ í•„ìˆ˜"
        },
        {
            "commit": "e8f2a1b",
            "date": "2023-09-22",
            "author": "devops-team",
            "message": "Add retry logic for transient failures",
            "changes": """
+ from tenacity import retry, stop_after_attempt
+
+ @retry(stop=stop_after_attempt(3))
  def batch_archive(ids):
      # ...
            """,
            "lesson": "Gmail APIëŠ” ì¼ì‹œì  ì‹¤íŒ¨ ë¹ˆë²ˆ â†’ ì¬ì‹œë„ ë¡œì§ í•„ìˆ˜"
        }
    ],
    "pattern_evolution": {
        "v1": "ë‹¨ìˆœ ìˆœì°¨ ì²˜ë¦¬ (2023-06)",
        "v2": "ë°°ì¹˜ ì²˜ë¦¬ ë„ì… (2023-08)",
        "v3": "ì¬ì‹œë„ ë¡œì§ ì¶”ê°€ (2023-09)",
        "v4": "í˜„ì¬ - ë³‘ë ¬ ì²˜ë¦¬ + ëª¨ë‹ˆí„°ë§ (2024-01)"
    }
}
```

**Git History ë¶„ì„ í”Œë¡œìš°**:

```mermaid
sequenceDiagram
    participant Alfred
    participant Git
    participant Analysis

    Alfred->>Git: git log -p --follow {file}
    Git-->>Alfred: ë³€ê²½ ì´ë ¥ ë°˜í™˜
    Alfred->>Analysis: íŒ¨í„´ ë¶„ì„
    Analysis->>Analysis: ì˜ì‚¬ê²°ì • ì´ìœ  ì¶”ë¡ 
    Analysis->>Analysis: ì‹¤íŒ¨/ì„±ê³µ íŒ¨í„´ ì¶”ì¶œ
    Analysis-->>Alfred: ì»¨í…ìŠ¤íŠ¸ ë³´ê³ 
    Alfred->>Alfred: ë™ì¼ ì‹¤ìˆ˜ ë°©ì§€ ì „ëµ ìˆ˜ë¦½
```

### Strategy 6: Vibe Prototype for Clarity

**ëª©ì **: ë¹ ë¥¸ í”„ë¡œí† íƒ€ì…ìœ¼ë¡œ ìš”êµ¬ì‚¬í•­ ëª…í™•í™”

**ì–¸ì œ ì‚¬ìš©í•˜ëŠ”ê°€?**
- ìš”êµ¬ì‚¬í•­ì´ ëª¨í˜¸í•  ë•Œ
- ì—¬ëŸ¬ UX ì˜µì…˜ ë¹„êµ í•„ìš” ì‹œ
- ì´í•´ê´€ê³„ì í”¼ë“œë°± í•„ìš” ì‹œ

**êµ¬í˜„ ë°©ì‹**:

```python
# 3ê°€ì§€ í”„ë¡œí† íƒ€ì… ë²„ì „ ìƒì„±
prototypes = {
    "version_a": {
        "approach": "Simple Sequential",
        "code": """
def archive_emails_v1(ids):
    for email_id in ids:
        gmail_api.archive(email_id)
        print(f'Archived: {email_id}')
        """,
        "pros": ["êµ¬í˜„ ë‹¨ìˆœ", "ë””ë²„ê¹… ì‰¬ì›€"],
        "cons": ["ëŠë¦¼ (53kê°œ = ~90ë¶„)", "ì§„í–‰ ìƒí™© ì €ì¥ ì—†ìŒ"]
    },
    "version_b": {
        "approach": "Batch with Progress",
        "code": """
def archive_emails_v2(ids):
    batch_size = 100
    for i in range(0, len(ids), batch_size):
        batch = ids[i:i+batch_size]
        gmail_api.batch_archive(batch)
        save_progress(i + len(batch))
        print(f'Progress: {i+len(batch)}/{len(ids)}')
        """,
        "pros": ["ë¹ ë¦„ (53kê°œ = ~15ë¶„)", "ì¤‘ë‹¨ ì‹œ ì¬ê°œ ê°€ëŠ¥"],
        "cons": ["ìˆœì°¨ ë°°ì¹˜ (ì—¬ì „íˆ ëŠë¦¼)"]
    },
    "version_c": {
        "approach": "Parallel + Monitoring",
        "code": """
from concurrent.futures import ThreadPoolExecutor

def archive_emails_v3(ids):
    batch_size = 100
    batches = [ids[i:i+batch_size] for i in range(0, len(ids), batch_size)]

    with ThreadPoolExecutor(max_workers=5) as executor:
        futures = [executor.submit(process_batch, b) for b in batches]
        for future in futures:
            future.result()
            update_dashboard()
        """,
        "pros": ["ë§¤ìš° ë¹ ë¦„ (53kê°œ = ~5ë¶„)", "ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§"],
        "cons": ["ë³µì¡ë„ ì¦ê°€", "Rate limit ê´€ë¦¬ í•„ìš”"]
    }
}

# ì‚¬ìš©ìì—ê²Œ í”„ë¡œí† íƒ€ì… ë°ëª¨
demo_results = {
    "user_feedback": "ë²„ì „ Cê°€ ì¢‹ì§€ë§Œ ì‹¤íŒ¨ ì‹œ ì–´ë–»ê²Œ ë˜ë‚˜ìš”?",
    "iteration": "ë²„ì „ C + ì²´í¬í¬ì¸íŠ¸ ì‹œìŠ¤í…œ ì¶”ê°€"
}
```

**í”„ë¡œí† íƒ€ì… ë¹„êµ í…Œì´ë¸”**:

| ë²„ì „ | ì†ë„ | ë³µì¡ë„ | ë³µêµ¬ ê°€ëŠ¥ | ëª¨ë‹ˆí„°ë§ | ì¶”ì²œë„ |
|------|------|--------|-----------|----------|--------|
| A | â­ | â­â­â­â­â­ | âŒ | âŒ | ğŸš« |
| B | â­â­â­ | â­â­â­ | âœ… | âš ï¸ | âš ï¸ |
| C | â­â­â­â­â­ | â­â­ | âœ… | âœ… | âœ… |

### Strategy 7: Synthesize with Options

**ëª©ì **: ì—¬ëŸ¬ ì†”ë£¨ì…˜ ë¹„êµ í›„ ìµœì ì•ˆ ì„ íƒ

**ì–¸ì œ ì‚¬ìš©í•˜ëŠ”ê°€?**
- íŠ¸ë ˆì´ë“œì˜¤í”„ê°€ ëª…í™•í•˜ì§€ ì•Šì„ ë•Œ
- ë¦¬ìŠ¤í¬ê°€ í° ì•„í‚¤í…ì²˜ ê²°ì • ì‹œ
- ë‹¤ì–‘í•œ ê¸°ìˆ  ìŠ¤íƒ ì˜µì…˜ ì¡´ì¬ ì‹œ

**êµ¬í˜„ ë°©ì‹**:

```python
# 3ê°€ì§€ ì•„í‚¤í…ì²˜ ì˜µì…˜ ë¶„ì„
options_analysis = {
    "option_1": {
        "name": "Synchronous REST API",
        "architecture": """
        Client -> Flask API -> Gmail API (sync)
               |
               v
          PostgreSQL
        """,
        "pros": [
            "êµ¬í˜„ ë‹¨ìˆœ",
            "ë””ë²„ê¹… ì‰¬ì›€",
            "ê¸°ì¡´ Flask ì¸í”„ë¼ ì¬ì‚¬ìš©"
        ],
        "cons": [
            "ìš”ì²­ë‹¹ 90ë¶„ ëŒ€ê¸° (53k ì´ë©”ì¼)",
            "API íƒ€ì„ì•„ì›ƒ ë°œìƒ",
            "ìŠ¤ì¼€ì¼ë§ ë¶ˆê°€"
        ],
        "complexity": 2,
        "performance": 1,
        "scalability": 1,
        "recommendation": "âŒ í”„ë¡œë•ì…˜ ë¶€ì í•©"
    },
    "option_2": {
        "name": "Async with Celery",
        "architecture": """
        Client -> Flask API -> Celery Queue -> Worker Pool
               |                                    |
               v                                    v
          PostgreSQL <----------------------- Gmail API
        """,
        "pros": [
            "ë¹„ë™ê¸° ì²˜ë¦¬ (ì¦‰ì‹œ ì‘ë‹µ)",
            "ìë™ ì¬ì‹œë„",
            "ì§„í–‰ ìƒí™© ì¶”ì ",
            "ê¸°ì¡´ Celery ì¸í”„ë¼ í™œìš©"
        ],
        "cons": [
            "Celery/Redis ì˜ì¡´ì„±",
            "ì›Œì»¤ ê´€ë¦¬ í•„ìš”",
            "ë³µì¡ë„ ì¦ê°€"
        ],
        "complexity": 6,
        "performance": 8,
        "scalability": 9,
        "recommendation": "âœ… ì¶”ì²œ (ê· í˜•ì¡íŒ ì†”ë£¨ì…˜)"
    },
    "option_3": {
        "name": "Serverless with AWS Lambda",
        "architecture": """
        Client -> API Gateway -> Lambda (parallel)
                                    |
                                    v
                              Gmail API + DynamoDB
        """,
        "pros": [
            "ìë™ ìŠ¤ì¼€ì¼ë§",
            "ì¸í”„ë¼ ê´€ë¦¬ ë¶ˆí•„ìš”",
            "ë¹„ìš© íš¨ìœ¨ì  (ì‚¬ìš©ëŸ‰ ê¸°ë°˜)"
        ],
        "cons": [
            "AWS ì˜ì¡´ì„± ì¦ê°€",
            "ë¡œì»¬ í…ŒìŠ¤íŠ¸ ì–´ë ¤ì›€",
            "Cold start ì§€ì—°",
            "ê¸°ì¡´ ì¸í”„ë¼ì™€ ë¶„ë¦¬"
        ],
        "complexity": 8,
        "performance": 9,
        "scalability": 10,
        "recommendation": "âš ï¸ í–¥í›„ ê³ ë ¤ (í˜„ì¬ëŠ” ê³¼ì‰)"
    }
}

# ì˜ì‚¬ê²°ì • ë§¤íŠ¸ë¦­ìŠ¤
decision_matrix = {
    "criteria": {
        "complexity": {"weight": 0.3, "scores": [2, 6, 8]},
        "performance": {"weight": 0.4, "scores": [1, 8, 9]},
        "scalability": {"weight": 0.2, "scores": [1, 9, 10]},
        "cost": {"weight": 0.1, "scores": [9, 7, 6]}
    },
    "weighted_scores": {
        "option_1": 2.1,  # ì œê±°
        "option_2": 7.4,  # ì„ íƒ! âœ…
        "option_3": 8.3   # í–¥í›„ ë§ˆì´ê·¸ë ˆì´ì…˜ ëŒ€ìƒ
    }
}
```

**ì˜µì…˜ ë¹„êµ ì‹œê°í™”**:

```mermaid
graph TB
    A[ì•„í‚¤í…ì²˜ ê²°ì •] --> B{ìš”êµ¬ì‚¬í•­ ë¶„ì„}
    B --> C[Option 1: Sync REST]
    B --> D[Option 2: Celery Async]
    B --> E[Option 3: Serverless]

    C --> F{ì„±ëŠ¥ ì¶©ì¡±?}
    D --> G{ë³µì¡ë„ ìˆ˜ìš© ê°€ëŠ¥?}
    E --> H{ì¸í”„ë¼ ë³€ê²½ ê°€ëŠ¥?}

    F -->|No| I[ì œê±°]
    G -->|Yes| J[ì„ íƒ! âœ…]
    H -->|No| K[í–¥í›„ ê³ ë ¤]

    J --> L[êµ¬í˜„ ì‹œì‘]
```

### Strategy 8: Review with Style Agents

**ëª©ì **: ë‹¤ì–‘í•œ ê´€ì ì—ì„œ ì½”ë“œ ë¦¬ë·°

**ì–¸ì œ ì‚¬ìš©í•˜ëŠ”ê°€?**
- ì¤‘ìš”í•œ ì½”ë“œ ë¨¸ì§€ ì „
- ì•„í‚¤í…ì²˜ ê²°ì • ìµœì¢… ê²€ì¦
- ë‹¤ì–‘í•œ ì „ë¬¸ê°€ ì˜ê²¬ í•„ìš” ì‹œ

**êµ¬í˜„ ë°©ì‹**:

```python
# 5ëª…ì˜ Style Agent ë¦¬ë·°ì–´
style_agents = {
    "security_expert": {
        "focus": "ë³´ì•ˆ ì·¨ì•½ì ",
        "review": """
ğŸ” Security Review:

1. âŒ API í‚¤ê°€ ì½”ë“œì— í•˜ë“œì½”ë”©ë¨
   - ìˆ˜ì •: í™˜ê²½ë³€ìˆ˜ ë˜ëŠ” secret manager ì‚¬ìš©

2. âš ï¸ Rate limit ì‹¤íŒ¨ ì‹œ ë¬´í•œ ì¬ì‹œë„
   - ìˆ˜ì •: ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜ ì œí•œ

3. âœ… HTTPS í†µì‹  í™•ì¸
4. âœ… ì…ë ¥ ê²€ì¦ ì ì ˆí•¨

Severity: MEDIUM (ìˆ˜ì • í•„ìš”)
        """
    },
    "performance_expert": {
        "focus": "ì„±ëŠ¥ ìµœì í™”",
        "review": """
âš¡ Performance Review:

1. âœ… ë°°ì¹˜ í¬ê¸° 100 ì ì ˆí•¨
2. âš ï¸ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì œí•œ ì—†ìŒ
   - 53k ì´ë©”ì¼ ID ì „ì²´ ë©”ëª¨ë¦¬ ë¡œë“œ (ì•½ 2MB)
   - ìˆ˜ì •: Generator íŒ¨í„´ìœ¼ë¡œ ë³€ê²½

3. âœ… ì—°ê²° í’€ ì‚¬ìš©
4. âŒ ë°ì´í„°ë² ì´ìŠ¤ N+1 ì¿¼ë¦¬ ë°œìƒ
   - ìˆ˜ì •: bulk_update_mappings ì‚¬ìš©

Optimization Score: 7/10
        """
    },
    "maintainability_expert": {
        "focus": "ìœ ì§€ë³´ìˆ˜ì„±",
        "review": """
ğŸ› ï¸ Maintainability Review:

1. âœ… í•¨ìˆ˜ ë¶„ë¦¬ ì˜ ë¨
2. âš ï¸ ì—ëŸ¬ ì²˜ë¦¬ ë¡œì§ ë¶„ì‚°
   - ìˆ˜ì •: í†µí•© ì—ëŸ¬ í•¸ë“¤ëŸ¬ ìƒì„±

3. âŒ í…ŒìŠ¤íŠ¸ ì»¤ë²„ë¦¬ì§€ ë¶€ì¡± (43%)
   - ìµœì†Œ 80% í•„ìš”

4. âœ… íƒ€ì… íŒíŒ… ì ì ˆ
5. âš ï¸ ë¬¸ì„œ ë¶€ì¡± (docstring ì—†ìŒ)

Maintainability Score: 6/10
        """
    },
    "scalability_expert": {
        "focus": "í™•ì¥ì„±",
        "review": """
ğŸ“ˆ Scalability Review:

1. âœ… ë³‘ë ¬ ì²˜ë¦¬ ê°€ëŠ¥
2. âœ… ìƒíƒœ ì €ì¥ (ì¬ì‹œì‘ ê°€ëŠ¥)
3. âš ï¸ ë‹¨ì¼ ì¸ìŠ¤í„´ìŠ¤ ì œí•œ
   - ìˆ˜ì •: ë¶„ì‚° ë½ ë©”ì»¤ë‹ˆì¦˜ ì¶”ê°€

4. âŒ í•˜ë“œì½”ë”©ëœ ì›Œì»¤ ìˆ˜ (5ê°œ)
   - ìˆ˜ì •: í™˜ê²½ë³€ìˆ˜ë¡œ ì„¤ì • ê°€ëŠ¥í•˜ê²Œ

Future-proof Score: 7/10
        """
    },
    "reliability_expert": {
        "focus": "ì•ˆì •ì„±",
        "review": """
ğŸ›¡ï¸ Reliability Review:

1. âœ… ì¬ì‹œë„ ë¡œì§ ì¡´ì¬
2. âš ï¸ ë¶€ë¶„ ì‹¤íŒ¨ ì‹œ ë¡¤ë°± ì—†ìŒ
   - ìˆ˜ì •: íŠ¸ëœì­ì…˜ ê´€ë¦¬ ì¶”ê°€

3. âŒ ëª¨ë‹ˆí„°ë§/ë¡œê¹… ë¶€ì¡±
   - ìˆ˜ì •: êµ¬ì¡°í™”ëœ ë¡œê¹… ì¶”ê°€

4. âš ï¸ Health check ì—”ë“œí¬ì¸íŠ¸ ì—†ìŒ
5. âœ… íƒ€ì„ì•„ì›ƒ ì„¤ì • ì ì ˆ

Reliability Score: 6/10
        """
    }
}

# í†µí•© ë¦¬ë·° ê²°ê³¼
consolidated_review = {
    "overall_score": 6.4,
    "verdict": "NEEDS_IMPROVEMENT",
    "critical_issues": [
        "í•˜ë“œì½”ë”©ëœ API í‚¤",
        "í…ŒìŠ¤íŠ¸ ì»¤ë²„ë¦¬ì§€ ë¶€ì¡±",
        "ëª¨ë‹ˆí„°ë§ ë¶€ì¬"
    ],
    "action_items": [
        "1. API í‚¤ í™˜ê²½ë³€ìˆ˜ ì´ë™ (ì¦‰ì‹œ)",
        "2. í…ŒìŠ¤íŠ¸ ì‘ì„± (80% ì´ìƒ)",
        "3. êµ¬ì¡°í™”ëœ ë¡œê¹… ì¶”ê°€",
        "4. ì—ëŸ¬ í•¸ë“¤ëŸ¬ í†µí•©",
        "5. Health check ì—”ë“œí¬ì¸íŠ¸ ì¶”ê°€"
    ]
}
```

**Multi-Agent Review í”Œë¡œìš°**:

```mermaid
graph LR
    A[ì½”ë“œ ì™„ì„±] --> B[Security Agent]
    A --> C[Performance Agent]
    A --> D[Maintainability Agent]
    A --> E[Scalability Agent]
    A --> F[Reliability Agent]

    B --> G[Issue ìˆ˜ì§‘]
    C --> G
    D --> G
    E --> G
    F --> G

    G --> H{Critical Issue?}
    H -->|Yes| I[ìˆ˜ì • í•„ìˆ˜]
    H -->|No| J{Score >= 8.0?}
    J -->|Yes| K[ìŠ¹ì¸]
    J -->|No| L[ê°œì„  ê¶Œì¥]
```

## ë³‘ë ¬ ì—°êµ¬ ì‘ì—… ì‹œìŠ¤í…œ

### Research Orchestrator

**ì—­í• **: ì—¬ëŸ¬ ì—°êµ¬ ì „ëµì„ ë™ì‹œì— ì‹¤í–‰í•˜ê³  ê²°ê³¼ í†µí•©

```python
# research-orchestrator êµ¬í˜„
from concurrent.futures import ThreadPoolExecutor
from typing import List, Dict

class ResearchOrchestrator:
    def __init__(self):
        self.strategies = {
            1: ReproduceDocumentStrategy(),
            2: BestPracticesStrategy(),
            3: CodebaseGroundingStrategy(),
            4: LibraryGroundingStrategy(),
            5: GitHistoryStrategy(),
            6: VibePrototypeStrategy(),
            7: SynthesizeOptionsStrategy(),
            8: StyleAgentReviewStrategy()
        }

    def research(self, problem: str, strategy_ids: List[int]) -> Dict:
        """ë³‘ë ¬ë¡œ ì—¬ëŸ¬ ì „ëµ ì‹¤í–‰"""
        with ThreadPoolExecutor(max_workers=4) as executor:
            futures = {
                executor.submit(
                    self.strategies[sid].execute, problem
                ): sid
                for sid in strategy_ids
            }

            results = {}
            for future in futures:
                strategy_id = futures[future]
                results[strategy_id] = future.result()

        return self.synthesize_results(results)

    def synthesize_results(self, results: Dict) -> Dict:
        """ê²°ê³¼ í†µí•© ë° ì¶©ëŒ í•´ê²°"""
        synthesis = {
            "findings": [],
            "recommendations": [],
            "conflicts": []
        }

        # ëª¨ë“  ê²°ê³¼ ë³‘í•©
        for strategy_id, result in results.items():
            synthesis["findings"].extend(result.get("findings", []))
            synthesis["recommendations"].extend(result.get("recommendations", []))

        # ì¶©ëŒí•˜ëŠ” ê¶Œì¥ì‚¬í•­ í•´ê²°
        synthesis["conflicts"] = self.detect_conflicts(
            synthesis["recommendations"]
        )

        # ìµœì¢… ê¶Œì¥ì‚¬í•­ ìƒì„±
        synthesis["final_recommendation"] = self.resolve_conflicts(
            synthesis["conflicts"]
        )

        return synthesis
```

**ì‹¤í–‰ ì˜ˆì‹œ**:

```python
# Alfredê°€ ë³µì¡í•œ ë¬¸ì œ ê°ì§€
problem = "53,000ê°œ ì´ë©”ì¼ì„ ì•ˆì „í•˜ê²Œ ì•„ì¹´ì´ë¸Œí•˜ëŠ” ì‹œìŠ¤í…œ ì„¤ê³„"

# ë³‘ë ¬ ì—°êµ¬ ì‹œì‘
orchestrator = ResearchOrchestrator()
research_result = orchestrator.research(
    problem=problem,
    strategy_ids=[1, 2, 3, 5, 7]  # 5ê°œ ì „ëµ ë™ì‹œ ì‹¤í–‰
)

# ê²°ê³¼:
{
    "findings": [
        "Gmail APIëŠ” ë°°ì¹˜ë‹¹ 100ê°œ ì œí•œ (Strategy 1)",
        "Rate limit: 250 req/s (Strategy 1)",
        "í”„ë¡œì íŠ¸ì— Celery ì„¤ì •ë¨ (Strategy 3)",
        "ê³¼ê±° ìˆœì°¨ ì²˜ë¦¬ ì‹œ ì‹¤íŒ¨ ì´ë ¥ (Strategy 5)",
        "3ê°€ì§€ ì•„í‚¤í…ì²˜ ì˜µì…˜ í‰ê°€ ì™„ë£Œ (Strategy 7)"
    ],
    "recommendations": [
        "Celery + Redisë¡œ ë¹„ë™ê¸° ì²˜ë¦¬",
        "ë°°ì¹˜ í¬ê¸° 100, ì›Œì»¤ 5ê°œ",
        "ì²´í¬í¬ì¸íŠ¸ ì‹œìŠ¤í…œìœ¼ë¡œ ë³µêµ¬ ê°€ëŠ¥í•˜ê²Œ",
        "êµ¬ì¡°í™”ëœ ë¡œê¹… ë° ëª¨ë‹ˆí„°ë§"
    ],
    "conflicts": [],
    "final_recommendation": {
        "architecture": "Celery-based async processing",
        "implementation_plan": "...",
        "estimated_duration": "5ë¶„ (53k ì´ë©”ì¼)"
    }
}
```

### Knowledge Synthesizer

**ì—­í• **: ì¤‘ë³µ/ì¶©ëŒ ì œê±° ë° ì¼ê´€ëœ ê²°ë¡  ë„ì¶œ

```python
class KnowledgeSynthesizer:
    def __init__(self):
        self.knowledge_base = []

    def add_finding(self, finding: Dict):
        """ìƒˆ ë°œê²¬ ì¶”ê°€ (ì¤‘ë³µ ì²´í¬)"""
        if not self.is_duplicate(finding):
            self.knowledge_base.append(finding)

    def is_duplicate(self, finding: Dict) -> bool:
        """ì˜ë¯¸ë¡ ì  ì¤‘ë³µ ê²€ì‚¬"""
        for existing in self.knowledge_base:
            similarity = self.calculate_similarity(
                finding, existing
            )
            if similarity > 0.8:
                return True
        return False

    def resolve_conflicts(self, findings: List[Dict]) -> Dict:
        """ì¶©ëŒ í•´ê²° ì•Œê³ ë¦¬ì¦˜"""
        conflicts = self.detect_conflicts(findings)

        for conflict in conflicts:
            # ì¦ê±° ê¸°ë°˜ ìš°ì„ ìˆœìœ„
            # 1. ê³µì‹ ë¬¸ì„œ > 2. ì½”ë“œë² ì´ìŠ¤ > 3. Best practices
            resolution = self.prioritize_by_evidence(
                conflict["options"]
            )
            conflict["resolution"] = resolution

        return {
            "conflicts": conflicts,
            "final_strategy": self.build_coherent_plan(conflicts)
        }

    def build_coherent_plan(self, resolved_conflicts: List[Dict]) -> Dict:
        """ì¼ê´€ëœ ì‹¤í–‰ ê³„íš ìƒì„±"""
        plan = {
            "architecture": None,
            "implementation_steps": [],
            "risk_mitigation": [],
            "success_criteria": []
        }

        # í•´ê²°ëœ ì¶©ëŒì„ ê¸°ë°˜ìœ¼ë¡œ ê³„íš êµ¬ì„±
        for conflict in resolved_conflicts:
            plan["architecture"] = conflict["resolution"]["architecture"]
            plan["implementation_steps"].extend(
                conflict["resolution"]["steps"]
            )

        return plan
```

**ì¶©ëŒ í•´ê²° ì˜ˆì‹œ**:

```python
# ì¶©ëŒ ìƒí™©
conflict = {
    "issue": "ë°°ì¹˜ í¬ê¸° ê²°ì •",
    "options": [
        {
            "source": "Strategy 1 (Gmail API docs)",
            "recommendation": "ë°°ì¹˜ í¬ê¸° 100 (API ì œí•œ)",
            "evidence_level": "official_docs"
        },
        {
            "source": "Strategy 3 (Codebase)",
            "recommendation": "ë°°ì¹˜ í¬ê¸° 50 (ê¸°ì¡´ íŒ¨í„´)",
            "evidence_level": "existing_code"
        },
        {
            "source": "Strategy 2 (Best Practices)",
            "recommendation": "ë°°ì¹˜ í¬ê¸° 200 (ì„±ëŠ¥ ìµœì í™”)",
            "evidence_level": "industry_standard"
        }
    ]
}

# í•´ê²° ê³¼ì •
synthesizer = KnowledgeSynthesizer()
resolution = synthesizer.resolve_conflicts([conflict])

# ê²°ê³¼:
{
    "decision": "ë°°ì¹˜ í¬ê¸° 100 ì‚¬ìš©",
    "rationale": "ê³µì‹ API ì œí•œ(100)ì„ ì¤€ìˆ˜í•´ì•¼ í•¨. Best Practices ê¶Œì¥(200)ì€ API ì œì•½ìœ¼ë¡œ ë¶ˆê°€ëŠ¥. ê¸°ì¡´ ì½”ë“œ(50)ëŠ” ë¹„íš¨ìœ¨ì ì´ë¯€ë¡œ ì—…ê·¸ë ˆì´ë“œ.",
    "action": "ê¸°ì¡´ ì½”ë“œë¥¼ 50 â†’ 100ìœ¼ë¡œ ë³€ê²½"
}
```

## í•™ìŠµ ë° ë³µë¦¬ íš¨ê³¼

### Knowledge Accumulation

AlfredëŠ” í”„ë¡œì íŠ¸ ì§„í–‰ì— ë”°ë¼ ì§€ì‹ì„ ëˆ„ì í•˜ê³  ì¬ì‚¬ìš©í•©ë‹ˆë‹¤.

```python
# Knowledge Graph êµ¬ì¡°
knowledge_graph = {
    "nodes": [
        {
            "id": "gmail_api_rate_limit",
            "type": "constraint",
            "content": "250 requests/second",
            "learned_from": "Strategy 1 (2024-01-15)",
            "confidence": 0.95
        },
        {
            "id": "celery_pattern",
            "type": "implementation_pattern",
            "content": "Async task with retry",
            "learned_from": "Strategy 3 (2024-01-15)",
            "confidence": 0.90
        },
        {
            "id": "batch_processing",
            "type": "best_practice",
            "content": "Chunk large datasets",
            "learned_from": "Strategy 2 (2024-01-15)",
            "confidence": 0.85
        }
    ],
    "edges": [
        {
            "from": "gmail_api_rate_limit",
            "to": "batch_processing",
            "relation": "requires"
        },
        {
            "from": "batch_processing",
            "to": "celery_pattern",
            "relation": "implemented_by"
        }
    ]
}

# ë‹¤ìŒ ì‘ì—…ì—ì„œ ì¬ì‚¬ìš©
next_task = "Google Drive íŒŒì¼ 10,000ê°œ ë‹¤ìš´ë¡œë“œ"

# Alfredê°€ ì´ë¯¸ ì•Œê³  ìˆëŠ” ì§€ì‹ í™œìš©
reused_knowledge = [
    "gmail_api_rate_limit â†’ Google APIë„ ë¹„ìŠ·í•œ ì œí•œ ìˆì„ ê²ƒ",
    "batch_processing â†’ ë™ì¼ íŒ¨í„´ ì ìš© ê°€ëŠ¥",
    "celery_pattern â†’ ë™ì¼ ì¸í”„ë¼ ì¬ì‚¬ìš©"
]

# ìƒˆ ì‘ì—…ì˜ ì—°êµ¬ ì‹œê°„ ë‹¨ì¶•
research_time = {
    "without_knowledge": "60ë¶„",
    "with_accumulated_knowledge": "15ë¶„",
    "savings": "75%"
}
```

**í•™ìŠµ ê³¡ì„ **:

```mermaid
graph LR
    A[Task 1: ì´ë©”ì¼ ì•„ì¹´ì´ë¸Œ] --> B[60ë¶„ ì—°êµ¬]
    B --> C[ì§€ì‹ ëˆ„ì  1]

    C --> D[Task 2: Drive ë‹¤ìš´ë¡œë“œ]
    D --> E[15ë¶„ ì—°êµ¬]
    E --> F[ì§€ì‹ ëˆ„ì  2]

    F --> G[Task 3: Calendar ë™ê¸°í™”]
    G --> H[5ë¶„ ì—°êµ¬]
    H --> I[ì§€ì‹ ëˆ„ì  3]

    style C fill:#90EE90
    style F fill:#7CFC00
    style I fill:#32CD32
```

### Adaptive Intelligence

AlfredëŠ” ì‹¤íŒ¨ë¡œë¶€í„° í•™ìŠµí•˜ê³  ì „ëµì„ ê°œì„ í•©ë‹ˆë‹¤.

```python
# ì ì‘í˜• í•™ìŠµ ì‹œìŠ¤í…œ
class AdaptiveLearningSystem:
    def __init__(self):
        self.success_patterns = []
        self.failure_patterns = []

    def record_outcome(self, task: Dict, outcome: str):
        """ì‘ì—… ê²°ê³¼ ê¸°ë¡"""
        record = {
            "task": task,
            "strategies_used": task["strategies"],
            "outcome": outcome,  # "success" | "failure"
            "timestamp": datetime.now()
        }

        if outcome == "success":
            self.success_patterns.append(record)
        else:
            self.failure_patterns.append(record)

    def recommend_strategies(self, new_task: Dict) -> List[int]:
        """ìœ ì‚¬í•œ ê³¼ê±° ì‘ì—… ê¸°ë°˜ ì „ëµ ì¶”ì²œ"""
        similar_tasks = self.find_similar_tasks(new_task)

        # ì„±ê³µë¥  ê¸°ë°˜ ì „ëµ ìˆœìœ„
        strategy_scores = {}
        for task in similar_tasks:
            for strategy_id in task["strategies_used"]:
                if task["outcome"] == "success":
                    strategy_scores[strategy_id] = strategy_scores.get(
                        strategy_id, 0
                    ) + 1
                else:
                    strategy_scores[strategy_id] = strategy_scores.get(
                        strategy_id, 0
                    ) - 0.5

        # ìƒìœ„ ì „ëµ ë°˜í™˜
        recommended = sorted(
            strategy_scores.items(),
            key=lambda x: x[1],
            reverse=True
        )

        return [sid for sid, score in recommended if score > 0]

    def learn_from_failure(self, failed_task: Dict):
        """ì‹¤íŒ¨ íŒ¨í„´ ë¶„ì„ ë° ê°œì„ """
        analysis = {
            "root_cause": self.identify_root_cause(failed_task),
            "missing_strategy": self.identify_missing_strategy(failed_task),
            "improvement": self.generate_improvement_plan(failed_task)
        }

        # ê°œì„ ì‚¬í•­ì„ ë‹¤ìŒ ì‘ì—…ì— ì ìš©
        self.apply_learnings(analysis)

        return analysis
```

**ì ì‘ ì‚¬ë¡€**:

```python
# ì²« ë²ˆì§¸ ì‹œë„ (ì‹¤íŒ¨)
task_v1 = {
    "goal": "ëŒ€ìš©ëŸ‰ íŒŒì¼ ì—…ë¡œë“œ",
    "strategies_used": [1, 2],  # ë¬¸ì„œ + Best Practices
    "outcome": "failure",
    "error": "Memory overflow"
}

alfred.learning_system.record_outcome(task_v1, "failure")
analysis = alfred.learning_system.learn_from_failure(task_v1)

# ë¶„ì„ ê²°ê³¼:
{
    "root_cause": "ë©”ëª¨ë¦¬ ê´€ë¦¬ ì „ëµ ëˆ„ë½",
    "missing_strategy": "Strategy 3 (ì½”ë“œë² ì´ìŠ¤ì— ìŠ¤íŠ¸ë¦¬ë° íŒ¨í„´ ì¡´ì¬)",
    "improvement": "ë‹¤ìŒë¶€í„° ëŒ€ìš©ëŸ‰ ë°ì´í„° ì‘ì—… ì‹œ Strategy 3 í•„ìˆ˜ í¬í•¨"
}

# ë‘ ë²ˆì§¸ ìœ ì‚¬ ì‘ì—… (ì„±ê³µ)
task_v2 = {
    "goal": "ëŒ€ìš©ëŸ‰ ë°ì´í„° export",
    "strategies_used": [1, 2, 3],  # Strategy 3 ì¶”ê°€!
    "outcome": "success"
}

# Alfredê°€ í•™ìŠµí•¨: ëŒ€ìš©ëŸ‰ ì‘ì—… = Strategy 3 í•„ìˆ˜
```

## ì‹¤ì œ ì‚¬ë¡€ ì—°êµ¬

### ì‚¬ë¡€ 1: ì´ë©”ì¼ 53,000ê°œ ì•„ì¹´ì´ë¸Œ

**ì´ˆê¸° ìš”ì²­**:
> "Gmail ê³„ì •ì˜ ì˜¤ë˜ëœ ì´ë©”ì¼ 53,000ê°œë¥¼ ìë™ìœ¼ë¡œ ì•„ì¹´ì´ë¸Œ í•´ì¤˜"

**Alfredì˜ ì ‘ê·¼**:

```python
# Step 1: ë¬¸ì œ ë³µì¡ë„ í‰ê°€
complexity_assessment = {
    "volume": "high (53,000ê°œ)",
    "api_constraints": "unknown",
    "time_sensitivity": "medium",
    "risk": "data loss ê°€ëŠ¥ì„±",
    "decision": "Senior Engineer Thinking í™œì„±í™”"
}

# Step 2: ë³‘ë ¬ ì—°êµ¬ ì „ëµ ì„ íƒ
alfred.activate_research([1, 2, 3, 5, 7])

# Step 3: ì—°êµ¬ ê²°ê³¼
research_findings = {
    "strategy_1_results": {
        "api_limit": "ë°°ì¹˜ë‹¹ 100ê°œ",
        "rate_limit": "250 req/s",
        "error_handling": "429 Too Many Requests ë¹ˆë²ˆ"
    },
    "strategy_2_results": {
        "best_practice": "Producer-Consumer íŒ¨í„´",
        "retry_logic": "Exponential backoff í•„ìˆ˜",
        "monitoring": "ì§„í–‰ ìƒí™© ì¶”ì  ì¤‘ìš”"
    },
    "strategy_3_results": {
        "existing_celery": "í”„ë¡œì íŠ¸ì— Celery ì„¤ì •ë¨",
        "db_pattern": "bulk_update_mappings ì‚¬ìš© ì¤‘",
        "testing": "pytest + pytest-mock"
    },
    "strategy_5_results": {
        "past_failure": "2023-08 ìˆœì°¨ ì²˜ë¦¬ë¡œ rate limit ë°œìƒ",
        "lesson": "ë°°ì¹˜ ì²˜ë¦¬ í•„ìˆ˜"
    },
    "strategy_7_results": {
        "options": ["Sync", "Celery Async", "Serverless"],
        "recommendation": "Celery Async (ê· í˜•)"
    }
}

# Step 4: í†µí•© ì†”ë£¨ì…˜ ìƒì„±
final_solution = {
    "architecture": "Celery + Redis + PostgreSQL",
    "implementation": """
# tasks.py
from celery import Celery
from tenacity import retry, stop_after_attempt

app = Celery('gmail_tasks', broker='redis://localhost:6379')

@app.task(bind=True)
@retry(stop=stop_after_attempt(3))
def archive_batch(self, batch_ids):
    '''100ê°œì”© ë°°ì¹˜ ì²˜ë¦¬'''
    rate_limiter.acquire()
    gmail_api.batch_modify(
        batch_ids,
        {'removeLabelIds': ['INBOX']}
    )
    save_checkpoint(len(batch_ids))

# main.py
def archive_all_emails():
    email_ids = fetch_email_ids()  # 53,000ê°œ
    batches = chunk(email_ids, 100)

    for batch in batches:
        archive_batch.delay(batch)  # Celery queueì— ì¶”ê°€
    """,
    "results": {
        "duration": "ì•½ 5ë¶„",
        "success_rate": "99.8%",
        "failures_handled": "ìë™ ì¬ì‹œë„ë¡œ í•´ê²°"
    }
}
```

### ì‚¬ë¡€ 2: ë©€í‹°í…Œë„ŒíŠ¸ ì¸ì¦ ì‹œìŠ¤í…œ

**ì´ˆê¸° ìš”ì²­**:
> "SaaS ì œí’ˆì— ë©€í‹°í…Œë„ŒíŠ¸ ì¸ì¦ ì‹œìŠ¤í…œ ì¶”ê°€í•´ì¤˜"

**Alfredì˜ ì ‘ê·¼**:

```python
# Step 1: ë³´ì•ˆ ì¤‘ìš”ë„ í‰ê°€
security_assessment = {
    "sensitivity": "critical (ì¸ì¦/ì¸ê°€)",
    "compliance": "GDPR, SOC2 í•„ìš”",
    "scalability": "ìˆ˜ì²œ ê°œ í…Œë„ŒíŠ¸ ì˜ˆìƒ",
    "decision": "Strategy 2 + 4 + 8 í™œì„±í™”"
}

# Step 2: ì—°êµ¬ ìˆ˜í–‰
research_process = {
    "strategy_2": {
        "best_practices": [
            "OAuth 2.0 / OpenID Connect í‘œì¤€",
            "JWT with refresh tokens",
            "Row-level security (RLS)",
            "OWASP Authentication Cheat Sheet"
        ]
    },
    "strategy_4": {
        "existing_libraries": [
            "authlib (OAuth/OIDC)",
            "PyJWT (JWT ì²˜ë¦¬)",
            "SQLAlchemy (RLS ì§€ì›)",
            "Redis (ì„¸ì…˜ ì €ì¥)"
        ],
        "recommendation": "ìƒˆ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¶ˆí•„ìš”, ê¸°ì¡´ìœ¼ë¡œ ì¶©ë¶„"
    },
    "strategy_8": {
        "security_agent": "âŒ JWT secret í™˜ê²½ë³€ìˆ˜ í•„ìˆ˜",
        "performance_agent": "âœ… Redis ìºì‹± ì ì ˆ",
        "scalability_agent": "âš ï¸ í…Œë„ŒíŠ¸ ê²©ë¦¬ DB ìƒ¤ë”© ê³ ë ¤",
        "reliability_agent": "âŒ Token rotation ë¯¸êµ¬í˜„"
    }
}

# Step 3: í†µí•© ì•„í‚¤í…ì²˜
architecture = """
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚             API Gateway                      â”‚
â”‚  (Rate limiting, CORS, API ë²„ì „ ê´€ë¦¬)         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                           â”‚
â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”
â”‚ Auth Service â”‚    â”‚ Resource API   â”‚
â”‚              â”‚    â”‚                â”‚
â”‚ - OAuth 2.0  â”‚    â”‚ - RLS ì ìš©     â”‚
â”‚ - JWT ë°œê¸‰   â”‚    â”‚ - Tenant ê²©ë¦¬  â”‚
â”‚ - Refresh    â”‚    â”‚                â”‚
â””â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚                       â”‚
â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”
â”‚      PostgreSQL (RLS í™œì„±í™”)     â”‚
â”‚  tenant_idë¡œ ìë™ ê²©ë¦¬           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
"""

# Step 4: êµ¬í˜„ (RLS ì˜ˆì œ)
implementation = '''
-- PostgreSQL RLS ì„¤ì •
CREATE TABLE users (
    id UUID PRIMARY KEY,
    tenant_id UUID NOT NULL,
    email TEXT NOT NULL,
    UNIQUE(tenant_id, email)
);

-- RLS ì •ì±… í™œì„±í™”
ALTER TABLE users ENABLE ROW LEVEL SECURITY;

-- ì •ì±…: ìì‹ ì˜ í…Œë„ŒíŠ¸ë§Œ ì ‘ê·¼
CREATE POLICY tenant_isolation ON users
    USING (tenant_id = current_setting('app.current_tenant_id')::UUID);

-- Pythonì—ì„œ í…Œë„ŒíŠ¸ ì„¤ì •
def set_tenant_context(tenant_id: str):
    db.execute(
        text("SET app.current_tenant_id = :tenant_id"),
        {"tenant_id": tenant_id}
    )

# API í•¸ë“¤ëŸ¬
@app.post("/api/users")
@require_auth
def create_user(request):
    # JWTì—ì„œ tenant_id ì¶”ì¶œ
    tenant_id = request.user.tenant_id

    # RLS ì»¨í…ìŠ¤íŠ¸ ì„¤ì •
    set_tenant_context(tenant_id)

    # ì´ì œ ìë™ìœ¼ë¡œ tenant_id ê²©ë¦¬ ì ìš©!
    user = User(email=request.json["email"])
    db.add(user)
    db.commit()
'''
}
```

### ì‚¬ë¡€ 3: ë ˆê±°ì‹œ API ì„±ëŠ¥ ìµœì í™”

**ì´ˆê¸° ìš”ì²­**:
> "ì´ API ì—”ë“œí¬ì¸íŠ¸ê°€ ë„ˆë¬´ ëŠë ¤. 10ì´ˆ â†’ 1ì´ˆë¡œ ìµœì í™” í•´ì¤˜"

**Alfredì˜ ì ‘ê·¼**:

```python
# Step 1: ì„±ëŠ¥ í”„ë¡œíŒŒì¼ë§
profiling = {
    "current_performance": "10.3ì´ˆ (95 percentile)",
    "target": "1ì´ˆ ë¯¸ë§Œ",
    "decision": "Strategy 3 + 5 + 6 í™œì„±í™”"
}

# Step 2: ê¸°ì¡´ ì½”ë“œ ë° Git íˆìŠ¤í† ë¦¬ ë¶„ì„
analysis = {
    "strategy_3_findings": {
        "n_plus_1_queries": "ë°œê²¬ë¨ (15ê°œ ì¿¼ë¦¬)",
        "missing_indexes": "3ê°œ í•„ë“œ ì¸ë±ìŠ¤ ì—†ìŒ",
        "full_table_scan": "100ë§Œ í–‰ ìŠ¤ìº”"
    },
    "strategy_5_findings": {
        "git_history": [
            "2022-03: ì´ˆê¸° êµ¬í˜„ (ë‹¨ìˆœ ì¿¼ë¦¬)",
            "2023-06: JOIN 3ê°œ ì¶”ê°€ (ì„±ëŠ¥ ì €í•˜ ì‹œì‘)",
            "2023-12: í•„í„° ì¡°ê±´ ì¶”ê°€ (ë” ì•…í™”)"
        ],
        "lesson": "ì ì§„ì  ì„±ëŠ¥ ì €í•˜, ëª¨ë‹ˆí„°ë§ ë¶€ì¬"
    }
}

# Step 3: í”„ë¡œí† íƒ€ì… 3ê°œ ìƒì„± (Strategy 6)
prototypes = {
    "v1_add_indexes": {
        "changes": "3ê°œ ì¸ë±ìŠ¤ ì¶”ê°€",
        "expected": "3ì´ˆ",
        "actual_test": "2.8ì´ˆ",
        "pros": "ê°„ë‹¨, ìœ„í—˜ ë‚®ìŒ",
        "cons": "ëª©í‘œ ë¯¸ë‹¬"
    },
    "v2_eager_loading": {
        "changes": "N+1 ì œê±° + ì¸ë±ìŠ¤",
        "expected": "1ì´ˆ",
        "actual_test": "0.9ì´ˆ",
        "pros": "ëª©í‘œ ë‹¬ì„±!",
        "cons": "ì½”ë“œ ë³µì¡ë„ ì¦ê°€"
    },
    "v3_caching": {
        "changes": "Redis ìºì‹± ì¶”ê°€",
        "expected": "0.1ì´ˆ",
        "actual_test": "0.05ì´ˆ",
        "pros": "ë§¤ìš° ë¹ ë¦„",
        "cons": "ìºì‹œ ë¬´íš¨í™” ë³µì¡, ë©”ëª¨ë¦¬ ë¹„ìš©"
    }
}

# Step 4: ìµœì¢… ì„ íƒ ë° êµ¬í˜„
decision = {
    "choice": "v2 (Eager Loading + Indexes)",
    "rationale": "ëª©í‘œ ë‹¬ì„± + ë³µì¡ë„ ìˆ˜ìš© ê°€ëŠ¥",
    "future": "v3 ìºì‹±ì€ íŠ¸ë˜í”½ ì¦ê°€ ì‹œ ì¶”ê°€"
}

# êµ¬í˜„
optimized_code = '''
# Before (10ì´ˆ)
def get_user_dashboard(user_id):
    user = User.query.get(user_id)
    posts = Post.query.filter_by(user_id=user_id).all()  # N+1 ì‹œì‘
    for post in posts:
        post.comments  # N+1 ë°œìƒ!
        for comment in post.comments:
            comment.author  # ë˜ N+1!
    return render_dashboard(user, posts)

# After (0.9ì´ˆ)
def get_user_dashboard(user_id):
    user = User.query.get(user_id)
    posts = (
        Post.query
        .filter_by(user_id=user_id)
        .options(
            joinedload(Post.comments)
            .joinedload(Comment.author)
        )  # Eager loadingìœ¼ë¡œ ë‹¨ì¼ ì¿¼ë¦¬
        .all()
    )
    return render_dashboard(user, posts)

# ì¶”ê°€ëœ ì¸ë±ìŠ¤
db.execute("""
    CREATE INDEX idx_posts_user_id ON posts(user_id);
    CREATE INDEX idx_comments_post_id ON comments(post_id);
    CREATE INDEX idx_comments_author_id ON comments(author_id);
""")
'''

results = {
    "performance": "10.3ì´ˆ â†’ 0.9ì´ˆ (91% ê°œì„ )",
    "queries": "15ê°œ â†’ 1ê°œ",
    "db_load": "95% ê°ì†Œ"
}
```

## MoAI-ADK ì›Œí¬í”Œë¡œìš° í†µí•©

Senior Engineer Thinkingì€ MoAI-ADKì˜ ëª¨ë“  ë‹¨ê³„ì— ìì—°ìŠ¤ëŸ½ê²Œ í†µí•©ë©ë‹ˆë‹¤.

### /alfred:1-plan ë‹¨ê³„

```python
# ì‚¬ìš©ì ìš”ì²­
user: "/alfred:1-plan ì´ë©”ì¼ ëŒ€ëŸ‰ ì•„ì¹´ì´ë¸Œ ê¸°ëŠ¥"

# Alfredì˜ ë‚´ë¶€ í”„ë¡œì„¸ìŠ¤
alfred_process = {
    "step_1": "ìš”êµ¬ì‚¬í•­ ë³µì¡ë„ í‰ê°€",
    "complexity": "HIGH (ëŒ€ëŸ‰ ë°ì´í„° + API ì œì•½)",
    "decision": "Senior Engineer Thinking í™œì„±í™”",

    "step_2": "ì—°êµ¬ ì „ëµ ì„ íƒ",
    "strategies": [1, 2, 3, 5],  # ë³‘ë ¬ ì‹¤í–‰

    "step_3": "Plan Agentì—ê²Œ ìœ„ì„",
    "task_prompt": """
    ë‹¤ìŒ ì—°êµ¬ ê²°ê³¼ë¥¼ ê¸°ë°˜ìœ¼ë¡œ SPEC ì‘ì„±:

    Research Findings:
    - Gmail API ë°°ì¹˜ ì œí•œ: 100ê°œ
    - Rate limit: 250 req/s
    - í”„ë¡œì íŠ¸ì— Celery ì¸í”„ë¼ ì¡´ì¬
    - ê³¼ê±° ìˆœì°¨ ì²˜ë¦¬ ì‹¤íŒ¨ ì´ë ¥

    Requirements:
    1. 53,000ê°œ ì´ë©”ì¼ ì²˜ë¦¬
    2. ì‹¤íŒ¨ ì‹œ ë³µêµ¬ ê°€ëŠ¥
    3. ì§„í–‰ ìƒí™© ëª¨ë‹ˆí„°ë§
    """,

    "step_4": "SPEC ë¬¸ì„œ ìƒì„±",
    "output": ".moai/specs/SPEC-EMAIL-ARCHIVE-001.md"
}
```

**ìƒì„±ëœ SPEC**:

```markdown
# SPEC-EMAIL-ARCHIVE-001: ëŒ€ëŸ‰ ì´ë©”ì¼ ì•„ì¹´ì´ë¸Œ

## @OVERVIEW
Gmail APIë¥¼ ì‚¬ìš©í•˜ì—¬ 53,000ê°œ ì´ë©”ì¼ì„ ì•ˆì „í•˜ê²Œ ì•„ì¹´ì´ë¸Œí•˜ëŠ” ì‹œìŠ¤í…œ

## @REQUIREMENTS
- REQ-001: ë°°ì¹˜ ì²˜ë¦¬ë¡œ API ì œì•½ ì¤€ìˆ˜
- REQ-002: Celery ê¸°ë°˜ ë¹„ë™ê¸° ì²˜ë¦¬
- REQ-003: ì²´í¬í¬ì¸íŠ¸ ì‹œìŠ¤í…œìœ¼ë¡œ ë³µêµ¬ ê°€ëŠ¥
- REQ-004: ì§„í–‰ ìƒí™© ì‹¤ì‹œê°„ ì¶”ì 

## @RESEARCH-EVIDENCE
- Gmail API ë¬¸ì„œ ë¶„ì„ (Strategy 1)
- Celery Best Practices ì ìš© (Strategy 2)
- ê¸°ì¡´ ë°°ì¹˜ ì²˜ë¦¬ íŒ¨í„´ ì¬ì‚¬ìš© (Strategy 3)
- 2023-08 ìˆœì°¨ ì²˜ë¦¬ ì‹¤íŒ¨ í•™ìŠµ (Strategy 5)

## @ARCHITECTURE
[Mermaid ë‹¤ì´ì–´ê·¸ë¨...]

## @IMPLEMENTATION-PLAN
[ìƒì„¸ êµ¬í˜„ ê³„íš...]
```

### /alfred:2-run ë‹¨ê³„

```python
# TDD êµ¬í˜„ ë‹¨ê³„ì—ì„œë„ ì—°êµ¬ í™œìš©
alfred_tdd_process = {
    "red_phase": {
        "action": "Test Engineer Agentê°€ í…ŒìŠ¤íŠ¸ ì‘ì„±",
        "research_used": "Strategy 3 (ê¸°ì¡´ í…ŒìŠ¤íŠ¸ íŒ¨í„´)"
    },
    "green_phase": {
        "action": "TDD Implementer Agentê°€ êµ¬í˜„",
        "research_used": "Strategy 1 + 2 (API ë¬¸ì„œ + Best Practices)"
    },
    "refactor_phase": {
        "action": "Code Quality Agentê°€ ë¦¬íŒ©í† ë§",
        "research_used": "Strategy 8 (Style Agents ë¦¬ë·°)"
    }
}

# ê° ë‹¨ê³„ë§ˆë‹¤ ì—°êµ¬ ê²°ê³¼ ì¬ì‚¬ìš©
test_code = '''
# test_email_archive.py
# Strategy 3ì—ì„œ ë°œê²¬í•œ ê¸°ì¡´ íŒ¨í„´ ì ìš©
def test_batch_archive(mock_gmail_api, email_repository):
    """ë°°ì¹˜ ì•„ì¹´ì´ë¸Œ í…ŒìŠ¤íŠ¸ (ê¸°ì¡´ íŒ¨í„´ ì¤€ìˆ˜)"""
    email_ids = [f"msg_{i}" for i in range(250)]

    result = email_repository.batch_archive(email_ids)

    assert result.success_count == 250
    assert mock_gmail_api.call_count == 3  # 100ê°œì”© 3ë²ˆ
'''

implementation = '''
# email_archive.py
# Strategy 1 (API ë¬¸ì„œ) + Strategy 2 (Best Practices)
from tenacity import retry, stop_after_attempt

class EmailArchiveService:
    @retry(stop=stop_after_attempt(3))
    def batch_archive(self, email_ids: List[str]):
        """Gmail APIë¡œ ë°°ì¹˜ ì•„ì¹´ì´ë¸Œ"""
        batch_size = 100  # Strategy 1: API ì œí•œ

        for i in range(0, len(email_ids), batch_size):
            batch = email_ids[i:i+batch_size]
            self._archive_chunk(batch)
            self._save_checkpoint(i + len(batch))  # Strategy 2: ë³µêµ¬
'''
```

### /alfred:3-sync ë‹¨ê³„

```python
# ë¬¸ì„œí™” ë‹¨ê³„ì—ì„œ ì—°êµ¬ ê²°ê³¼ í¬í•¨
alfred_doc_sync = {
    "action": "Doc Syncer Agentê°€ ë¬¸ì„œ ìƒì„±",
    "research_integration": {
        "architecture_docs": "ì—°êµ¬í•œ ì•„í‚¤í…ì²˜ ë‹¤ì´ì–´ê·¸ë¨ í¬í•¨",
        "api_docs": "Strategy 1ì˜ Gmail API ë¶„ì„ ê²°ê³¼ ì°¸ì¡°",
        "best_practices": "Strategy 2ì˜ Best Practices ë¬¸ì„œí™”",
        "lessons_learned": "Strategy 5ì˜ Git íˆìŠ¤í† ë¦¬ ì¸ì‚¬ì´íŠ¸"
    }
}

# ìƒì„±ëœ ë¬¸ì„œ
generated_doc = '''
# Email Archive ì‹œìŠ¤í…œ

## ì•„í‚¤í…ì²˜ ê²°ì • ë°°ê²½

### ì™œ Celeryë¥¼ ì„ íƒí–ˆë‚˜?
**Research Evidence (Strategy 2 + 7)**:
- 3ê°€ì§€ ì˜µì…˜ ë¹„êµ (Sync, Celery, Serverless)
- Celeryê°€ ë³µì¡ë„/ì„±ëŠ¥/í™•ì¥ì„± ê· í˜• ìµœì 
- í”„ë¡œì íŠ¸ì— ì´ë¯¸ Celery ì¸í”„ë¼ ì¡´ì¬ (Strategy 3)

### API ì œì•½ì‚¬í•­
**Research Evidence (Strategy 1)**:
- Gmail API ë°°ì¹˜ ì œí•œ: 100ê°œ
- Rate limit: 250 requests/second
- ì¬í˜„ ì½”ë“œë¡œ ê²€ì¦ ì™„ë£Œ

### ê³¼ê±° ì‹¤íŒ¨ ì‚¬ë¡€
**Research Evidence (Strategy 5)**:
- 2023-08: ìˆœì°¨ ì²˜ë¦¬ë¡œ rate limit ì´ˆê³¼
- êµí›ˆ: ë°˜ë“œì‹œ ë°°ì¹˜ ì²˜ë¦¬ ì‚¬ìš©
'''
```

## Performance Metrics

### ì—°êµ¬ ì‹œê°„ vs ê°œë°œ í’ˆì§ˆ

| ì ‘ê·¼ë²• | ì´ˆê¸° ì—°êµ¬ | êµ¬í˜„ ì‹œê°„ | ë²„ê·¸ ë°œìƒ | ë¦¬íŒ©í† ë§ | ì´ ì‹œê°„ |
|--------|----------|----------|----------|----------|--------|
| **ì¦‰ì‹œ ì‹¤í–‰** | 0ë¶„ | 30ë¶„ | 5ê°œ | 120ë¶„ | 150ë¶„ |
| **Senior Engineer** | 20ë¶„ | 40ë¶„ | 0ê°œ | 10ë¶„ | 70ë¶„ |

**ì ˆê° íš¨ê³¼**: 53% ì‹œê°„ ë‹¨ì¶• + ë²„ê·¸ ì œë¡œ

### ì „ëµë³„ íš¨ê³¼ì„±

```python
strategy_effectiveness = {
    "Strategy 1 (Reproduce)": {
        "time_cost": "15-30ë¶„",
        "value": "API ì˜¤ì‘ë™ ë°©ì§€ 100%",
        "roi": "ë§¤ìš° ë†’ìŒ"
    },
    "Strategy 2 (Best Practices)": {
        "time_cost": "10-20ë¶„",
        "value": "ì•„í‚¤í…ì²˜ ê²°ì • ì‹ ë¢°ë„ +85%",
        "roi": "ë†’ìŒ"
    },
    "Strategy 3 (Codebase)": {
        "time_cost": "5-15ë¶„",
        "value": "ì½”ë“œ ì¼ê´€ì„± +90%",
        "roi": "ë§¤ìš° ë†’ìŒ"
    },
    "Strategy 5 (Git History)": {
        "time_cost": "10-20ë¶„",
        "value": "ë™ì¼ ì‹¤ìˆ˜ ì¬ë°œ ë°©ì§€ 100%",
        "roi": "ë†’ìŒ"
    },
    "Strategy 7 (Options)": {
        "time_cost": "20-40ë¶„",
        "value": "ìµœì  ì†”ë£¨ì…˜ ì„ íƒ í™•ë¥  +70%",
        "roi": "ì¤‘ê°„ (ì¤‘ìš” ê²°ì • ì‹œ í•„ìˆ˜)"
    }
}
```

### ë³µë¦¬ íš¨ê³¼ ì¸¡ì •

```python
# í”„ë¡œì íŠ¸ ì§„í–‰ì— ë”°ë¥¸ ì—°êµ¬ ì‹œê°„ ê°ì†Œ
project_timeline = {
    "week_1": {
        "tasks": 5,
        "avg_research_time": "25ë¶„/ì‘ì—…",
        "total_research": "125ë¶„"
    },
    "week_4": {
        "tasks": 5,
        "avg_research_time": "10ë¶„/ì‘ì—…",  # 60% ê°ì†Œ!
        "total_research": "50ë¶„",
        "reason": "ì§€ì‹ ëˆ„ì  íš¨ê³¼"
    },
    "week_12": {
        "tasks": 5,
        "avg_research_time": "3ë¶„/ì‘ì—…",  # 88% ê°ì†Œ!
        "total_research": "15ë¶„",
        "reason": "ëŒ€ë¶€ë¶„ ì¬ì‚¬ìš© ê°€ëŠ¥"
    }
}
```

## Best Practices

### 1. ì—°êµ¬ ì‹œê¸° ê²°ì •

```python
def should_research(task: Dict) -> bool:
    """ì—°êµ¬ê°€ í•„ìš”í•œì§€ íŒë‹¨"""
    triggers = [
        task.get("complexity") == "high",
        task.get("risk") in ["medium", "high"],
        task.get("novelty") == True,  # ìƒˆë¡œìš´ ë„ë©”ì¸
        task.get("scale") == "large",  # ëŒ€ìš©ëŸ‰ ë°ì´í„°
        task.get("security_sensitive") == True
    ]

    return any(triggers)

# ì˜ˆì‹œ
task_examples = {
    "simple_crud": {
        "complexity": "low",
        "risk": "low",
        "research_needed": False  # ì¦‰ì‹œ êµ¬í˜„
    },
    "payment_integration": {
        "complexity": "high",
        "security_sensitive": True,
        "research_needed": True  # ë°˜ë“œì‹œ ì—°êµ¬!
    }
}
```

### 2. ì „ëµ ì¡°í•© ê°€ì´ë“œ

```python
# ìƒí™©ë³„ ì¶”ì²œ ì „ëµ ì¡°í•©
strategy_combinations = {
    "new_library_integration": [1, 2, 4],  # ë¬¸ì„œ + Best Practices + ê¸°ì¡´ ë¼ì´ë¸ŒëŸ¬ë¦¬
    "legacy_refactoring": [3, 5, 8],  # ì½”ë“œë² ì´ìŠ¤ + Git íˆìŠ¤í† ë¦¬ + ë¦¬ë·°
    "architecture_decision": [2, 7, 8],  # Best Practices + ì˜µì…˜ ë¹„êµ + ë¦¬ë·°
    "performance_optimization": [3, 5, 6],  # ì½”ë“œë² ì´ìŠ¤ + íˆìŠ¤í† ë¦¬ + í”„ë¡œí† íƒ€ì…
    "security_feature": [1, 2, 8],  # ë¬¸ì„œ + Best Practices + ë¦¬ë·° (í•„ìˆ˜!)
}
```

### 3. ì—°êµ¬ ê¹Šì´ ì¡°ì ˆ

```python
research_depth_levels = {
    "shallow": {
        "duration": "5-10ë¶„",
        "strategies": [3],  # ì½”ë“œë² ì´ìŠ¤ë§Œ ì²´í¬
        "when": "ë‹¨ìˆœ ê¸°ëŠ¥ ì¶”ê°€"
    },
    "medium": {
        "duration": "15-30ë¶„",
        "strategies": [1, 2, 3],
        "when": "ì¼ë°˜ì ì¸ ìƒˆ ê¸°ëŠ¥"
    },
    "deep": {
        "duration": "30-60ë¶„",
        "strategies": [1, 2, 3, 5, 7, 8],
        "when": "ì¤‘ìš” ì•„í‚¤í…ì²˜ ê²°ì •"
    }
}
```

### 4. ì—°êµ¬ ê²°ê³¼ ë¬¸ì„œí™”

```python
# ì—°êµ¬ ê²°ê³¼ë¥¼ SPECì— í¬í•¨
spec_template = '''
## @RESEARCH-EVIDENCE

### Strategy 1: API Documentation Analysis
- [API ë¶„ì„ ê²°ê³¼]
- [ì¬í˜„ ì½”ë“œ ë§í¬]

### Strategy 2: Best Practices
- [ì°¸ê³  ë¬¸ì„œ/ì•„í‹°í´]
- [ì ìš©í•  íŒ¨í„´]

### Strategy 5: Git History Insights
- [ê´€ë ¨ ì»¤ë°‹]
- [ê³¼ê±° ì‹¤íŒ¨ ì‚¬ë¡€]
- [í•™ìŠµ í¬ì¸íŠ¸]

### Final Decision
- [ì„ íƒí•œ ì ‘ê·¼ë²•]
- [ê·¼ê±°]
- [íŠ¸ë ˆì´ë“œì˜¤í”„]
'''
```

## ë‹¤ìŒ ë‹¨ê³„

### 1. Senior Engineer Thinking í™œì„±í™”

```bash
# .moai/config/config.jsonì—ì„œ ì„¤ì •
{
  "senior_engineer_thinking": {
    "enabled": true,
    "auto_activate_threshold": "medium_complexity",
    "default_strategies": [1, 2, 3],
    "max_research_time": "30m"
  }
}
```

### 2. ì‹¤ì „ ì—°ìŠµ

```bash
# ê°„ë‹¨í•œ ì‘ì—…ë¶€í„° ì‹œì‘
/alfred:1-plan "ìƒˆ API ì—”ë“œí¬ì¸íŠ¸ ì¶”ê°€"

# Alfredê°€ ìë™ìœ¼ë¡œ ì—°êµ¬ ìˆ˜í–‰
# â†’ Strategy 3 (ê¸°ì¡´ íŒ¨í„´ ë¶„ì„)
# â†’ ì¼ê´€ëœ êµ¬í˜„ ì œì•ˆ
```

### 3. ê³ ê¸‰ ê¸°ëŠ¥ íƒìƒ‰

- **Knowledge Graph ì‹œê°í™”**: `.moai/knowledge/graph.html`
- **ì—°êµ¬ ë¦¬í¬íŠ¸ ìƒì„±**: `.moai/research/reports/`
- **ì „ëµ íš¨ê³¼ì„± ë¶„ì„**: `.moai/metrics/strategy_effectiveness.json`

### 4. íŒ€ ê³µìœ 

```bash
# ì—°êµ¬ ê²°ê³¼ë¥¼ íŒ€ê³¼ ê³µìœ 
git add .moai/research/
git commit -m "docs: Add research findings for email archive system"
git push origin feature/email-archive
```

---

**Senior Engineer Thinkingê³¼ í•¨ê»˜ë¼ë©´, AlfredëŠ” ë‹¨ìˆœí•œ ì½”ë“œ ìƒì„±ì„ ë„˜ì–´ ì§„ì§œ ì‹œë‹ˆì–´ ì—”ì§€ë‹ˆì–´ì²˜ëŸ¼ ìƒê°í•˜ê³  í–‰ë™í•©ë‹ˆë‹¤.**

**ë¬¸ì„œ ì‘ì„±**: 2024-01
**ë²„ì „**: v0.22.0
**ìœ ì§€ë³´ìˆ˜**: MoAI-ADK Team
