# ì—°êµ¬ ì „ëµ ì‹¤ì „ í™œìš© ê°€ì´ë“œ

## ê°œìš”

ì´ ê°€ì´ë“œëŠ” MoAI-ADKì˜ **8ê°€ì§€ ì—°êµ¬ ì „ëµ**ì„ ì‹¤ì „ í”„ë¡œì íŠ¸ì—ì„œ íš¨ê³¼ì ìœ¼ë¡œ í™œìš©í•˜ëŠ” ë°©ë²•ì„ ë‹¤ë£¹ë‹ˆë‹¤. ê° ì „ëµì˜ ì‹¤í–‰ ì ˆì°¨, ë„êµ¬, í•¨ì •, ê·¸ë¦¬ê³  ì‹¤ì œ ì½”ë“œ ì˜ˆì œë¥¼ í†µí•´ Senior Engineerì²˜ëŸ¼ ë¬¸ì œë¥¼ í•´ê²°í•˜ëŠ” ë°©ë²•ì„ í•™ìŠµí•©ë‹ˆë‹¤.

### ì´ ê°€ì´ë“œì˜ ëª©í‘œ

- âœ… ê° ì „ëµì„ **ì–¸ì œ, ì–´ë–»ê²Œ** ì‚¬ìš©í•˜ëŠ”ì§€ ëª…í™•íˆ ì´í•´
- âœ… ë‹¨ê³„ë³„ ì‹¤í–‰ í”„ë¡œì„¸ìŠ¤ ìŠµë“
- âœ… ì‹¤ì „ ì˜ˆì œë¡œ ì¦‰ì‹œ ì ìš© ê°€ëŠ¥í•œ íŒ¨í„´ í•™ìŠµ
- âœ… í”í•œ ì‹¤ìˆ˜ ë°©ì§€ ë° ë¬¸ì œ í•´ê²° ëŠ¥ë ¥ í–¥ìƒ

```mermaid
graph TB
    A[ë¬¸ì œ ë°œìƒ] --> B{ë³µì¡ë„ í‰ê°€}
    B -->|Low| C[ì§ì ‘ í•´ê²°]
    B -->|Medium| D[ì „ëµ 1-3ê°œ ì„ íƒ]
    B -->|High| E[ì „ëµ 4-6ê°œ ë³‘ë ¬ ì‹¤í–‰]

    D --> F[ë‹¨ì¼ ì „ëµ ì‹¤í–‰]
    E --> G[Research Orchestrator]

    F --> H[í•´ê²°ì±… ì ìš©]
    G --> I[Knowledge Synthesis]
    I --> H

    H --> J{ì„±ê³µ?}
    J -->|Yes| K[í•™ìŠµ íš¨ê³¼ ì €ì¥]
    J -->|No| L[ì¶”ê°€ ì „ëµ ì‹œë„]
    L --> D

    K --> M[ë‹¤ìŒ ì‘ì—…ì— ì¬ì‚¬ìš©]
```

## Strategy 1: Reproduce & Document

### ì–¸ì œ ì‚¬ìš©í•˜ëŠ”ê°€?

**ì‚¬ìš© ì‹œì **:
- âœ… ìƒˆë¡œìš´ ë¼ì´ë¸ŒëŸ¬ë¦¬/APIë¥¼ ì²˜ìŒ ì‚¬ìš©í•  ë•Œ
- âœ… ê³µì‹ ë¬¸ì„œê°€ ì˜¤ë˜ë˜ì—ˆê±°ë‚˜ ë¶ˆì™„ì „í•  ë•Œ
- âœ… ì˜ˆì œ ì½”ë“œê°€ ì‘ë™í•˜ì§€ ì•Šì„ ë•Œ
- âœ… ë²„ì „ ì°¨ì´ë¡œ ì¸í•œ ë³€ê²½ì‚¬í•­ í™•ì¸ í•„ìš” ì‹œ

**ì‚¬ìš©í•˜ì§€ ì•Šì„ ë•Œ**:
- âŒ ì´ë¯¸ ê²€ì¦ëœ íŒ¨í„´ì´ í”„ë¡œì íŠ¸ì— ì¡´ì¬
- âŒ ì‹œê°„ì´ ì´‰ë°•í•œ ë‹¨ìˆœ ì‘ì—…
- âŒ ë‚´ë¶€ ë¼ì´ë¸ŒëŸ¬ë¦¬ (ë¬¸ì„œ ì¬í˜„ ë¶ˆí•„ìš”)

### ë‹¨ê³„ë³„ í”„ë¡œì„¸ìŠ¤

#### Step 1: ê³µì‹ ë¬¸ì„œ ìˆ˜ì§‘

```python
# research_strategy_1.py
from typing import Dict, List
import requests
from bs4 import BeautifulSoup

class DocumentReproducer:
    def __init__(self, library_name: str):
        self.library_name = library_name
        self.docs_urls = self.find_official_docs()

    def find_official_docs(self) -> List[str]:
        """ê³µì‹ ë¬¸ì„œ URL ì°¾ê¸°"""
        search_queries = [
            f"{self.library_name} official documentation",
            f"{self.library_name} API reference",
            f"{self.library_name} quickstart guide"
        ]

        # Context7 MCP ì‚¬ìš© (ì¶”ì²œ)
        docs = context7.search_library_docs(self.library_name)

        return docs

    def extract_code_examples(self, doc_url: str) -> List[str]:
        """ë¬¸ì„œì—ì„œ ì½”ë“œ ì˜ˆì œ ì¶”ì¶œ"""
        response = requests.get(doc_url)
        soup = BeautifulSoup(response.content, 'html.parser')

        # ì½”ë“œ ë¸”ë¡ ì°¾ê¸°
        code_blocks = soup.find_all('code')

        examples = []
        for block in code_blocks:
            if self.is_runnable(block.text):
                examples.append(block.text)

        return examples
```

#### Step 2: ìµœì†Œ ì¬í˜„ ì½”ë“œ ì‘ì„±

```python
# ì˜ˆì‹œ: Stripe API ì¬í˜„
import stripe

def reproduce_stripe_payment():
    """
    ê³µì‹ ë¬¸ì„œ ì˜ˆì œ ì¬í˜„
    ì¶œì²˜: https://stripe.com/docs/payments/quickstart
    """
    stripe.api_key = 'sk_test_...'

    # ë¬¸ì„œ ì˜ˆì œ ê·¸ëŒ€ë¡œ ì‹¤í–‰
    try:
        payment_intent = stripe.PaymentIntent.create(
            amount=1000,
            currency='usd',
            payment_method_types=['card']
        )

        print(f"âœ… ì¬í˜„ ì„±ê³µ: {payment_intent.id}")
        return {
            "success": True,
            "findings": [
                "amountëŠ” ì„¼íŠ¸ ë‹¨ìœ„ (1000 = $10.00)",
                "payment_method_typesëŠ” ë°°ì—´ í˜•íƒœ",
                "ì¦‰ì‹œ client_secret ë°˜í™˜"
            ]
        }

    except stripe.error.StripeError as e:
        print(f"âŒ ì¬í˜„ ì‹¤íŒ¨: {e}")
        return {
            "success": False,
            "error": str(e),
            "lesson": "API í‚¤ ê¶Œí•œ í™•ì¸ í•„ìš”"
        }
```

#### Step 3: ë¬¸ì„œ vs ì‹¤ì œ ë™ì‘ ë¹„êµ

```python
def compare_doc_vs_reality():
    """ë¬¸ì„œì™€ ì‹¤ì œ ë™ì‘ ì°¨ì´ ë¶„ì„"""

    comparison = {
        "documented_behavior": {
            "response_time": "100-200ms",
            "idempotency": "ìë™ ì²˜ë¦¬",
            "error_codes": ["card_declined", "insufficient_funds"]
        },
        "actual_behavior": {
            "response_time": "300-500ms (ì‹¤ì œ ë” ëŠë¦¼)",
            "idempotency": "idempotency_key ëª…ì‹œ í•„ìš”",
            "error_codes": [
                "card_declined",
                "insufficient_funds",
                "rate_limit_error"  # ë¬¸ì„œì— ëˆ„ë½!
            ]
        },
        "critical_differences": [
            "Rate limit ë¬¸ì„œì— ëª…ì‹œ ì•ˆ ë¨ â†’ ì¶”ê°€ ì²˜ë¦¬ í•„ìš”",
            "Idempotency key ìë™ ìƒì„± ì•ˆ ë¨ â†’ ìˆ˜ë™ êµ¬í˜„"
        ]
    }

    return comparison
```

#### Step 4: ê²€ì¦ëœ íŒ¨í„´ ë¬¸ì„œí™”

```python
# ì¬í˜„ ê²°ê³¼ë¥¼ í”„ë¡œì íŠ¸ì— ë¬¸ì„œí™”
reproduction_report = """
# Stripe Payment Intent API ì¬í˜„ ë¦¬í¬íŠ¸

## ì¬í˜„ ë‚ ì§œ
2024-01-15

## ë¬¸ì„œ ë²„ì „
Stripe API v2023-10-16

## ì¬í˜„ ê²°ê³¼

### âœ… ì‘ë™ í™•ì¸ëœ ê¸°ëŠ¥
- PaymentIntent ìƒì„±
- ì¹´ë“œ ê²°ì œ ì²˜ë¦¬
- ì›¹í›… ìˆ˜ì‹ 

### âš ï¸ ë¬¸ì„œì™€ ë‹¤ë¥¸ ì 
1. **Response Time**: ë¬¸ì„œëŠ” 100-200msë¼ê³  í–ˆì§€ë§Œ ì‹¤ì œëŠ” 300-500ms
2. **Idempotency**: ìë™ ì²˜ë¦¬ ì•ˆ ë¨ â†’ `idempotency_key` ì§ì ‘ ìƒì„± í•„ìš”
3. **Rate Limit**: ë¬¸ì„œì— ëˆ„ë½ â†’ 100 req/s ì œí•œ ì¡´ì¬

### ğŸ“ ê¶Œì¥ êµ¬í˜„ íŒ¨í„´
```python
import uuid
import stripe

def create_payment_with_idempotency(amount: int):
    '''ì¶”ì²œ íŒ¨í„´: idempotency key ì‚¬ìš©'''
    return stripe.PaymentIntent.create(
        amount=amount,
        currency='usd',
        payment_method_types=['card'],
        idempotency_key=str(uuid.uuid4())  # ì¤‘ë³µ ë°©ì§€!
    )
```

### ğŸš¨ ì£¼ì˜ì‚¬í•­
- Rate limit ëŒ€ë¹„ ì¬ì‹œë„ ë¡œì§ í•„ìˆ˜
- í…ŒìŠ¤íŠ¸ í™˜ê²½ì—ì„œë„ ì‹¤ì œ API í‚¤ í•„ìš” (mock ë¶ˆì™„ì „)
"""
```

### ì‹¤ì „ ì˜ˆì œ: GitHub API ì¬í˜„

```python
# ì‹¤ì „ ì˜ˆì œ: GitHub GraphQL API
import requests

class GitHubAPIReproducer:
    def __init__(self, token: str):
        self.token = token
        self.endpoint = "https://api.github.com/graphql"

    def reproduce_pr_query(self):
        """ë¬¸ì„œ ì˜ˆì œ ì¬í˜„: PR ëª©ë¡ ì¡°íšŒ"""

        # ê³µì‹ ë¬¸ì„œ ì˜ˆì œ
        query = """
        query {
          repository(owner: "facebook", name: "react") {
            pullRequests(first: 10, states: OPEN) {
              nodes {
                number
                title
                author {
                  login
                }
              }
            }
          }
        }
        """

        response = requests.post(
            self.endpoint,
            json={'query': query},
            headers={'Authorization': f'Bearer {self.token}'}
        )

        result = response.json()

        # ê²€ì¦
        findings = {
            "success": "errors" not in result,
            "observations": []
        }

        if findings["success"]:
            findings["observations"].extend([
                "âœ… GraphQL ì¿¼ë¦¬ ì •ìƒ ì‘ë™",
                "âœ… ì¤‘ì²© í•„ë“œ (author.login) ë¬¸ì œì—†ìŒ",
                f"âœ… ë°˜í™˜ëœ PR ê°œìˆ˜: {len(result['data']['repository']['pullRequests']['nodes'])}"
            ])
        else:
            findings["observations"].append(
                f"âŒ ì—ëŸ¬ ë°œìƒ: {result['errors']}"
            )

        # ì¶”ê°€ ë°œê²¬ì‚¬í•­
        findings["undocumented"] = [
            "Rate limit header ì¡´ì¬: X-RateLimit-Remaining",
            "Responseì— complexity ì •ë³´ í¬í•¨ (ë¬¸ì„œ ëˆ„ë½)"
        ]

        return findings

# ì‚¬ìš©
reproducer = GitHubAPIReproducer(token="ghp_...")
report = reproducer.reproduce_pr_query()
print(report)

# ì¶œë ¥:
# {
#   "success": True,
#   "observations": [
#     "âœ… GraphQL ì¿¼ë¦¬ ì •ìƒ ì‘ë™",
#     "âœ… ì¤‘ì²© í•„ë“œ (author.login) ë¬¸ì œì—†ìŒ",
#     "âœ… ë°˜í™˜ëœ PR ê°œìˆ˜: 10"
#   ],
#   "undocumented": [
#     "Rate limit header ì¡´ì¬: X-RateLimit-Remaining",
#     "Responseì— complexity ì •ë³´ í¬í•¨ (ë¬¸ì„œ ëˆ„ë½)"
#   ]
# }
```

### ë„êµ¬ ë° ê¸°ë²•

**ì¶”ì²œ ë„êµ¬**:
- `requests` + `httpx`: API í˜¸ì¶œ í…ŒìŠ¤íŠ¸
- `pytest`: ì¬í˜„ ì½”ë“œë¥¼ í…ŒìŠ¤íŠ¸ë¡œ ë³€í™˜
- Context7 MCP: ìµœì‹  ë¬¸ì„œ ìë™ ê²€ìƒ‰
- `postman` / `insomnia`: API ìˆ˜ë™ í…ŒìŠ¤íŠ¸

**ë””ë²„ê¹… ê¸°ë²•**:
```python
# ìƒì„¸ ë¡œê¹…ìœ¼ë¡œ ë””ë²„ê¹…
import logging
import http.client

# HTTP ìš”ì²­/ì‘ë‹µ ì „ì²´ ë¡œê¹…
http.client.HTTPConnection.debuglevel = 1
logging.basicConfig(level=logging.DEBUG)

# API í˜¸ì¶œ ì‹œ ì „ì²´ ê³¼ì • í™•ì¸ ê°€ëŠ¥
response = requests.post(api_url, json=payload)
```

### Common Pitfalls

**í•¨ì • 1: ë¬¸ì„œ ë²„ì „ ë¶ˆì¼ì¹˜**
```python
# âŒ ì˜ëª»ëœ ì ‘ê·¼
# ìµœì‹  ë¬¸ì„œë¥¼ ë³´ì§€ë§Œ ë¼ì´ë¸ŒëŸ¬ë¦¬ëŠ” êµ¬ë²„ì „ ì‚¬ìš©

# âœ… ì˜¬ë°”ë¥¸ ì ‘ê·¼
import stripe
print(f"Stripe version: {stripe.VERSION}")
# â†’ í•´ë‹¹ ë²„ì „ì˜ ë¬¸ì„œ í™•ì¸
```

**í•¨ì • 2: í™˜ê²½ ì°¨ì´ ë¬´ì‹œ**
```python
# âŒ ì˜ëª»ëœ ì ‘ê·¼
# ë¡œì»¬ì—ì„œëŠ” ì‘ë™í•˜ì§€ë§Œ í”„ë¡œë•ì…˜ì—ì„œ ì‹¤íŒ¨

# âœ… ì˜¬ë°”ë¥¸ ì ‘ê·¼
def test_api_in_all_environments():
    environments = ['local', 'staging', 'production']
    for env in environments:
        config = load_config(env)
        result = test_api_call(config)
        assert result.success, f"{env} í™˜ê²½ ì‹¤íŒ¨"
```

**í•¨ì • 3: ì˜ˆì œ ì½”ë“œì˜ ìˆ¨ê²¨ì§„ ì „ì œ ì¡°ê±´**
```python
# ë¬¸ì„œ ì˜ˆì œ
payment = stripe.PaymentIntent.create(amount=1000, ...)

# âŒ í•¨ì •: stripe.api_key ì„¤ì • í•„ìš” (ì˜ˆì œì— ì—†ìŒ)
# âœ… ì™„ì „í•œ ì½”ë“œ
stripe.api_key = os.getenv('STRIPE_SECRET_KEY')
payment = stripe.PaymentIntent.create(amount=1000, ...)
```

## Strategy 2: Ground in Best Practices

### ì–¸ì œ ì‚¬ìš©í•˜ëŠ”ê°€?

**ì‚¬ìš© ì‹œì **:
- âœ… ì•„í‚¤í…ì²˜ ê²°ì •ì´ í•„ìš”í•  ë•Œ
- âœ… ì—¬ëŸ¬ êµ¬í˜„ ë°©ë²• ì¤‘ ì„ íƒí•´ì•¼ í•  ë•Œ
- âœ… ë³´ì•ˆ/ì„±ëŠ¥ì´ ì¤‘ìš”í•œ ê²½ìš°
- âœ… íŒ€ ì»¨ë²¤ì…˜ ì •ë¦½ ì‹œ

### ë‹¨ê³„ë³„ í”„ë¡œì„¸ìŠ¤

#### Step 1: Best Practices ì†ŒìŠ¤ ì°¾ê¸°

```python
# ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” Best Practices ì¶œì²˜
best_practice_sources = {
    "official_standards": [
        "RFC documents",
        "W3C specifications",
        "OWASP guidelines",
        "ISO standards"
    ],
    "cloud_providers": [
        "AWS Well-Architected Framework",
        "Google Cloud Architecture Framework",
        "Azure Architecture Center"
    ],
    "industry_leaders": [
        "Google SRE Book",
        "Martin Fowler's blog",
        "12-Factor App",
        "Microsoft REST API Guidelines"
    ],
    "large_projects": [
        "Django (Python web)",
        "React (Frontend)",
        "Kubernetes (Orchestration)",
        "PostgreSQL (Database)"
    ]
}

def search_best_practices(domain: str) -> List[Dict]:
    """Context7ë¡œ Best Practices ê²€ìƒ‰"""
    queries = [
        f"{domain} best practices",
        f"{domain} design patterns",
        f"{domain} architecture guidelines"
    ]

    results = []
    for query in queries:
        # Context7 MCP í™œìš©
        docs = context7.search(query, sources=best_practice_sources)
        results.extend(docs)

    return results
```

#### Step 2: íŒ¨í„´ ë¶„ì„ ë° í‰ê°€

```python
# ì˜ˆì‹œ: API Rate Limiting Best Practices
class RateLimitingAnalyzer:
    def analyze_patterns(self):
        """ì—¬ëŸ¬ ì†ŒìŠ¤ì˜ Rate Limiting íŒ¨í„´ ë¹„êµ"""

        patterns = {
            "token_bucket": {
                "source": "Google Cloud API Design Guide",
                "description": "í† í°ì„ ì¼ì • ì†ë„ë¡œ ì¶©ì „, ìš”ì²­ ì‹œ ì†Œë¹„",
                "pros": [
                    "ë²„ìŠ¤íŠ¸ íŠ¸ë˜í”½ í—ˆìš©",
                    "êµ¬í˜„ ë‹¨ìˆœ",
                    "ë©”ëª¨ë¦¬ íš¨ìœ¨ì "
                ],
                "cons": [
                    "ë¶„ì‚° í™˜ê²½ì—ì„œ ë™ê¸°í™” í•„ìš”"
                ],
                "use_case": "ì¼ë°˜ì ì¸ API rate limiting",
                "code": """
import time
from threading import Lock

class TokenBucket:
    def __init__(self, capacity: int, refill_rate: float):
        self.capacity = capacity
        self.tokens = capacity
        self.refill_rate = refill_rate
        self.last_refill = time.time()
        self.lock = Lock()

    def consume(self, tokens: int = 1) -> bool:
        with self.lock:
            self._refill()
            if self.tokens >= tokens:
                self.tokens -= tokens
                return True
            return False

    def _refill(self):
        now = time.time()
        elapsed = now - self.last_refill
        self.tokens = min(
            self.capacity,
            self.tokens + elapsed * self.refill_rate
        )
        self.last_refill = now
                """
            },
            "leaky_bucket": {
                "source": "AWS API Gateway",
                "description": "íì— ìš”ì²­ ì €ì¥, ì¼ì • ì†ë„ë¡œ ì²˜ë¦¬",
                "pros": [
                    "íŠ¸ë˜í”½ í‰í™œí™”",
                    "ì˜ˆì¸¡ ê°€ëŠ¥í•œ ë¶€í•˜"
                ],
                "cons": [
                    "ëŒ€ê¸° ì‹œê°„ ì¦ê°€ ê°€ëŠ¥",
                    "ë©”ëª¨ë¦¬ ì‚¬ìš© ë†’ìŒ"
                ],
                "use_case": "ë°±ì—”ë“œ ë³´í˜¸ê°€ ì¤‘ìš”í•œ ê²½ìš°"
            },
            "fixed_window": {
                "source": "Stripe API",
                "description": "ê³ ì • ì‹œê°„ ì°½ ë‚´ ìš”ì²­ ìˆ˜ ì œí•œ",
                "pros": [
                    "êµ¬í˜„ ë§¤ìš° ë‹¨ìˆœ",
                    "Redisë¡œ ì‰½ê²Œ êµ¬í˜„"
                ],
                "cons": [
                    "ì°½ ê²½ê³„ì—ì„œ 2ë°° íŠ¸ë˜í”½ ê°€ëŠ¥"
                ],
                "use_case": "ë‹¨ìˆœ ì œí•œë§Œ í•„ìš”í•œ ê²½ìš°"
            },
            "sliding_window": {
                "source": "GitHub API",
                "description": "ì´ë™ ì‹œê°„ ì°½ìœ¼ë¡œ ì •í™•í•œ ì œí•œ",
                "pros": [
                    "ë²„ìŠ¤íŠ¸ ë°©ì§€",
                    "ê³µì •í•œ ì œí•œ"
                ],
                "cons": [
                    "êµ¬í˜„ ë³µì¡",
                    "ë©”ëª¨ë¦¬ ì‚¬ìš© ë†’ìŒ"
                ],
                "use_case": "ì •ë°€í•œ ì œí•œ í•„ìš” ì‹œ"
            }
        }

        return patterns

    def recommend(self, requirements: Dict) -> str:
        """ìš”êµ¬ì‚¬í•­ì— ë§ëŠ” íŒ¨í„´ ì¶”ì²œ"""
        patterns = self.analyze_patterns()

        if requirements.get("burst_tolerance") == "high":
            return "token_bucket"
        elif requirements.get("backend_protection") == "critical":
            return "leaky_bucket"
        elif requirements.get("simplicity") == "priority":
            return "fixed_window"
        else:
            return "sliding_window"

# ì‚¬ìš©
analyzer = RateLimitingAnalyzer()
recommendation = analyzer.recommend({
    "burst_tolerance": "high",
    "simplicity": "medium"
})

print(f"ì¶”ì²œ íŒ¨í„´: {recommendation}")
# â†’ "token_bucket"
```

#### Step 3: í”„ë¡œì íŠ¸ ì»¨í…ìŠ¤íŠ¸ ì ìš©

```python
def apply_best_practice_to_project(pattern: Dict, project_context: Dict):
    """Best Practiceë¥¼ í”„ë¡œì íŠ¸ì— ë§ê²Œ ì¡°ì •"""

    adaptation = {
        "original_pattern": pattern,
        "project_constraints": project_context,
        "adaptations": []
    }

    # ê¸°ìˆ  ìŠ¤íƒ ê³ ë ¤
    if project_context["cache"] == "redis":
        adaptation["adaptations"].append({
            "change": "Use Redis for distributed rate limiting",
            "code": """
import redis
from datetime import datetime

class RedisRateLimiter:
    def __init__(self, redis_client: redis.Redis):
        self.redis = redis_client

    def is_allowed(self, user_id: str, limit: int, window: int) -> bool:
        '''Sliding window with Redis'''
        now = datetime.now().timestamp()
        key = f'rate_limit:{user_id}'

        # ì˜¤ë˜ëœ ìš”ì²­ ì‚­ì œ
        self.redis.zremrangebyscore(key, 0, now - window)

        # í˜„ì¬ ìš”ì²­ ìˆ˜ í™•ì¸
        request_count = self.redis.zcard(key)

        if request_count < limit:
            # ìš”ì²­ ê¸°ë¡
            self.redis.zadd(key, {str(now): now})
            self.redis.expire(key, window)
            return True

        return False
            """
        })

    # ì„±ëŠ¥ ìš”êµ¬ì‚¬í•­ ê³ ë ¤
    if project_context["latency_requirement"] == "low":
        adaptation["adaptations"].append({
            "change": "Use local cache for hot paths",
            "rationale": "Redis ì™•ë³µ ì‹œê°„ ì ˆê° (2-5ms â†’ 0.1ms)"
        })

    return adaptation
```

### ì‹¤ì „ ì˜ˆì œ: ì¸ì¦ ì‹œìŠ¤í…œ ì„¤ê³„

```python
# Best Practices ê¸°ë°˜ ì¸ì¦ ì‹œìŠ¤í…œ
class AuthenticationSystemDesigner:
    def design_from_best_practices(self):
        """OWASP + OAuth 2.0 Best Practices ì ìš©"""

        design = {
            "authentication": {
                "pattern": "OAuth 2.0 + OpenID Connect",
                "source": "IETF RFC 6749, OpenID Foundation",
                "rationale": "ì‚°ì—… í‘œì¤€, ê²€ì¦ëœ ë³´ì•ˆ",

                "implementation": """
from authlib.integrations.flask_client import OAuth

oauth = OAuth(app)

# Best Practice: Authorization Code Flow (PKCE)
oauth.register(
    'google',
    client_id='...',
    client_secret='...',
    server_metadata_url='https://accounts.google.com/.well-known/openid-configuration',
    client_kwargs={
        'scope': 'openid email profile',
        'code_challenge_method': 'S256'  # PKCE
    }
)

@app.route('/login')
def login():
    redirect_uri = url_for('auth_callback', _external=True)
    return oauth.google.authorize_redirect(redirect_uri)

@app.route('/auth/callback')
def auth_callback():
    token = oauth.google.authorize_access_token()
    user_info = oauth.google.parse_id_token(token)
    # JWTì— user_info ì €ì¥
    return create_session(user_info)
                """
            },

            "session_management": {
                "pattern": "JWT with Refresh Tokens",
                "source": "OWASP Session Management Cheat Sheet",
                "rationale": "Stateless + ë³´ì•ˆ",

                "best_practices": [
                    "Access token: ì§§ì€ ìœ íš¨ê¸°ê°„ (15ë¶„)",
                    "Refresh token: ê¸´ ìœ íš¨ê¸°ê°„ (7ì¼) + DB ì €ì¥",
                    "Refresh token rotation (ì¬ì‚¬ìš© ë°©ì§€)",
                    "Secure + HttpOnly ì¿ í‚¤"
                ],

                "implementation": """
import jwt
from datetime import datetime, timedelta

def create_tokens(user_id: str):
    '''Access + Refresh í† í° ìƒì„±'''

    # Access Token (ì§§ì€ ìœ íš¨ê¸°ê°„)
    access_token = jwt.encode({
        'user_id': user_id,
        'exp': datetime.utcnow() + timedelta(minutes=15),
        'type': 'access'
    }, SECRET_KEY)

    # Refresh Token (ê¸´ ìœ íš¨ê¸°ê°„)
    refresh_token = jwt.encode({
        'user_id': user_id,
        'exp': datetime.utcnow() + timedelta(days=7),
        'type': 'refresh',
        'jti': str(uuid.uuid4())  # Unique ID
    }, SECRET_KEY)

    # Refresh token DBì— ì €ì¥ (revoke ê°€ëŠ¥í•˜ê²Œ)
    db.save_refresh_token(
        user_id=user_id,
        token_id=refresh_token['jti'],
        expires_at=refresh_token['exp']
    )

    return access_token, refresh_token

def refresh_access_token(refresh_token: str):
    '''Refresh tokenìœ¼ë¡œ access token ê°±ì‹ '''

    # Best Practice: Refresh token rotation
    payload = jwt.decode(refresh_token, SECRET_KEY)

    # DBì—ì„œ í† í° ìœ íš¨ì„± í™•ì¸
    if not db.is_valid_refresh_token(payload['jti']):
        raise InvalidTokenError('Refresh token revoked')

    # ê¸°ì¡´ refresh token ë¬´íš¨í™”
    db.revoke_refresh_token(payload['jti'])

    # ìƒˆ í† í° ìŒ ë°œê¸‰
    return create_tokens(payload['user_id'])
                """
            },

            "password_storage": {
                "pattern": "Argon2id",
                "source": "OWASP Password Storage Cheat Sheet",
                "rationale": "í˜„ì¬ ìµœê³ ì˜ í•´ì‹± ì•Œê³ ë¦¬ì¦˜",

                "implementation": """
from argon2 import PasswordHasher

ph = PasswordHasher(
    time_cost=2,        # Iterations
    memory_cost=102400, # 100 MB
    parallelism=8,      # Threads
    hash_len=32,
    salt_len=16
)

# ë¹„ë°€ë²ˆí˜¸ ì €ì¥
hashed = ph.hash(password)

# ë¹„ë°€ë²ˆí˜¸ ê²€ì¦
try:
    ph.verify(hashed, password)
    # Best Practice: Rehash if needed
    if ph.check_needs_rehash(hashed):
        new_hash = ph.hash(password)
        db.update_password_hash(user_id, new_hash)
except argon2.exceptions.VerifyMismatchError:
    raise InvalidPasswordError()
                """
            }
        }

        return design

# ì‚¬ìš©
designer = AuthenticationSystemDesigner()
auth_design = designer.design_from_best_practices()

# SPEC ë¬¸ì„œì— í¬í•¨
spec_content = f"""
## ì¸ì¦ ì‹œìŠ¤í…œ ì„¤ê³„

### Best Practices ê·¼ê±°
- OAuth 2.0: {auth_design['authentication']['source']}
- Session: {auth_design['session_management']['source']}
- Password: {auth_design['password_storage']['source']}

### êµ¬í˜„ íŒ¨í„´
{auth_design['authentication']['implementation']}
"""
```

### ë„êµ¬ ë° ê¸°ë²•

**Best Practices ê²€ìƒ‰ ë„êµ¬**:
- Context7 MCP: ë¼ì´ë¸ŒëŸ¬ë¦¬ ê³µì‹ ë¬¸ì„œ
- Google Scholar: í•™ìˆ  ë…¼ë¬¸
- GitHub Code Search: ì‹¤ì œ êµ¬í˜„ íŒ¨í„´
- Stack Overflow: ì»¤ë®¤ë‹ˆí‹° ì§€í˜œ

**í‰ê°€ ì²´í¬ë¦¬ìŠ¤íŠ¸**:
```python
evaluation_checklist = {
    "security": [
        "OWASP Top 10 ìœ„í˜‘ ëŒ€ì‘",
        "ìµœì‹  CVE í™•ì¸",
        "ì•”í˜¸í™” ì•Œê³ ë¦¬ì¦˜ ê²€ì¦"
    ],
    "performance": [
        "O(n) ë³µì¡ë„ ë¶„ì„",
        "ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¶”ì •",
        "ë³‘ëª© ì§€ì  ì‹ë³„"
    ],
    "scalability": [
        "ìˆ˜í‰ í™•ì¥ ê°€ëŠ¥ì„±",
        "ìƒíƒœ ê´€ë¦¬ ë°©ì‹",
        "ë¶„ì‚° ì‹œìŠ¤í…œ í˜¸í™˜ì„±"
    ],
    "maintainability": [
        "ì½”ë“œ ë³µì¡ë„",
        "í…ŒìŠ¤íŠ¸ ìš©ì´ì„±",
        "ë¬¸ì„œí™” ìˆ˜ì¤€"
    ]
}
```

### Common Pitfalls

**í•¨ì • 1: Cargo Cult Programming**
```python
# âŒ ì˜ëª»ëœ ì ‘ê·¼: ì´ìœ  ëª¨ë¥´ê³  ë³µì‚¬
# "Netflixê°€ ì“°ë‹ˆê¹Œ ìš°ë¦¬ë„ ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤!"

# âœ… ì˜¬ë°”ë¥¸ ì ‘ê·¼: ì»¨í…ìŠ¤íŠ¸ ê³ ë ¤
def should_use_microservices(team_size: int, traffic: int):
    if team_size < 10 and traffic < 1000:
        return False, "ëª¨ë†€ë¦¬ìŠ¤ê°€ ë” ì í•© (íŒ€ ê·œëª¨/íŠ¸ë˜í”½)"
    return True, "ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ ê³ ë ¤ ê°€ëŠ¥"
```

**í•¨ì • 2: ê³¼ë„í•œ ì—”ì§€ë‹ˆì–´ë§**
```python
# âŒ ì˜ëª»ëœ ì ‘ê·¼: ëª¨ë“  Best Practice ì ìš©
# â†’ ë‹¨ìˆœ CRUDì— CQRS + Event Sourcing + DDD

# âœ… ì˜¬ë°”ë¥¸ ì ‘ê·¼: í•„ìš”ì— ë”°ë¼ ì„ íƒ
complexity_levels = {
    "simple_crud": ["REST", "ORM", "basic validation"],
    "moderate": ["REST", "Repository pattern", "DTO"],
    "complex": ["CQRS", "Event Sourcing", "Domain Events"]
}
```

## Strategy 3: Ground in Your Codebase

### ì–¸ì œ ì‚¬ìš©í•˜ëŠ”ê°€?

**ì‚¬ìš© ì‹œì **:
- âœ… ê¸°ì¡´ ì‹œìŠ¤í…œì— ê¸°ëŠ¥ ì¶”ê°€ ì‹œ
- âœ… ì½”ë“œ ì¼ê´€ì„±ì´ ì¤‘ìš”í•  ë•Œ
- âœ… íŒ€ ì»¨ë²¤ì…˜ íŒŒì•… í•„ìš” ì‹œ

### ë‹¨ê³„ë³„ í”„ë¡œì„¸ìŠ¤

#### Step 1: ì½”ë“œë² ì´ìŠ¤ íŒ¨í„´ ë¶„ì„

```python
# codebase_analyzer.py
import ast
from pathlib import Path
from collections import defaultdict

class CodebasePatternAnalyzer:
    def __init__(self, project_root: Path):
        self.root = project_root
        self.patterns = defaultdict(list)

    def analyze_architecture_patterns(self):
        """ì•„í‚¤í…ì²˜ íŒ¨í„´ ì¶”ì¶œ"""

        # ë””ë ‰í† ë¦¬ êµ¬ì¡° ë¶„ì„
        structure = {
            "layers": self.detect_layers(),
            "patterns": self.detect_design_patterns(),
            "conventions": self.detect_naming_conventions()
        }

        return structure

    def detect_layers(self) -> Dict:
        """ë ˆì´ì–´ ì•„í‚¤í…ì²˜ ê°ì§€"""
        common_layers = [
            'controllers', 'services', 'repositories',
            'models', 'dto', 'entities'
        ]

        found_layers = {}
        for layer in common_layers:
            path = self.root / layer
            if path.exists():
                found_layers[layer] = {
                    "path": str(path),
                    "file_count": len(list(path.glob('**/*.py')))
                }

        return found_layers

    def detect_design_patterns(self) -> List[Dict]:
        """ë””ìì¸ íŒ¨í„´ ê°ì§€"""
        patterns_found = []

        # Repository íŒ¨í„´ ê°ì§€
        repo_files = list(self.root.glob('**/repository.py'))
        repo_files.extend(list(self.root.glob('**/*_repository.py')))

        if repo_files:
            example = self.extract_class_example(repo_files[0])
            patterns_found.append({
                "pattern": "Repository Pattern",
                "files": [str(f) for f in repo_files],
                "example": example
            })

        # Factory íŒ¨í„´ ê°ì§€
        factory_files = list(self.root.glob('**/*_factory.py'))
        if factory_files:
            patterns_found.append({
                "pattern": "Factory Pattern",
                "files": [str(f) for f in factory_files]
            })

        return patterns_found

    def extract_class_example(self, file_path: Path) -> str:
        """í´ë˜ìŠ¤ ì˜ˆì œ ì¶”ì¶œ"""
        with open(file_path) as f:
            tree = ast.parse(f.read())

        for node in ast.walk(tree):
            if isinstance(node, ast.ClassDef):
                # ì²« ë²ˆì§¸ í´ë˜ìŠ¤ì˜ ë©”ì„œë“œ ì‹œê·¸ë‹ˆì²˜ ì¶”ì¶œ
                methods = [
                    f"{m.name}({', '.join(a.arg for a in m.args.args)})"
                    for m in node.body
                    if isinstance(m, ast.FunctionDef)
                ]
                return f"class {node.name}:\n" + "\n".join(f"  def {m}" for m in methods)

        return ""

    def analyze_testing_patterns(self) -> Dict:
        """í…ŒìŠ¤íŠ¸ íŒ¨í„´ ë¶„ì„"""
        test_files = list(self.root.glob('tests/**/*.py'))

        patterns = {
            "framework": self.detect_test_framework(test_files),
            "fixtures": self.find_fixtures(),
            "mocking": self.detect_mocking_style(test_files)
        }

        return patterns

    def detect_test_framework(self, test_files: List[Path]) -> str:
        """í…ŒìŠ¤íŠ¸ í”„ë ˆì„ì›Œí¬ ê°ì§€"""
        for file in test_files:
            content = file.read_text()
            if 'import pytest' in content:
                return 'pytest'
            elif 'import unittest' in content:
                return 'unittest'

        return 'unknown'

# ì‚¬ìš©
analyzer = CodebasePatternAnalyzer(Path('/project'))
patterns = analyzer.analyze_architecture_patterns()

print(f"""
í”„ë¡œì íŠ¸ ì•„í‚¤í…ì²˜:
- Layers: {patterns['layers'].keys()}
- Patterns: {[p['pattern'] for p in patterns['patterns']]}
""")
```

#### Step 2: ê¸°ì¡´ íŒ¨í„´ ì¬ì‚¬ìš©

```python
# ê¸°ì¡´ ì½”ë“œë² ì´ìŠ¤ì—ì„œ ë°œê²¬í•œ íŒ¨í„´
existing_patterns = {
    "repository_pattern": """
# ë°œê²¬ ìœ„ì¹˜: src/repositories/user_repository.py
class UserRepository:
    def __init__(self, db_session):
        self.db = db_session

    def get_by_id(self, user_id: int):
        return self.db.query(User).filter_by(id=user_id).first()

    def get_all(self, limit: int = 100):
        return self.db.query(User).limit(limit).all()

    def create(self, user_data: dict):
        user = User(**user_data)
        self.db.add(user)
        self.db.commit()
        return user
    """,

    "service_pattern": """
# ë°œê²¬ ìœ„ì¹˜: src/services/user_service.py
class UserService:
    def __init__(self, user_repo: UserRepository):
        self.user_repo = user_repo

    def register_user(self, email: str, password: str):
        # ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§
        if self.user_repo.get_by_email(email):
            raise UserExistsError()

        hashed_password = hash_password(password)
        return self.user_repo.create({
            'email': email,
            'password': hashed_password
        })
    """
}

# ìƒˆ ê¸°ëŠ¥ë„ ë™ì¼ íŒ¨í„´ ì ìš©
new_feature_code = """
# ìƒˆ ê¸°ëŠ¥: Email Archive (ê¸°ì¡´ íŒ¨í„´ ì¤€ìˆ˜)

# Repository Layer
class EmailRepository:
    def __init__(self, db_session):
        self.db = db_session  # ê¸°ì¡´ íŒ¨í„´ ì¤€ìˆ˜

    def get_by_id(self, email_id: str):
        # ê¸°ì¡´ get_by_id íŒ¨í„´ê³¼ ë™ì¼
        return self.db.query(Email).filter_by(id=email_id).first()

    def batch_archive(self, email_ids: List[str]):
        # ìƒˆ ë©”ì„œë“œì§€ë§Œ ëª…ëª… ê·œì¹™ ì¤€ìˆ˜
        return self.db.query(Email).filter(
            Email.id.in_(email_ids)
        ).update({'archived': True})

# Service Layer
class EmailService:
    def __init__(self, email_repo: EmailRepository):
        self.email_repo = email_repo  # ê¸°ì¡´ íŒ¨í„´ ì¤€ìˆ˜

    def archive_old_emails(self, days: int):
        # ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ (ê¸°ì¡´ ìŠ¤íƒ€ì¼ê³¼ ë™ì¼)
        cutoff_date = datetime.now() - timedelta(days=days)
        old_emails = self.email_repo.get_older_than(cutoff_date)
        return self.email_repo.batch_archive([e.id for e in old_emails])
"""
```

#### Step 3: ì»¨ë²¤ì…˜ ì¤€ìˆ˜

```python
# í”„ë¡œì íŠ¸ë³„ ì»¨ë²¤ì…˜ ìë™ ê°ì§€
class ConventionDetector:
    def detect_naming_conventions(self, project_root: Path) -> Dict:
        """ëª…ëª… ê·œì¹™ ê°ì§€"""
        conventions = {
            "functions": defaultdict(int),
            "classes": defaultdict(int),
            "variables": defaultdict(int)
        }

        for py_file in project_root.glob('**/*.py'):
            with open(py_file) as f:
                tree = ast.parse(f.read())

            for node in ast.walk(tree):
                if isinstance(node, ast.FunctionDef):
                    # í•¨ìˆ˜ëª… íŒ¨í„´ ë¶„ì„
                    if '_' in node.name:
                        conventions["functions"]["snake_case"] += 1
                    elif node.name[0].islower() and node.name[1:].isalnum():
                        conventions["functions"]["camelCase"] += 1

                elif isinstance(node, ast.ClassDef):
                    # í´ë˜ìŠ¤ëª… íŒ¨í„´ ë¶„ì„
                    if node.name[0].isupper():
                        conventions["classes"]["PascalCase"] += 1

        # ë‹¤ìˆ˜ê²°ë¡œ ê²°ì •
        result = {
            "functions": max(conventions["functions"], key=conventions["functions"].get),
            "classes": max(conventions["classes"], key=conventions["classes"].get)
        }

        return result

# ì»¨ë²¤ì…˜ ì ìš©
detector = ConventionDetector()
conventions = detector.detect_naming_conventions(Path('/project'))

print(f"""
í”„ë¡œì íŠ¸ ì»¨ë²¤ì…˜:
- Functions: {conventions['functions']}
- Classes: {conventions['classes']}

â†’ ìƒˆ ì½”ë“œë„ ì´ ê·œì¹™ ì¤€ìˆ˜ í•„ìš”!
""")
```

### ì‹¤ì „ ì˜ˆì œ: ìƒˆ API ì—”ë“œí¬ì¸íŠ¸ ì¶”ê°€

```python
# ê¸°ì¡´ ì½”ë“œë² ì´ìŠ¤ ë¶„ì„ ê²°ê³¼
codebase_analysis = {
    "api_pattern": "Flask Blueprints + Service Layer",
    "example": """
# ê¸°ì¡´ ì½”ë“œ: src/api/users.py
from flask import Blueprint

users_bp = Blueprint('users', __name__)

@users_bp.route('/users/<int:user_id>', methods=['GET'])
def get_user(user_id):
    service = UserService(db.session)
    user = service.get_user(user_id)
    return jsonify(user.to_dict())

@users_bp.route('/users', methods=['POST'])
def create_user():
    service = UserService(db.session)
    user = service.create_user(request.json)
    return jsonify(user.to_dict()), 201
    """,

    "error_handling": """
# ê¸°ì¡´ ì—ëŸ¬ í•¸ë“¤ë§ íŒ¨í„´
@users_bp.errorhandler(UserNotFoundError)
def handle_not_found(error):
    return jsonify({'error': str(error)}), 404

@users_bp.errorhandler(ValidationError)
def handle_validation(error):
    return jsonify({'error': str(error)}), 400
    """
}

# ìƒˆ API ì—”ë“œí¬ì¸íŠ¸ (ë™ì¼ íŒ¨í„´ ì ìš©)
new_endpoint = """
# ìƒˆ ì½”ë“œ: src/api/emails.py (ê¸°ì¡´ íŒ¨í„´ 100% ì¤€ìˆ˜)
from flask import Blueprint

emails_bp = Blueprint('emails', __name__)  # ë™ì¼ Blueprint íŒ¨í„´

@emails_bp.route('/emails/<string:email_id>', methods=['GET'])
def get_email(email_id):
    service = EmailService(db.session)  # ë™ì¼ Service íŒ¨í„´
    email = service.get_email(email_id)
    return jsonify(email.to_dict())  # ë™ì¼ ì§ë ¬í™” íŒ¨í„´

@emails_bp.route('/emails/archive', methods=['POST'])
def archive_emails():
    service = EmailService(db.session)
    archived = service.archive_emails(request.json['email_ids'])
    return jsonify({'archived_count': len(archived)}), 200

# ë™ì¼ ì—ëŸ¬ í•¸ë“¤ë§ íŒ¨í„´
@emails_bp.errorhandler(EmailNotFoundError)
def handle_not_found(error):
    return jsonify({'error': str(error)}), 404

@emails_bp.errorhandler(ValidationError)
def handle_validation(error):
    return jsonify({'error': str(error)}), 400
"""

# ê²°ê³¼: ì½”ë“œ ë¦¬ë·°ì–´ê°€ ì¦‰ì‹œ ì´í•´ ê°€ëŠ¥!
```

### ë„êµ¬ ë° ê¸°ë²•

**ì½”ë“œ ë¶„ì„ ë„êµ¬**:
- `ast`: Python AST íŒŒì‹±
- `grep` / `ripgrep`: íŒ¨í„´ ê²€ìƒ‰
- `tree`: ë””ë ‰í† ë¦¬ êµ¬ì¡° ì‹œê°í™”
- IDEì˜ "Find Usages" ê¸°ëŠ¥

### Common Pitfalls

**í•¨ì • 1: ë ˆê±°ì‹œ íŒ¨í„´ ë¬´ë¹„íŒì  ë³µì‚¬**
```python
# âŒ ì˜ëª»ëœ ì ‘ê·¼
# ê¸°ì¡´ ì½”ë“œê°€ ì•ˆí‹°íŒ¨í„´ì´ì–´ë„ ê·¸ëŒ€ë¡œ ë³µì‚¬

# âœ… ì˜¬ë°”ë¥¸ ì ‘ê·¼
if is_anti_pattern(existing_code):
    # 1. ë¬¸ì„œí™”
    document_anti_pattern(existing_code)
    # 2. ê°œì„ ì•ˆ ì œì‹œ
    propose_refactoring(existing_code)
    # 3. ì ì§„ì  ê°œì„ 
    use_improved_pattern(new_code)
```

## ì „ëµ ì¡°í•© íŒ¨í„´

### íŒ¨í„´ 1: Problem Diagnosis (ë¬¸ì œ ì§„ë‹¨)

```python
# Strategy 3 + 5 ì¡°í•©
def diagnose_performance_issue(endpoint: str):
    """ì„±ëŠ¥ ë¬¸ì œ ì§„ë‹¨: ì½”ë“œë² ì´ìŠ¤ + Git íˆìŠ¤í† ë¦¬"""

    # Strategy 3: í˜„ì¬ ì½”ë“œ ë¶„ì„
    current_code = read_endpoint_code(endpoint)
    issues = analyze_code_issues(current_code)

    # Strategy 5: Git íˆìŠ¤í† ë¦¬ ë¶„ì„
    git_history = analyze_git_history(endpoint)
    performance_degradation = detect_degradation(git_history)

    # í†µí•© ì§„ë‹¨
    diagnosis = {
        "current_issues": issues,
        "degradation_timeline": performance_degradation,
        "root_cause": correlate_issues_with_history(issues, performance_degradation)
    }

    return diagnosis

# ì‹¤í–‰ ê²°ê³¼
diagnosis = diagnose_performance_issue('/api/users')
# {
#   "current_issues": ["N+1 queries", "Missing index"],
#   "degradation_timeline": [
#     "2023-06: Performance was 200ms",
#     "2023-09: Degraded to 1000ms after adding JOIN"
#   ],
#   "root_cause": "JOIN added without index"
# }
```

### íŒ¨í„´ 2: Architecture Decision (ì•„í‚¤í…ì²˜ ê²°ì •)

```python
# Strategy 2 + 7 + 8 ì¡°í•©
def make_architecture_decision(requirement: str):
    """ì•„í‚¤í…ì²˜ ê²°ì •: Best Practices + ì˜µì…˜ ë¹„êµ + ë¦¬ë·°"""

    # Strategy 2: Best Practices ìˆ˜ì§‘
    best_practices = search_best_practices(requirement)

    # Strategy 7: 3ê°€ì§€ ì˜µì…˜ ìƒì„±
    options = synthesize_options(best_practices)

    # Strategy 8: ì „ë¬¸ê°€ ë¦¬ë·°
    reviews = review_with_style_agents(options)

    # ìµœì¢… ê²°ì •
    decision = select_best_option(options, reviews)

    return decision
```

### íŒ¨í„´ 3: Feature Implementation (ê¸°ëŠ¥ êµ¬í˜„)

```python
# Strategy 1 + 3 + 4 ì¡°í•©
def implement_new_feature(feature: str):
    """ì‹ ê·œ ê¸°ëŠ¥ êµ¬í˜„: API ì¬í˜„ + ì½”ë“œë² ì´ìŠ¤ + ë¼ì´ë¸ŒëŸ¬ë¦¬"""

    # Strategy 1: ì™¸ë¶€ API ì¬í˜„
    api_findings = reproduce_api_docs(feature)

    # Strategy 3: ê¸°ì¡´ íŒ¨í„´ ë¶„ì„
    existing_patterns = analyze_codebase_patterns()

    # Strategy 4: ì‚¬ìš© ê°€ëŠ¥í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬
    available_libraries = analyze_installed_libraries()

    # í†µí•© êµ¬í˜„
    implementation = synthesize_implementation(
        api_findings,
        existing_patterns,
        available_libraries
    )

    return implementation
```

## Research Orchestrator í™œìš©ë²•

```python
# ë³‘ë ¬ ì—°êµ¬ ì‘ì—… ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜
from concurrent.futures import ThreadPoolExecutor, as_completed

class ResearchOrchestrator:
    def __init__(self):
        self.strategies = {
            1: Strategy1Reproducer(),
            2: Strategy2BestPractices(),
            3: Strategy3CodebaseGrounding(),
            # ... ë‚˜ë¨¸ì§€ ì „ëµë“¤
        }

    def research(self, problem: str, strategy_ids: List[int], max_workers: int = 4):
        """ë³‘ë ¬ ì—°êµ¬ ì‹¤í–‰"""

        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            # ëª¨ë“  ì „ëµ ë™ì‹œ ì‹¤í–‰
            future_to_strategy = {
                executor.submit(self.strategies[sid].execute, problem): sid
                for sid in strategy_ids
            }

            results = {}
            for future in as_completed(future_to_strategy):
                strategy_id = future_to_strategy[future]
                try:
                    result = future.result()
                    results[strategy_id] = result
                    print(f"âœ… Strategy {strategy_id} completed")
                except Exception as e:
                    print(f"âŒ Strategy {strategy_id} failed: {e}")
                    results[strategy_id] = {"error": str(e)}

        # ê²°ê³¼ í†µí•©
        return self.synthesize_results(results)

    def synthesize_results(self, results: Dict) -> Dict:
        """ê²°ê³¼ í†µí•© ë° ì¶©ëŒ í•´ê²°"""
        synthesis = {
            "findings": [],
            "recommendations": [],
            "conflicts": []
        }

        # ëª¨ë“  ë°œê²¬ì‚¬í•­ ìˆ˜ì§‘
        for strategy_id, result in results.items():
            if "error" not in result:
                synthesis["findings"].extend(result.get("findings", []))
                synthesis["recommendations"].extend(result.get("recommendations", []))

        # ì¶©ëŒ ê°ì§€ ë° í•´ê²°
        conflicts = self.detect_conflicts(synthesis["recommendations"])
        if conflicts:
            synthesis["conflicts"] = conflicts
            synthesis["resolution"] = self.resolve_conflicts(conflicts)

        return synthesis

    def detect_conflicts(self, recommendations: List[Dict]) -> List[Dict]:
        """ìƒì¶©ë˜ëŠ” ê¶Œì¥ì‚¬í•­ ê°ì§€"""
        conflicts = []

        # ì˜ˆ: ë°°ì¹˜ í¬ê¸° ê¶Œì¥ì‚¬í•­ì´ ë‹¤ë¥¼ ë•Œ
        batch_sizes = [
            r for r in recommendations
            if "batch_size" in r
        ]

        if len(set(b["batch_size"] for b in batch_sizes)) > 1:
            conflicts.append({
                "type": "batch_size_conflict",
                "options": batch_sizes
            })

        return conflicts

    def resolve_conflicts(self, conflicts: List[Dict]) -> Dict:
        """ì¶©ëŒ í•´ê²° (ì¦ê±° ê¸°ë°˜)"""
        resolutions = {}

        for conflict in conflicts:
            if conflict["type"] == "batch_size_conflict":
                # ê³µì‹ ë¬¸ì„œ ìš°ì„ 
                official_rec = [
                    opt for opt in conflict["options"]
                    if opt["source"] == "official_docs"
                ]

                if official_rec:
                    resolutions[conflict["type"]] = official_rec[0]
                else:
                    # Best practices ìš°ì„ 
                    resolutions[conflict["type"]] = conflict["options"][0]

        return resolutions

# ì‚¬ìš©
orchestrator = ResearchOrchestrator()
result = orchestrator.research(
    problem="53,000ê°œ ì´ë©”ì¼ ì•„ì¹´ì´ë¸Œ",
    strategy_ids=[1, 2, 3, 5, 7]  # 5ê°œ ì „ëµ ë³‘ë ¬ ì‹¤í–‰
)

print(result["resolution"])
```

## Knowledge Synthesizer íŒ¨í„´

```python
class KnowledgeSynthesizer:
    def __init__(self):
        self.knowledge_base = []

    def synthesize(self, research_results: List[Dict]) -> Dict:
        """ì—¬ëŸ¬ ì—°êµ¬ ê²°ê³¼ë¥¼ ì¼ê´€ëœ ì§€ì‹ìœ¼ë¡œ í†µí•©"""

        synthesis = {
            "unified_findings": self.merge_findings(research_results),
            "action_plan": self.generate_action_plan(research_results),
            "risk_assessment": self.assess_risks(research_results)
        }

        return synthesis

    def merge_findings(self, results: List[Dict]) -> List[Dict]:
        """ì¤‘ë³µ ì œê±° ë° ì§€ì‹ ë³‘í•©"""
        merged = []
        seen = set()

        for result in results:
            for finding in result.get("findings", []):
                # ì˜ë¯¸ë¡ ì  ì¤‘ë³µ ì²´í¬
                key = self.generate_finding_key(finding)
                if key not in seen:
                    merged.append(finding)
                    seen.add(key)
                else:
                    # ì¤‘ë³µì´ì§€ë§Œ ì¶”ê°€ ì •ë³´ê°€ ìˆìœ¼ë©´ ë³‘í•©
                    self.enrich_existing_finding(merged, finding)

        return merged

    def generate_action_plan(self, results: List[Dict]) -> List[Dict]:
        """ì‹¤í–‰ ê°€ëŠ¥í•œ ì•¡ì…˜ í”Œëœ ìƒì„±"""
        actions = []

        # ëª¨ë“  ê¶Œì¥ì‚¬í•­ ìˆ˜ì§‘
        all_recommendations = []
        for result in results:
            all_recommendations.extend(result.get("recommendations", []))

        # ìš°ì„ ìˆœìœ„ ì •ë ¬
        prioritized = self.prioritize_actions(all_recommendations)

        # ì˜ì¡´ì„± ìˆœì„œë¡œ ì •ë ¬
        ordered = self.order_by_dependencies(prioritized)

        return ordered

    def prioritize_actions(self, actions: List[Dict]) -> List[Dict]:
        """ì•¡ì…˜ ìš°ì„ ìˆœìœ„ ê²°ì •"""
        priority_rules = {
            "security": 10,      # ë³´ì•ˆ ìµœìš°ì„ 
            "blocking": 8,       # ë¸”ë¡œí‚¹ ì´ìŠˆ
            "performance": 6,    # ì„±ëŠ¥
            "maintainability": 4 # ìœ ì§€ë³´ìˆ˜ì„±
        }

        for action in actions:
            action["priority"] = priority_rules.get(
                action.get("category", "other"),
                1
            )

        return sorted(actions, key=lambda a: a["priority"], reverse=True)

# ì‚¬ìš©
synthesizer = KnowledgeSynthesizer()
synthesis = synthesizer.synthesize([
    strategy1_results,
    strategy2_results,
    strategy3_results
])

print(synthesis["action_plan"])
# [
#   {"action": "Fix security issue", "priority": 10},
#   {"action": "Add API rate limiting", "priority": 8},
#   {"action": "Optimize queries", "priority": 6}
# ]
```

## ì‹¤ì „ ì›Œí¬ìƒµ

### ì›Œí¬ìƒµ 1: ì´ë©”ì¼ ëŒ€ëŸ‰ ì•„ì¹´ì´ë¸Œ

**ì‹œë‚˜ë¦¬ì˜¤**: 53,000ê°œ Gmail ì´ë©”ì¼ì„ ì•ˆì „í•˜ê²Œ ì•„ì¹´ì´ë¸Œ

**ì‹¤ìŠµ ê³¼ì •**:

```python
# Step 1: ë³µì¡ë„ í‰ê°€
complexity = evaluate_complexity({
    "volume": 53000,
    "api": "Gmail API",
    "constraints": "unknown"
})
# â†’ "HIGH" â†’ Senior Engineer Thinking í™œì„±í™”

# Step 2: ì „ëµ ì„ íƒ
strategies = [1, 2, 3, 5, 7]  # 5ê°œ ì „ëµ

# Step 3: ë³‘ë ¬ ì—°êµ¬
orchestrator = ResearchOrchestrator()
research = orchestrator.research(
    "Gmail 53,000 emails archive",
    strategies
)

# Step 4: ê²°ê³¼ ë¶„ì„
print(research["findings"])
# - API limit: 100 per batch
# - Rate limit: 250 req/s
# - Celery infrastructure exists
# - Past failure: sequential processing

# Step 5: ì†”ë£¨ì…˜ ì„ íƒ
solution = research["resolution"]
# â†’ "Celery + batch processing + checkpoint"

# Step 6: êµ¬í˜„
implement_solution(solution)
```

### ì›Œí¬ìƒµ 2: ì„±ëŠ¥ ìµœì í™”

**ì‹œë‚˜ë¦¬ì˜¤**: API ì—”ë“œí¬ì¸íŠ¸ 10ì´ˆ â†’ 1ì´ˆ ìµœì í™”

**ì‹¤ìŠµ ê³¼ì •**:

```python
# Step 1: ë¬¸ì œ ì§„ë‹¨ (Strategy 3 + 5)
diagnosis = diagnose_performance_issue('/api/dashboard')

# Step 2: í”„ë¡œí† íƒ€ì… ìƒì„± (Strategy 6)
prototypes = create_three_prototypes(diagnosis)

# Step 3: ë²¤ì¹˜ë§ˆí¬
benchmarks = {
    "v1_add_indexes": "2.8s",
    "v2_eager_loading": "0.9s",  # ëª©í‘œ ë‹¬ì„±!
    "v3_caching": "0.05s"
}

# Step 4: ë¦¬ë·° (Strategy 8)
reviews = review_prototypes(prototypes)

# Step 5: ìµœì¢… ì„ íƒ
selected = "v2_eager_loading"  # ê· í˜•ì¡íŒ ì†”ë£¨ì…˜

# Step 6: êµ¬í˜„ ë° ê²€ì¦
implement_and_validate(selected)
```

### ì›Œí¬ìƒµ 3: ìƒˆ API í†µí•©

**ì‹œë‚˜ë¦¬ì˜¤**: Stripe ê²°ì œ ì‹œìŠ¤í…œ í†µí•©

**ì‹¤ìŠµ ê³¼ì •**:

```python
# Step 1: API ë¬¸ì„œ ì¬í˜„ (Strategy 1)
reproduction = reproduce_stripe_docs()

# Step 2: Best Practices (Strategy 2)
best_practices = search_payment_best_practices()

# Step 3: ê¸°ì¡´ ë¼ì´ë¸ŒëŸ¬ë¦¬ í™•ì¸ (Strategy 4)
libraries = analyze_installed_libraries()

# Step 4: í†µí•© êµ¬í˜„
implementation = synthesize_implementation(
    reproduction,
    best_practices,
    libraries
)

# Step 5: ë³´ì•ˆ ë¦¬ë·° (Strategy 8)
security_review = review_with_security_agent(implementation)

# Step 6: ìµœì¢… êµ¬í˜„
deploy_secure_implementation(implementation, security_review)
```

## Best Practices

1. **ì „ëµ ì„ íƒ ê°€ì´ë“œ**:
   - ë‹¨ìˆœ ì‘ì—…: Strategy 3 (ì½”ë“œë² ì´ìŠ¤) ë§Œ
   - ìƒˆ API: Strategy 1 + 2 + 4
   - ì•„í‚¤í…ì²˜: Strategy 2 + 7 + 8
   - ë ˆê±°ì‹œ ë¦¬íŒ©í† ë§: Strategy 3 + 5 + 8

2. **ì‹œê°„ ê´€ë¦¬**:
   - ì—°êµ¬ ì‹œê°„ ì œí•œ ì„¤ì • (30-60ë¶„)
   - ë¹ ë¥¸ ì‹¤íŒ¨: ë§‰íˆë©´ ë‹¤ë¥¸ ì „ëµ ì‹œë„
   - ì ì§„ì  ì‹¬í™”: ì–•ì€ ì—°êµ¬ â†’ í•„ìš”ì‹œ ê¹Šê²Œ

3. **ë¬¸ì„œí™”**:
   - ì—°êµ¬ ê²°ê³¼ë¥¼ SPECì— í¬í•¨
   - ì˜ì‚¬ê²°ì • ê·¼ê±° ëª…ì‹œ
   - íŠ¸ë ˆì´ë“œì˜¤í”„ ë¬¸ì„œí™”

## ë¬¸ì œ í•´ê²°

### Q: ì—°êµ¬ê°€ ë„ˆë¬´ ì˜¤ë˜ ê±¸ë ¤ìš”

**A**:
```python
# ì‹œê°„ ì œí•œ ì„¤ì •
orchestrator.research(
    problem,
    strategies,
    max_time=30  # 30ë¶„ ì œí•œ
)

# ë˜ëŠ” ì–•ì€ ì—°êµ¬ë§Œ
shallow_research(strategies=[3])  # ì½”ë“œë² ì´ìŠ¤ë§Œ ì²´í¬
```

### Q: ì „ëµë“¤ì´ ìƒì¶©ë˜ëŠ” ê²°ê³¼ë¥¼ ì¤˜ìš”

**A**: ì¦ê±° ê¸°ë°˜ ìš°ì„ ìˆœìœ„
1. ê³µì‹ ë¬¸ì„œ (Strategy 1)
2. Best Practices (Strategy 2)
3. ê¸°ì¡´ ì½”ë“œ (Strategy 3)

### Q: ì–´ë–¤ ì „ëµì„ ì„ íƒí• ì§€ ëª¨ë¥´ê² ì–´ìš”

**A**: ì˜ì‚¬ê²°ì • íŠ¸ë¦¬ ì‚¬ìš©
```python
if is_new_library:
    use_strategies([1, 2, 4])
elif is_architecture_decision:
    use_strategies([2, 7, 8])
elif is_legacy_code:
    use_strategies([3, 5, 8])
```

## ë‹¤ìŒ ë‹¨ê³„

1. **ì‹¤ìŠµ**: ìœ„ ì›Œí¬ìƒµ 3ê°œ ì§ì ‘ ì‹¤í–‰
2. **íŒ€ ê³µìœ **: ì—°êµ¬ ê²°ê³¼ë¥¼ íŒ€ê³¼ ê³µìœ í•˜ëŠ” í”„ë¡œì„¸ìŠ¤ í™•ë¦½
3. **ìë™í™”**: Research Orchestratorë¥¼ CI/CDì— í†µí•©
4. **í•™ìŠµ íš¨ê³¼**: Knowledge Graphë¡œ ì¶•ì ëœ ì§€ì‹ ì‹œê°í™”

---

**ì´ì œ Senior Engineerì²˜ëŸ¼ ë¬¸ì œë¥¼ ë¶„ì„í•˜ê³  í•´ê²°í•  ì¤€ë¹„ê°€ ë˜ì—ˆìŠµë‹ˆë‹¤!**

**ë¬¸ì„œ ì‘ì„±**: 2024-01
**ë²„ì „**: v0.22.0
**ìœ ì§€ë³´ìˆ˜**: MoAI-ADK Team
