# Command Orchestration Examples
**MoAI-ADK Agent Orchestration in Commands**
**Version**: 1.0.0
**Date**: 2025-11-12

---

## ê°œìš”

MoAI-ADKì˜ Commandsê°€ ì–´ë–»ê²Œ ì—¬ëŸ¬ agentsë¥¼ ì¡°ìœ¨í•˜ê³  Session Managerë¥¼ í™œìš©í•˜ëŠ”ì§€ ì‹¤ì „ ì˜ˆì œë¥¼ ì œê³µí•©ë‹ˆë‹¤.

**í•µì‹¬ íŒ¨í„´**:

- CommandsëŠ” orchestrationë§Œ ë‹´ë‹¹
- ëª¨ë“  ì‹¤ì œ ì‘ì—…ì€ agentsì—ê²Œ ìœ„ì„
- SessionManagerë¡œ agentId ì¶”ì  ë° resume ê´€ë¦¬
- Alfred contextì— ê²°ê³¼ ì €ì¥ ë° ì „ë‹¬

---

## Command êµ¬ì¡° í…œí”Œë¦¿

### ê¸°ë³¸ êµ¬ì¡°

```python
# /alfred:X-command.py (ì˜ˆì‹œ - ì‹¤ì œëŠ” .md íŒŒì¼)

from moai_adk.core.session_manager import SessionManager, get_session_manager

def execute_command(args: dict) -> dict:
    """
    Command ì‹¤í–‰ ì§„ì…ì 

    Args:
        args: ì‚¬ìš©ì ì…ë ¥ ì¸ì

    Returns:
        ì‹¤í–‰ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
    """
    # Session manager ì´ˆê¸°í™”
    session_mgr = get_session_manager()

    # Alfred context ì´ˆê¸°í™”
    alfred_context = {
        "command": "/alfred:X-command",
        "args": args,
        "agent_results": {},
        "workflow_state": {}
    }

    # STEP 1: ì²« agent í˜¸ì¶œ
    result1 = invoke_agent_1(session_mgr, alfred_context)

    # STEP 2: ê²°ê³¼ ì €ì¥ ë° ë‹¤ìŒ agent í˜¸ì¶œ
    alfred_context["agent_results"]["agent-1"] = result1
    result2 = invoke_agent_2(session_mgr, alfred_context, result1)

    # STEP 3: ìµœì¢… ê²°ê³¼ ë°˜í™˜
    return prepare_final_result(alfred_context)
```

---

## ì˜ˆì œ 1: `/alfred:1-plan` - SPEC ìƒì„± ë° ê³„íš ìˆ˜ë¦½

### Workflow

```
User â†’ /alfred:1-plan "feature" â†’ spec-builder â†’ implementation-planner â†’ User Approval
```

### ì™„ì „í•œ êµ¬í˜„

```python
# File: .claude/commands/alfred-1-plan.py (ê°œë…ì  ì˜ˆì‹œ)

from moai_adk.core.session_manager import SessionManager, register_agent, get_resume_id
from typing import Dict, Any, Optional

def execute_alfred_plan(feature_description: str, expert_consultation: bool = False) -> Dict[str, Any]:
    """
    /alfred:1-plan ëª…ë ¹ ì‹¤í–‰

    Workflow:
    1. spec-builder: SPEC ë¬¸ì„œ ìƒì„±
    2. implementation-planner: êµ¬í˜„ ê³„íš ìˆ˜ë¦½
    3. (Optional) Expert consultation
    4. ì‚¬ìš©ì ìŠ¹ì¸ ëŒ€ê¸°

    Args:
        feature_description: ê¸°ëŠ¥ ì„¤ëª…
        expert_consultation: ì „ë¬¸ê°€ ìë¬¸ í•„ìš” ì—¬ë¶€

    Returns:
        ì‹¤í–‰ ê²°ê³¼ (SPEC ID, ê³„íš ìš”ì•½, ë‹¤ìŒ ë‹¨ê³„)
    """
    # ===== ì´ˆê¸°í™” =====
    session_mgr = SessionManager()

    alfred_context = {
        "command": "/alfred:1-plan",
        "feature": feature_description,
        "agent_results": {},
        "expert_reviews": {},
        "workflow_state": {
            "current_step": "initialize",
            "completed_steps": []
        }
    }

    print(f"ğŸ© Alfred: Starting /alfred:1-plan for '{feature_description}'")

    # ===== STEP 1: SPEC ìƒì„± (spec-builder) =====
    print("\nğŸ“‹ STEP 1: Creating SPEC document...")
    alfred_context["workflow_state"]["current_step"] = "spec_creation"

    # Check if we should resume (unlikely for SPEC creation, but possible)
    resume_id = get_resume_id("spec-builder")

    # Invoke spec-builder
    spec_result = Task(
        subagent_type="spec-builder",
        prompt=f"""You are the spec-builder agent.

        User request: "{feature_description}"

        Your tasks:
        1. Analyze requirements and create SPEC in Korean
        2. Generate SPEC-XXX directory with proper naming
        3. Create spec.md, plan.md, acceptance.md using MultiEdit
        4. Follow EARS format and MoAI-ADK standards

        Use Skill("moai-foundation-specs") and Skill("moai-foundation-ears") for guidance.
        """,
        resume=resume_id if resume_id else None
    )

    # Register result
    register_agent(
        agent_name="spec-builder",
        agent_id=spec_result["agent_id"],
        result=spec_result,
        chain_id=f"{spec_result['spec_id']}-planning"
    )

    # Store in Alfred context
    alfred_context["agent_results"]["spec-builder"] = spec_result
    alfred_context["spec_id"] = spec_result["spec_id"]
    alfred_context["workflow_state"]["completed_steps"].append("spec_creation")

    print(f"âœ… SPEC created: {spec_result['spec_id']}")
    print(f"   Files: {', '.join(spec_result['files_created'])}")

    # ===== STEP 2: êµ¬í˜„ ê³„íš ìˆ˜ë¦½ (implementation-planner) =====
    print(f"\nğŸ› ï¸ STEP 2: Creating implementation plan...")
    alfred_context["workflow_state"]["current_step"] = "planning"

    # Invoke implementation-planner
    plan_result = Task(
        subagent_type="implementation-planner",
        prompt=f"""You are the implementation-planner agent.

        SPEC has been created: {alfred_context['spec_id']}
        Location: .moai/specs/{alfred_context['spec_id']}/spec.md

        Your tasks:
        1. Read SPEC thoroughly
        2. Break down into TAG chain
        3. Identify library dependencies (use WebFetch for latest versions)
        4. Define implementation sequence with priorities
        5. Assess risks and mitigation strategies

        SPEC summary from spec-builder:
        {json.dumps(spec_result['summary'], indent=2)}

        Generate detailed plan in Korean.
        """
    )

    # Register result
    register_agent(
        agent_name="implementation-planner",
        agent_id=plan_result["agent_id"],
        result=plan_result,
        chain_id=f"{alfred_context['spec_id']}-planning"
    )

    # Store in Alfred context
    alfred_context["agent_results"]["implementation-planner"] = plan_result
    alfred_context["tag_chain"] = plan_result["tag_chain"]
    alfred_context["dependencies"] = plan_result["dependencies"]
    alfred_context["workflow_state"]["completed_steps"].append("planning")

    print(f"âœ… Implementation plan created")
    print(f"   TAGs: {len(plan_result['tag_chain'])}")
    print(f"   Dependencies: {list(plan_result['dependencies'].keys())}")

    # ===== STEP 3: Expert Consultation (ì„ íƒì ) =====
    if expert_consultation or plan_result.get("requires_expert_review"):
        print(f"\nğŸ§‘â€ğŸ’¼ STEP 3: Expert consultation...")
        alfred_context["workflow_state"]["current_step"] = "expert_consultation"

        # Determine which experts to consult
        required_experts = identify_required_experts(plan_result)

        for expert_type in required_experts:
            print(f"   Consulting {expert_type}...")

            expert_result = Task(
                subagent_type=f"{expert_type}-expert",
                prompt=f"""You are the {expert_type}-expert agent.

                Review SPEC: {alfred_context['spec_id']}
                Focus: {get_expert_focus(expert_type)}

                Implementation plan:
                {json.dumps(plan_result['summary'], indent=2)}

                Provide:
                1. Architecture recommendations
                2. Risk identification
                3. Best practice suggestions
                4. Technology choices review
                """
            )

            # Register (independent sessions, no resume)
            register_agent(
                agent_name=f"{expert_type}-expert",
                agent_id=expert_result["agent_id"],
                result=expert_result,
                chain_id=f"{alfred_context['spec_id']}-review"
            )

            alfred_context["expert_reviews"][expert_type] = expert_result

        alfred_context["workflow_state"]["completed_steps"].append("expert_consultation")
        print(f"âœ… {len(required_experts)} expert reviews completed")

    # ===== STEP 4: ì‚¬ìš©ì ìŠ¹ì¸ =====
    print(f"\nâœ… Planning complete! Awaiting user approval...")

    # Prepare summary for user
    summary = {
        "spec_id": alfred_context["spec_id"],
        "tag_count": len(alfred_context["tag_chain"]),
        "tags": alfred_context["tag_chain"],
        "dependencies": alfred_context["dependencies"],
        "expert_reviews": list(alfred_context["expert_reviews"].keys()),
        "next_steps": [
            "/alfred:2-run " + alfred_context["spec_id"],
            "Review and modify SPEC if needed",
            "Proceed with implementation when ready"
        ]
    }

    # Ask user for next action
    user_decision = AskUserQuestion(
        questions=[{
            "question": f"Planning complete for {alfred_context['spec_id']}. What would you like to do?",
            "header": "Next Step",
            "multiSelect": False,
            "options": [
                {
                    "label": "Proceed to Implementation",
                    "description": f"Run /alfred:2-run {alfred_context['spec_id']}"
                },
                {
                    "label": "Revise SPEC",
                    "description": "Resume spec-builder to modify SPEC"
                },
                {
                    "label": "Review Later",
                    "description": "Save state and continue later"
                }
            ]
        }]
    )

    # Handle user decision
    if user_decision == "Proceed to Implementation":
        # Automatically trigger /alfred:2-run
        return execute_alfred_run(alfred_context["spec_id"], alfred_context)

    elif user_decision == "Revise SPEC":
        # Resume spec-builder with expert feedback
        revised_spec = Task(
            subagent_type="spec-builder",
            prompt=f"""Continue SPEC creation for {alfred_context['spec_id']}.

            Expert feedback received:
            {json.dumps(alfred_context['expert_reviews'], indent=2)}

            User requested revisions. Update SPEC to address concerns.
            """,
            resume=spec_result["agent_id"]  # ğŸ”‘ Resume with full context
        )

        register_agent(
            agent_name="spec-builder",
            agent_id=revised_spec["agent_id"],
            result=revised_spec,
            chain_id=f"{alfred_context['spec_id']}-planning"
        )

        return {
            "status": "revised",
            "spec_id": alfred_context["spec_id"],
            "message": "SPEC updated based on feedback"
        }

    else:  # Review Later
        return {
            "status": "pending",
            "spec_id": alfred_context["spec_id"],
            "summary": summary,
            "message": f"Planning saved. Run /alfred:2-run {alfred_context['spec_id']} when ready."
        }


def identify_required_experts(plan_result: Dict[str, Any]) -> List[str]:
    """
    Determine which expert agents to consult based on plan.

    Args:
        plan_result: Implementation plan from implementation-planner

    Returns:
        List of expert types (e.g., ["backend", "security", "frontend"])
    """
    experts = []

    # Backend expert if API/database involved
    if any(keyword in str(plan_result).lower() for keyword in ["api", "database", "server", "backend"]):
        experts.append("backend")

    # Frontend expert if UI involved
    if any(keyword in str(plan_result).lower() for keyword in ["ui", "component", "frontend", "client"]):
        experts.append("frontend")

    # Security expert if auth/security involved
    if any(keyword in str(plan_result).lower() for keyword in ["auth", "security", "password", "token"]):
        experts.append("security")

    # DevOps expert if deployment involved
    if any(keyword in str(plan_result).lower() for keyword in ["deploy", "docker", "kubernetes", "ci/cd"]):
        experts.append("devops")

    return experts


def get_expert_focus(expert_type: str) -> str:
    """Get focus area for expert type."""
    focus_map = {
        "backend": "API design, database schema, authentication strategy, security",
        "frontend": "UI/UX, component design, state management, accessibility",
        "security": "OWASP compliance, authentication, authorization, data protection",
        "devops": "Deployment strategy, CI/CD, infrastructure, monitoring"
    }
    return focus_map.get(expert_type, "General architecture and best practices")
```

---

## ì˜ˆì œ 2: `/alfred:2-run` - TDD êµ¬í˜„ ì‹¤í–‰

### Workflow

```
User â†’ /alfred:2-run SPEC-XXX â†’ tdd-implementer (resume) â†’ quality-gate â†’ git-manager â†’ doc-syncer
```

### ì™„ì „í•œ êµ¬í˜„

```python
# File: .claude/commands/alfred-2-run.py (ê°œë…ì  ì˜ˆì‹œ)

def execute_alfred_run(
    spec_id: str,
    context: Optional[Dict[str, Any]] = None
) -> Dict[str, Any]:
    """
    /alfred:2-run ëª…ë ¹ ì‹¤í–‰

    Workflow:
    1. Load or create implementation plan
    2. tdd-implementer: Execute TDD cycle for all TAGs (with resume)
    3. quality-gate: Verify implementation
    4. (If failed) debug-helper: Analyze and suggest fixes
    5. git-manager: Create TDD commits
    6. doc-syncer: Update documentation

    Args:
        spec_id: SPEC identifier (e.g., "SPEC-AUTH-001")
        context: Optional context from /alfred:1-plan

    Returns:
        ì‹¤í–‰ ê²°ê³¼
    """
    # ===== ì´ˆê¸°í™” =====
    session_mgr = SessionManager()

    alfred_context = context or {
        "command": "/alfred:2-run",
        "spec_id": spec_id,
        "agent_results": {},
        "workflow_state": {}
    }

    print(f"ğŸ© Alfred: Starting /alfred:2-run for {spec_id}")

    # ===== STEP 1: êµ¬í˜„ ê³„íš í™•ì¸ =====
    if "tag_chain" not in alfred_context:
        print("\nğŸ“‹ STEP 1: Loading implementation plan...")

        plan_result = Task(
            subagent_type="implementation-planner",
            prompt=f"""You are the implementation-planner agent.

            Load implementation plan for {spec_id}.
            Read SPEC from .moai/specs/{spec_id}/spec.md

            Provide:
            - TAG chain breakdown
            - Library dependencies
            - Implementation sequence
            """
        )

        register_agent(
            agent_name="implementation-planner",
            agent_id=plan_result["agent_id"],
            result=plan_result,
            chain_id=f"{spec_id}-implementation"
        )

        alfred_context["tag_chain"] = plan_result["tag_chain"]
        alfred_context["dependencies"] = plan_result["dependencies"]

    print(f"âœ… Plan loaded: {len(alfred_context['tag_chain'])} TAGs to implement")

    # ===== STEP 2: TDD êµ¬í˜„ (tdd-implementer with resume) =====
    print(f"\nğŸ”¬ STEP 2: TDD Implementation...")

    # Create workflow chain
    session_mgr.create_chain(
        chain_id=f"{spec_id}-implementation",
        agent_sequence=["tdd-implementer", "quality-gate", "git-manager", "doc-syncer"],
        metadata={
            "spec_id": spec_id,
            "tag_chain": alfred_context["tag_chain"]
        }
    )

    # First TAG implementation
    tdd_result = Task(
        subagent_type="tdd-implementer",
        prompt=f"""You are the tdd-implementer agent.

        SPEC: {spec_id}
        TAG chain: {alfred_context['tag_chain']}

        Execute TDD cycle:
        1. RED: Write failing tests for {alfred_context['tag_chain'][0]}
        2. GREEN: Write minimal passing code
        3. REFACTOR: Improve code quality

        Report progress after each phase.
        """
    )

    # Register first execution
    tdd_agent_id = tdd_result["agent_id"]
    register_agent(
        agent_name="tdd-implementer",
        agent_id=tdd_agent_id,
        result=tdd_result,
        chain_id=f"{spec_id}-implementation"
    )

    alfred_context["agent_results"]["tdd-implementer"] = tdd_result
    completed_tags = [tdd_result["current_tag"]]

    print(f"âœ… TAG {tdd_result['current_tag']} complete (1/{len(alfred_context['tag_chain'])})")

    # Continue with remaining TAGs (resume pattern)
    for i, tag in enumerate(alfred_context['tag_chain'][1:], start=2):
        print(f"\nğŸ”¬ Implementing TAG {tag} ({i}/{len(alfred_context['tag_chain'])})...")

        # Resume tdd-implementer for next TAG
        tdd_result = Task(
            subagent_type="tdd-implementer",
            prompt=f"""Continue TDD implementation for TAG {tag}.

            Previous TAG {completed_tags[-1]} is complete.
            Maintain code quality and test coverage.

            Execute RED-GREEN-REFACTOR cycle for TAG {tag}.
            """,
            resume=tdd_agent_id  # ğŸ”‘ Resume with full context
        )

        # Update resume count
        session_mgr.increment_resume_count(tdd_agent_id)

        completed_tags.append(tag)
        print(f"âœ… TAG {tag} complete ({i}/{len(alfred_context['tag_chain'])})")

    # Final implementation result
    alfred_context["agent_results"]["tdd-implementer"] = tdd_result
    alfred_context["workflow_state"]["tdd_complete"] = True

    print(f"\nâœ… All TAGs implemented: {len(completed_tags)}/{len(alfred_context['tag_chain'])}")

    # ===== STEP 3: í’ˆì§ˆ ê²€ì¦ (quality-gate) =====
    print(f"\nğŸ” STEP 3: Quality validation...")

    qa_result = Task(
        subagent_type="quality-gate",
        prompt=f"""You are the quality-gate agent.

        Verify implementation of {spec_id}:
        1. Run test suite and check coverage (target: 85%)
        2. Run linting (ruff for Python)
        3. Run type checking (mypy for Python)
        4. Verify TRUST principles compliance
        5. Validate TAG chain integrity

        Implementation summary:
        - TAGs: {completed_tags}
        - Files created: {tdd_result.get('files_created', [])}

        Provide detailed quality report.
        """
    )

    register_agent(
        agent_name="quality-gate",
        agent_id=qa_result["agent_id"],
        result=qa_result,
        chain_id=f"{spec_id}-implementation"
    )

    alfred_context["agent_results"]["quality-gate"] = qa_result

    # ===== STEP 3.1: í’ˆì§ˆ ê²€ì¦ ì‹¤íŒ¨ ì²˜ë¦¬ =====
    if qa_result["status"] != "success":
        print(f"âŒ Quality validation failed")
        print(f"   Issues: {len(qa_result['issues'])}")

        # Invoke debug-helper
        print(f"\nğŸ”§ Invoking debug-helper...")

        debug_result = Task(
            subagent_type="debug-helper",
            prompt=f"""You are the debug-helper agent.

            Quality gate failed for {spec_id}.

            Issues:
            {json.dumps(qa_result['issues'], indent=2)}

            Provide:
            1. Root cause analysis for each issue
            2. Specific fix recommendations
            3. Code snippets for fixes
            """
        )

        register_agent(
            agent_name="debug-helper",
            agent_id=debug_result["agent_id"],
            result=debug_result,
            chain_id=f"{spec_id}-debugging"
        )

        # Ask user how to proceed
        user_action = AskUserQuestion(
            questions=[{
                "question": "Quality validation failed. How would you like to proceed?",
                "header": "Fix Strategy",
                "multiSelect": False,
                "options": [
                    {
                        "label": "Auto-fix with debug-helper recommendations",
                        "description": "Resume tdd-implementer to apply fixes"
                    },
                    {
                        "label": "Manual fix",
                        "description": "Fix code manually and re-run validation"
                    },
                    {
                        "label": "Abort",
                        "description": "Stop execution and review issues"
                    }
                ]
            }]
        )

        if user_action == "Auto-fix with debug-helper recommendations":
            # Resume tdd-implementer to apply fixes
            fix_result = Task(
                subagent_type="tdd-implementer",
                prompt=f"""Apply fixes based on debug-helper analysis.

                Issues:
                {json.dumps(qa_result['issues'], indent=2)}

                Recommendations:
                {json.dumps(debug_result['recommendations'], indent=2)}

                Fix code and re-run tests.
                """,
                resume=tdd_agent_id  # ğŸ”‘ Resume to maintain context
            )

            session_mgr.increment_resume_count(tdd_agent_id)

            # Re-run quality gate
            qa_result = Task(
                subagent_type="quality-gate",
                prompt=f"Re-verify {spec_id} after fixes"
            )

            register_agent(
                agent_name="quality-gate",
                agent_id=qa_result["agent_id"],
                result=qa_result,
                chain_id=f"{spec_id}-implementation"
            )

        elif user_action == "Abort":
            return {
                "status": "failed",
                "spec_id": spec_id,
                "issues": qa_result["issues"],
                "debug_recommendations": debug_result.get("recommendations", [])
            }

    print(f"âœ… Quality validation passed")
    print(f"   Coverage: {qa_result['coverage']}%")
    print(f"   Tests: {qa_result['tests_passed']}/{qa_result['tests_total']}")

    # ===== STEP 4: Git Commit (git-manager) =====
    print(f"\nğŸ“ STEP 4: Creating Git commit...")

    commit_result = Task(
        subagent_type="git-manager",
        prompt=f"""You are the git-manager agent.

        Create TDD commit for {spec_id}:
        1. Stage implementation files
        2. Generate commit message following conventional commits
        3. Include TAG references
        4. Add quality metrics to commit message

        Implementation summary:
        - TAGs: {completed_tags}
        - Coverage: {qa_result['coverage']}%
        - Tests: {qa_result['tests_passed']}/{qa_result['tests_total']}

        Files to commit:
        {json.dumps(tdd_result.get('files_created', []), indent=2)}
        """
    )

    register_agent(
        agent_name="git-manager",
        agent_id=commit_result["agent_id"],
        result=commit_result,
        chain_id=f"{spec_id}-implementation"
    )

    alfred_context["agent_results"]["git-manager"] = commit_result

    print(f"âœ… Commit created: {commit_result['commit_sha'][:7]}")
    print(f"   Message: {commit_result['commit_message'].split(chr(10))[0]}")

    # ===== STEP 5: ë¬¸ì„œ ë™ê¸°í™” (doc-syncer) =====
    print(f"\nğŸ“š STEP 5: Synchronizing documentation...")

    doc_result = Task(
        subagent_type="doc-syncer",
        prompt=f"""You are the doc-syncer agent.

        Synchronize documentation for {spec_id}:
        1. Update .moai/project/product.md (new feature added)
        2. Update .moai/project/structure.md (if architecture changed)
        3. Update .moai/project/tech.md (if new libraries added)
        4. Ensure TAG chain consistency

        Implementation details:
        - TAGs: {completed_tags}
        - Features: {tdd_result.get('features_implemented', [])}
        - Dependencies: {alfred_context.get('dependencies', {})}
        """
    )

    register_agent(
        agent_name="doc-syncer",
        agent_id=doc_result["agent_id"],
        result=doc_result,
        chain_id=f"{spec_id}-implementation"
    )

    alfred_context["agent_results"]["doc-syncer"] = doc_result

    print(f"âœ… Documentation synchronized")
    print(f"   Updated: {', '.join(doc_result['files_updated'])}")

    # ===== STEP 6: ìµœì¢… ìš”ì•½ =====
    print(f"\nğŸ‰ Implementation complete for {spec_id}!")

    summary = {
        "status": "success",
        "spec_id": spec_id,
        "tags_implemented": completed_tags,
        "coverage": qa_result["coverage"],
        "commit_sha": commit_result["commit_sha"],
        "files_created": tdd_result.get("files_created", []),
        "files_updated": doc_result["files_updated"],
        "next_command": "/alfred:3-sync"
    }

    # Ask for next step
    user_next = AskUserQuestion(
        questions=[{
            "question": f"Implementation complete for {spec_id}. What's next?",
            "header": "Next Step",
            "multiSelect": False,
            "options": [
                {
                    "label": "Run /alfred:3-sync",
                    "description": "Synchronize all documentation and create PR"
                },
                {
                    "label": "Implement another SPEC",
                    "description": "Start /alfred:1-plan for new feature"
                },
                {
                    "label": "Review and test",
                    "description": "Manual review before proceeding"
                }
            ]
        }]
    )

    if user_next == "Run /alfred:3-sync":
        return execute_alfred_sync(spec_id, alfred_context)
    else:
        return summary
```

---

## ì˜ˆì œ 3: Resume Pattern - ì—¬ëŸ¬ ë¬¸ì„œ ì—°ì† ì—…ë°ì´íŠ¸

### Workflow

```
doc-syncer: product.md â†’ structure.md â†’ tech.md (ëª¨ë‘ resumeë¡œ ì—°ê²°)
```

### êµ¬í˜„

```python
def sync_all_documents(spec_id: str, implementation_summary: Dict[str, Any]) -> Dict[str, Any]:
    """
    ëª¨ë“  í”„ë¡œì íŠ¸ ë¬¸ì„œë¥¼ ì—°ì†ì ìœ¼ë¡œ ì—…ë°ì´íŠ¸ (resume í™œìš©)

    Args:
        spec_id: SPEC ID
        implementation_summary: êµ¬í˜„ ìš”ì•½ ì •ë³´

    Returns:
        ë™ê¸°í™” ê²°ê³¼
    """
    session_mgr = SessionManager()

    documents = ["product.md", "structure.md", "tech.md"]
    doc_syncer_id = None

    for i, doc in enumerate(documents):
        print(f"\nğŸ“„ Updating {doc} ({i+1}/{len(documents)})...")

        # First execution or resume
        is_first = (i == 0)

        doc_result = Task(
            subagent_type="doc-syncer",
            prompt=f"""You are the doc-syncer agent.

            {"This is the first document in a series." if is_first else f"Continue updating documents. {documents[i-1]} is complete."}

            Update {doc} with implementation of {spec_id}:
            {json.dumps(implementation_summary, indent=2)}

            Maintain consistent style and cross-references.
            """,
            resume=doc_syncer_id if not is_first else None  # ğŸ”‘ Resume from 2nd onwards
        )

        # Save agent ID on first execution
        if is_first:
            doc_syncer_id = doc_result["agent_id"]

        register_agent(
            agent_name="doc-syncer",
            agent_id=doc_result["agent_id"],
            result=doc_result,
            chain_id=f"{spec_id}-documentation"
        )

        if not is_first:
            session_mgr.increment_resume_count(doc_syncer_id)

        print(f"âœ… {doc} updated")

    return {
        "status": "success",
        "documents_updated": documents,
        "agent_id": doc_syncer_id
    }
```

**Resumeì˜ ì´ì **:

- âœ… ì¼ê´€ëœ ìŠ¤íƒ€ì¼ ìœ ì§€ (ê°™ì€ ìš©ì–´, ê°™ì€ êµ¬ì¡°)
- âœ… ë¬¸ì„œ ê°„ ìƒí˜¸ ì°¸ì¡° ì •í™•ì„±
- âœ… ì¤‘ë³µ ì„¤ëª… ë¶ˆí•„ìš” (ì²« ë¬¸ì„œì—ì„œ ì´ë¯¸ ì„¤ëª…)

---

## ì˜ˆì œ 4: ë³‘ë ¬ ì‹¤í–‰ - ì—¬ëŸ¬ ì „ë¬¸ê°€ ë™ì‹œ ìë¬¸

### Workflow

```
                  â”Œâ”€ backend-expert
Alfred (parallel) â”¼â”€ frontend-expert â†’ Alfred (merge results) â†’ spec-builder (update)
                  â””â”€ security-expert
```

### êµ¬í˜„

```python
import asyncio
from typing import List

async def parallel_expert_consultation(
    spec_id: str,
    experts: List[str]
) -> Dict[str, Any]:
    """
    ì—¬ëŸ¬ ì „ë¬¸ê°€ì—ê²Œ ë™ì‹œì— ìë¬¸ (ë³‘ë ¬ ì‹¤í–‰)

    Args:
        spec_id: SPEC ID
        experts: ì „ë¬¸ê°€ íƒ€ì… ë¦¬ìŠ¤íŠ¸ (ì˜ˆ: ["backend", "security", "frontend"])

    Returns:
        í†µí•© ìë¬¸ ê²°ê³¼
    """
    print(f"ğŸ§‘â€ğŸ’¼ Consulting {len(experts)} experts in parallel...")

    # Prepare tasks (conceptual - Task() is synchronous in reality)
    expert_tasks = []

    for expert_type in experts:
        # Each expert runs independently (no resume needed)
        expert_result = Task(
            subagent_type=f"{expert_type}-expert",
            prompt=f"""You are the {expert_type}-expert agent.

            Review SPEC {spec_id} for {expert_type} concerns.

            Provide:
            - Architecture recommendations
            - Risk identification
            - Best practices
            - Technology choices
            """
        )

        # Register each independently
        register_agent(
            agent_name=f"{expert_type}-expert",
            agent_id=expert_result["agent_id"],
            result=expert_result,
            chain_id=f"{spec_id}-expert-review"
        )

        expert_tasks.append(expert_result)

    # Merge results
    merged_feedback = {
        "spec_id": spec_id,
        "expert_count": len(experts),
        "recommendations": [],
        "risks": [],
        "action_items": []
    }

    for expert_result in expert_tasks:
        merged_feedback["recommendations"].extend(expert_result.get("recommendations", []))
        merged_feedback["risks"].extend(expert_result.get("risks", []))
        merged_feedback["action_items"].extend(expert_result.get("action_items", []))

    print(f"âœ… {len(experts)} expert reviews merged")

    return merged_feedback
```

---

## SessionManager í†µí•© íŒ¨í„´

### Pattern 1: ê¸°ë³¸ ë“±ë¡

```python
# Agent ì‹¤í–‰ í›„ ì¦‰ì‹œ ë“±ë¡
result = Task(subagent_type="agent-name", prompt="...")

register_agent(
    agent_name="agent-name",
    agent_id=result["agent_id"],
    result=result,
    chain_id="workflow-chain-id"
)
```

---

### Pattern 2: Resume ê²°ì •

```python
# Should resume?
should_resume_decision = session_mgr.should_resume(
    agent_name="tdd-implementer",
    current_task="Implement TAG-002",
    previous_task="Implement TAG-001"
)

if should_resume_decision:
    resume_id = get_resume_id("tdd-implementer", chain_id="SPEC-XXX-implementation")
    result = Task(subagent_type="tdd-implementer", prompt="...", resume=resume_id)
    session_mgr.increment_resume_count(resume_id)
else:
    result = Task(subagent_type="tdd-implementer", prompt="...")
```

---

### Pattern 3: Chain ê²°ê³¼ ì¡°íšŒ

```python
# Get all results in a chain
chain_results = session_mgr.get_chain_results("SPEC-AUTH-001-implementation")

for result in chain_results:
    print(f"{result['agent_name']}: {result['timestamp']}")
```

---

## Error Handling íŒ¨í„´

### Pattern 1: Agent ì‹¤íŒ¨ ì‹œ ì¬ì‹œë„

```python
max_retries = 2
for attempt in range(max_retries + 1):
    try:
        result = Task(subagent_type="agent-name", prompt="...")

        if result["status"] == "success":
            register_agent("agent-name", result["agent_id"], result)
            break
    except Exception as e:
        if attempt < max_retries:
            print(f"Retry {attempt + 1}/{max_retries}...")
            # Start new session on retry (don't resume failed session)
            continue
        else:
            # Escalate to debug-helper
            debug_result = Task(
                subagent_type="debug-helper",
                prompt=f"Analyze failure: {str(e)}"
            )
            raise
```

---

### Pattern 2: Quality Gate ì‹¤íŒ¨ ë£¨í”„

```python
max_iterations = 3

for iteration in range(max_iterations):
    # Implement
    impl_result = Task(
        subagent_type="tdd-implementer",
        prompt=f"Implement (iteration {iteration + 1})",
        resume=tdd_id if iteration > 0 else None
    )

    # Validate
    qa_result = Task(subagent_type="quality-gate", prompt="Validate")

    if qa_result["status"] == "success":
        break  # Success!

    if iteration < max_iterations - 1:
        # Debug and retry
        debug_result = Task(subagent_type="debug-helper", prompt=f"Fix: {qa_result['issues']}")
        tdd_id = impl_result["agent_id"]
    else:
        # Max iterations reached
        raise QualityGateError("Failed after max iterations")
```

---

## Best Practices

### âœ… DO

1. **ëª¨ë“  agent ê²°ê³¼ë¥¼ ì¦‰ì‹œ ë“±ë¡**
   ```python
   result = Task(...)
   register_agent(agent_name, result["agent_id"], result, chain_id)
   ```

2. **Chain ID ì¼ê´€ì„± ìœ ì§€**
   ```python
   chain_id = f"{spec_id}-{workflow_type}"  # ì˜ˆ: "SPEC-AUTH-001-implementation"
   ```

3. **Resume ì‚¬ìš© ì‹œ increment**
   ```python
   result = Task(..., resume=resume_id)
   session_mgr.increment_resume_count(resume_id)
   ```

4. **Alfred contextì— ê²°ê³¼ ì €ì¥**
   ```python
   alfred_context["agent_results"][agent_name] = result
   ```

5. **Workflow ìƒíƒœ ì¶”ì **
   ```python
   alfred_context["workflow_state"]["completed_steps"].append("planning")
   ```

---

### âŒ DON'T

1. **Agentê°€ ë‹¤ë¥¸ agent í˜¸ì¶œ**
   ```python
   # âŒ In agent file
   result = Task(subagent_type="other-agent", ...)
   ```

2. **íŒŒì¼ë¡œ agent ê°„ í†µì‹ **
   ```python
   # âŒ In agent file
   Write(".moai/temp/plan.json", plan_data)
   # Next agent reads this file
   ```

3. **Resume ì—†ì´ ì—°ì† ì‘ì—…**
   ```python
   # âŒ TAG-001, TAG-002ë¥¼ ë³„ê°œ sessionìœ¼ë¡œ
   Task(subagent_type="tdd-implementer", prompt="TAG-001")
   Task(subagent_type="tdd-implementer", prompt="TAG-002")  # Context ì†ì‹¤!
   ```

4. **Resume count ë¯¸ì¦ê°€**
   ```python
   # âŒ Resume ì‚¬ìš©í–ˆëŠ”ë° count ì•ˆ ì˜¬ë¦¼
   Task(..., resume=resume_id)
   # session_mgr.increment_resume_count(resume_id) ëˆ„ë½
   ```

---

## ì°¸ê³  ìë£Œ

- **Alfred Orchestration**: `.moai/config/alfred-orchestration.yaml`
- **Agent Invocation**: `.moai/guidelines/agent-invocation.md`
- **SessionManager**: `src/moai_adk/core/session_manager.py`
- **Official Docs**: https://code.claude.com/docs/en/sub-agents

---

**Last Updated**: 2025-11-12
**Version**: 1.0.0
