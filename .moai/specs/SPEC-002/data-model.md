# @DATA:TAG-MODEL "16-Core TAG ê´€ë¦¬ ì‹œìŠ¤í…œ ë°ì´í„° ëª¨ë¸"

> **SPEC-002 Phase 1 Design**: ì½”ë“œ TAG ê´€ë¦¬ ì‹œìŠ¤í…œì˜ í•µì‹¬ ë°ì´í„° ëª¨ë¸ ë° ì•„í‚¤í…ì²˜ ì„¤ê³„

## ğŸ“Š ê°œìš”

ë³¸ ë¬¸ì„œëŠ” SPEC-002ì˜ Phase 1 ì„¤ê³„ë¡œ, 16-Core TAG ê´€ë¦¬ ì‹œìŠ¤í…œì˜ ë°ì´í„° ëª¨ë¸, í”Œë¡œìš° ì„¤ê³„, ì €ì¥ ì „ëµ ë° ì„±ëŠ¥ ê³ ë ¤ì‚¬í•­ì„ ë‹¤ë£¹ë‹ˆë‹¤.

## ğŸ—ï¸ í•µì‹¬ ì—”í‹°í‹° ëª¨ë¸

### 1. Tag ì—”í‹°í‹°

```python
@dataclass
class Tag:
    """16-Core TAG ì‹œìŠ¤í…œì˜ í•µì‹¬ ì—”í‹°í‹°"""

    # ê¸°ë³¸ ì‹ë³„ ì •ë³´
    id: str  # @REQ:CODE-TAG-002 í˜•ì‹
    category: TagCategory  # SPEC, STEERING, IMPLEMENTATION, QUALITY
    type: TagType  # REQ, DESIGN, TASK, etc.
    topic: str  # CODE-TAG, USER-AUTH, etc.
    sequence: Optional[str]  # 002, 001, etc.

    # ë©”íƒ€ë°ì´í„°
    description: str
    created_at: datetime
    updated_at: datetime
    status: TagStatus  # active, draft, deprecated
    priority: Optional[int]  # 1-5 ìš°ì„ ìˆœìœ„

    # ìœ„ì¹˜ ì •ë³´
    file_path: str
    line_number: int
    context: Optional[str]  # ì£¼ë³€ ì½”ë“œ ì»¨í…ìŠ¤íŠ¸

    # ì¶”ì ì„± ì •ë³´
    parent_tags: List[str]  # ìƒìœ„ TAG ì°¸ì¡°
    child_tags: List[str]   # í•˜ìœ„ TAG ì°¸ì¡°
    related_tags: List[str] # ì—°ê´€ TAG ì°¸ì¡°

    # í’ˆì§ˆ ì •ë³´
    auto_generated: bool = False
    confidence_score: float = 1.0  # 0.0-1.0
    validation_status: ValidationStatus = ValidationStatus.PENDING

    # ë³€ê²½ ì¶”ì 
    created_by: Optional[str]
    last_modified_by: Optional[str]
    change_reason: Optional[str]
```

### 2. TagIndex ì—”í‹°í‹°

```python
@dataclass
class TagIndex:
    """TAG ì¸ë±ìŠ¤ ê´€ë¦¬ ì—”í‹°í‹°"""

    # ì¸ë±ìŠ¤ ë©”íƒ€ë°ì´í„°
    version: str  # 16-core
    created_at: datetime
    last_updated: datetime
    total_tags: int

    # ì¹´í…Œê³ ë¦¬ë³„ í†µê³„
    category_stats: Dict[TagCategory, int]
    status_stats: Dict[TagStatus, int]

    # ì¸ë±ìŠ¤ ë°ì´í„°
    tags: Dict[str, Tag]  # tag_id -> Tag
    file_mappings: Dict[str, List[str]]  # file_path -> [tag_ids]

    # ê´€ê³„ ê·¸ë˜í”„
    relationships: Dict[str, List[TagRelationship]]

    # ì„±ëŠ¥ ë©”íŠ¸ë¦­
    index_size_bytes: int
    last_scan_duration_ms: int
    last_validation_duration_ms: int
```

### 3. FileMapping ì—”í‹°í‹°

```python
@dataclass
class FileMapping:
    """íŒŒì¼ê³¼ TAG ê°„ì˜ ë§¤í•‘ ì •ë³´"""

    # íŒŒì¼ ì •ë³´
    file_path: str
    file_hash: str  # SHA-256 hash
    file_size_bytes: int
    last_modified: datetime

    # TAG ì •ë³´
    tags: List[str]  # TAG IDs in this file
    tag_count: int

    # íŒŒì¼ ë©”íƒ€ë°ì´í„°
    language: str  # python, javascript, etc.
    encoding: str  # utf-8
    line_count: int
    function_count: int
    class_count: int
    complexity_score: float

    # íŒŒì‹± ì •ë³´
    parser_used: ParserType  # libcst, tree_sitter, ast
    parse_time_ms: int
    syntax_errors: List[str]
    warnings: List[str]

    # ìƒíƒœ ì¶”ì 
    scan_status: ScanStatus  # success, error, skipped
    last_scanned: datetime
    scan_duration_ms: int
```

### 4. ValidationResult ì—”í‹°í‹°

```python
@dataclass
class ValidationResult:
    """TAG ê²€ì¦ ê²°ê³¼"""

    # ê²€ì¦ ì„¸ì…˜ ì •ë³´
    validation_id: str  # UUID
    timestamp: datetime
    validation_type: ValidationType  # format, consistency, traceability

    # ê²€ì¦ ëŒ€ìƒ
    target_tags: List[str]
    target_files: List[str]
    scope: ValidationScope  # project, directory, file

    # ê²€ì¦ ê²°ê³¼
    status: ValidationStatus  # passed, failed, warning
    total_checks: int
    passed_checks: int
    failed_checks: int
    warnings: int

    # ìƒì„¸ ê²°ê³¼
    issues: List[ValidationIssue]
    suggestions: List[str]
    auto_fixes_applied: List[str]

    # ì„±ëŠ¥ ì •ë³´
    duration_ms: int
    memory_usage_mb: float
    processed_items: int
```

## ğŸ”„ ë°ì´í„° í”Œë¡œìš° ì„¤ê³„

### 1. Scan â†’ Validate â†’ Index â†’ Monitor íŒŒì´í”„ë¼ì¸

```mermaid
graph LR
    A[File Changes] --> B[Scanner]
    B --> C[Parser<br/>LibCST/Tree-sitter]
    C --> D[TAG Extractor]
    D --> E[Validator]
    E --> F{Valid?}
    F -->|Yes| G[Indexer]
    F -->|No| H[Auto-Repair]
    H --> E
    G --> I[JSON Store]
    G --> J[SQLite Store]
    I --> K[Monitor]
    J --> K
    K --> L[Dashboard]
```

### 2. ì‹¤ì‹œê°„ ë³€ê²½ ê°ì§€ í”Œë¡œìš°

```python
class ChangeDetectionFlow:
    """ì‹¤ì‹œê°„ íŒŒì¼ ë³€ê²½ ê°ì§€ ë° ì²˜ë¦¬"""

    def __init__(self):
        self.file_watcher = WatchdogObserver()
        self.change_queue = asyncio.Queue()
        self.batch_processor = BatchProcessor()

    async def process_file_change(self, event: FileSystemEvent):
        """íŒŒì¼ ë³€ê²½ ì´ë²¤íŠ¸ ì²˜ë¦¬"""
        if event.src_path.endswith('.py'):
            change = FileChange(
                file_path=event.src_path,
                change_type=event.event_type,
                timestamp=datetime.now()
            )
            await self.change_queue.put(change)

    async def batch_process_changes(self):
        """ë³€ê²½ì‚¬í•­ ë°°ì¹˜ ì²˜ë¦¬"""
        changes = await self.batch_processor.collect_changes(
            timeout_ms=1000,  # 1ì´ˆ ëŒ€ê¸°
            max_batch_size=50
        )

        # ìŠ¤ìº” â†’ ê²€ì¦ â†’ ì¸ë±ì‹± íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
        scan_results = await self.scanner.scan_files(changes)
        validation_results = await self.validator.validate_tags(scan_results)
        await self.indexer.update_index(validation_results)

        # ëª¨ë‹ˆí„°ë§ ì´ë²¤íŠ¸ ë°œìƒ
        await self.monitor.emit_change_event(changes, validation_results)
```

### 3. ê²€ì¦ ì²´ì¸ í”Œë¡œìš°

```python
class ValidationChain:
    """TAG ê²€ì¦ ì²´ì¸ ì²˜ë¦¬"""

    validators = [
        FormatValidator(),      # TAG í˜•ì‹ ê²€ì¦
        NamingValidator(),      # ëª…ëª… ê·œì¹™ ê²€ì¦
        ConsistencyValidator(), # ì¼ê´€ì„± ê²€ì¦
        TraceabilityValidator(), # ì¶”ì ì„± ê²€ì¦
        DuplicateValidator(),   # ì¤‘ë³µ ê²€ì¦
        OrphanValidator()       # ê³ ì•„ TAG ê²€ì¦
    ]

    async def validate(self, tags: List[Tag]) -> ValidationResult:
        """ê²€ì¦ ì²´ì¸ ì‹¤í–‰"""
        result = ValidationResult()

        for validator in self.validators:
            validator_result = await validator.validate(tags)
            result.merge(validator_result)

            # ì‹¬ê°í•œ ì˜¤ë¥˜ ì‹œ ì²´ì¸ ì¤‘ë‹¨
            if validator_result.has_critical_errors():
                break

        return result
```

## ğŸ’¾ ì €ì¥ ì „ëµ - JSON + SQLite í•˜ì´ë¸Œë¦¬ë“œ ì ‘ê·¼

### 1. JSON ì €ì¥ì†Œ (ë©”ì¸ ì¸ë±ìŠ¤)

```json
{
  "meta": {
    "version": "16-core",
    "created": "2025-09-18T10:00:00Z",
    "last_updated": "2025-09-18T15:30:00Z",
    "total_tags": 1247,
    "index_size_bytes": 2048576
  },
  "categories": {
    "SPEC": {
      "description": "ë¬¸ì„œ ì¶”ì  - í•„ìˆ˜",
      "tags": ["REQ", "DESIGN", "TASK"],
      "count": 425
    },
    "STEERING": {
      "description": "ì›ì¹™ ì¶”ì  - í•„ìˆ˜",
      "tags": ["VISION", "STRUCT", "TECH", "ADR"],
      "count": 156
    },
    "IMPLEMENTATION": {
      "description": "ì½”ë“œ ì¶”ì  - í•„ìˆ˜",
      "tags": ["FEATURE", "API", "TEST", "DATA"],
      "count": 498
    },
    "QUALITY": {
      "description": "í’ˆì§ˆ ì¶”ì  - ì„ íƒ",
      "tags": ["PERF", "SEC", "DEBT", "TODO"],
      "count": 168
    }
  },
  "active_tags": {
    "@REQ:CODE-TAG-002": {
      "category": "SPEC",
      "topic": "CODE-TAG",
      "id": "002",
      "description": "src/moai_adk ì½”ë“œë² ì´ìŠ¤ ì „ì²´ì— 16-Core TAG ì‹œìŠ¤í…œ ì ìš©",
      "file": ".moai/specs/SPEC-002/spec.md",
      "line": 3,
      "created": "2025-09-18T10:00:00Z",
      "updated": "2025-09-18T15:30:00Z",
      "status": "active",
      "priority": 2,
      "relationships": {
        "implements": ["@VISION:MOAI-ADK"],
        "references": ["@TECH:MOAI-ADK"],
        "traces_to": ["@TASK:TAG-SCAN-001", "@TASK:TAG-VALIDATE-001"]
      }
    }
  },
  "file_mappings": {
    "src/moai_adk/core/engine.py": {
      "tags": ["@FEATURE:ENGINE-CORE", "@API:GET-STATUS"],
      "last_scanned": "2025-09-18T15:25:00Z",
      "hash": "a1b2c3d4e5f6...",
      "size_bytes": 1024,
      "line_count": 45,
      "complexity": 3.2
    }
  },
  "statistics": {
    "by_category": {
      "SPEC": 425,
      "STEERING": 156,
      "IMPLEMENTATION": 498,
      "QUALITY": 168
    },
    "by_status": {
      "active": 1180,
      "draft": 45,
      "deprecated": 22
    },
    "health_metrics": {
      "orphaned_tags": 12,
      "duplicate_tags": 3,
      "broken_references": 5,
      "health_score": 0.94
    }
  }
}
```

### 2. SQLite ì €ì¥ì†Œ (ê´€ê³„í˜• ë°ì´í„°)

```sql
-- í…Œì´ë¸” ìŠ¤í‚¤ë§ˆ
CREATE TABLE tags (
    id TEXT PRIMARY KEY,
    category TEXT NOT NULL,
    type TEXT NOT NULL,
    topic TEXT NOT NULL,
    sequence TEXT,
    description TEXT NOT NULL,
    file_path TEXT NOT NULL,
    line_number INTEGER NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    status TEXT DEFAULT 'active',
    priority INTEGER,
    auto_generated BOOLEAN DEFAULT FALSE,
    confidence_score REAL DEFAULT 1.0,
    created_by TEXT,
    last_modified_by TEXT
);

CREATE TABLE tag_relationships (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    source_tag TEXT NOT NULL,
    target_tag TEXT NOT NULL,
    relationship_type TEXT NOT NULL, -- implements, references, traces_to
    strength REAL DEFAULT 1.0,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    FOREIGN KEY (source_tag) REFERENCES tags(id),
    FOREIGN KEY (target_tag) REFERENCES tags(id)
);

CREATE TABLE file_mappings (
    file_path TEXT PRIMARY KEY,
    file_hash TEXT NOT NULL,
    file_size_bytes INTEGER,
    last_modified TIMESTAMP,
    last_scanned TIMESTAMP,
    scan_duration_ms INTEGER,
    tag_count INTEGER DEFAULT 0,
    language TEXT,
    line_count INTEGER,
    complexity_score REAL
);

CREATE TABLE validation_history (
    id TEXT PRIMARY KEY,
    timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    validation_type TEXT NOT NULL,
    status TEXT NOT NULL,
    total_checks INTEGER,
    passed_checks INTEGER,
    failed_checks INTEGER,
    warnings INTEGER,
    duration_ms INTEGER
);

-- ì¸ë±ìŠ¤ ìƒì„±
CREATE INDEX idx_tags_category ON tags(category);
CREATE INDEX idx_tags_type ON tags(type);
CREATE INDEX idx_tags_status ON tags(status);
CREATE INDEX idx_tags_file_path ON tags(file_path);
CREATE INDEX idx_relationships_source ON tag_relationships(source_tag);
CREATE INDEX idx_relationships_target ON tag_relationships(target_tag);
CREATE INDEX idx_file_mappings_last_scanned ON file_mappings(last_scanned);
```

### 3. í•˜ì´ë¸Œë¦¬ë“œ ì ‘ê·¼ë²•ì˜ ì¥ì 

| ì €ì¥ì†Œ | ìš©ë„ | ì¥ì  | ì„±ëŠ¥ íŠ¹ì„± |
|--------|------|------|-----------|
| **JSON** | ë©”ì¸ ì¸ë±ìŠ¤, ë¹ ë¥¸ ì½ê¸° | ë‹¨ìˆœí•¨, ê°€ë…ì„±, ë°±ì—… ìš©ì´ | ì½ê¸°: O(1), ì“°ê¸°: O(n) |
| **SQLite** | ë³µì¡í•œ ì¿¼ë¦¬, ê´€ê³„í˜• ë°ì´í„° | ê°•ë ¥í•œ ì¿¼ë¦¬, íŠ¸ëœì­ì…˜, ë¬´ê²°ì„± | ì½ê¸°: O(log n), ì“°ê¸°: O(log n) |

## âš¡ ì„±ëŠ¥ ê³ ë ¤ì‚¬í•­

### 1. ëª©í‘œ ì„±ëŠ¥ ì§€í‘œ

| ë©”íŠ¸ë¦­ | ëª©í‘œ | í˜„ì¬ ê¸°ì¤€ |
|--------|------|-----------|
| **ìŠ¤ìº” ì†ë„** | 5ì´ˆ/1000íŒŒì¼ | 1000 LOC Python íŒŒì¼ ê¸°ì¤€ |
| **ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰** | <500MB | 10,000 TAG í”„ë¡œì íŠ¸ ê¸°ì¤€ |
| **ì¸ë±ìŠ¤ ì—…ë°ì´íŠ¸** | <100ms | ë‹¨ì¼ íŒŒì¼ ë³€ê²½ ê¸°ì¤€ |
| **ê²€ìƒ‰ ì‘ë‹µ** | <50ms | ë‹¨ìˆœ í…ìŠ¤íŠ¸ ê²€ìƒ‰ ê¸°ì¤€ |
| **ê²€ì¦ ì†ë„** | <10ì´ˆ | ì „ì²´ í”„ë¡œì íŠ¸ ê²€ì¦ ê¸°ì¤€ |

### 2. LibCST + Tree-sitter í•˜ì´ë¸Œë¦¬ë“œ íŒŒì‹± ì „ëµ

```python
class HybridParser:
    """LibCSTì™€ Tree-sitterë¥¼ ì¡°í•©í•œ í•˜ì´ë¸Œë¦¬ë“œ íŒŒì„œ"""

    def __init__(self):
        self.libcst_parser = LibCSTParser()  # ì •í™•í•œ Python AST
        self.tree_sitter_parser = TreeSitterParser()  # ë¹ ë¥¸ êµ¬ë¬¸ ë¶„ì„

    async def parse_file(self, file_path: str) -> ParseResult:
        """íŒŒì¼ í¬ê¸°ì™€ ë³µì¡ë„ì— ë”°ë¥¸ ì ì‘í˜• íŒŒì‹±"""
        file_info = await self.analyze_file(file_path)

        if file_info.size_bytes > 100_000 or file_info.complexity > 10:
            # í° íŒŒì¼: Tree-sitterë¡œ ë¹ ë¥¸ íŒŒì‹±
            return await self.tree_sitter_parser.parse(file_path)
        else:
            # ì‘ì€ íŒŒì¼: LibCSTë¡œ ì •í™•í•œ íŒŒì‹±
            return await self.libcst_parser.parse(file_path)

    async def extract_tags(self, parse_result: ParseResult) -> List[Tag]:
        """íŒŒì‹± ê²°ê³¼ì—ì„œ TAG ì¶”ì¶œ"""
        visitor = TagExtractionVisitor()

        if parse_result.parser_type == ParserType.LIBCST:
            # LibCST AST ìˆœíšŒ
            parse_result.tree.visit(visitor)
        else:
            # Tree-sitter ë…¸ë“œ ìˆœíšŒ
            visitor.visit_tree_sitter(parse_result.tree)

        return visitor.extracted_tags
```

### 3. orjsonì„ í™œìš©í•œ ê³ ì„±ëŠ¥ JSON ì²˜ë¦¬

```python
import orjson
from typing import Any, Dict

class HighPerformanceJSONStore:
    """orjson ê¸°ë°˜ ê³ ì„±ëŠ¥ JSON ì €ì¥ì†Œ"""

    def __init__(self, file_path: str):
        self.file_path = file_path
        self._cache: Optional[Dict[str, Any]] = None
        self._cache_timestamp: Optional[float] = None

    async def load(self) -> Dict[str, Any]:
        """ë¹„ë™ê¸° JSON ë¡œë“œ (ìºì‹± í¬í•¨)"""
        current_time = time.time()

        if (self._cache is None or
            current_time - self._cache_timestamp > 60):  # 1ë¶„ ìºì‹œ

            async with aiofiles.open(self.file_path, 'rb') as f:
                content = await f.read()
                self._cache = orjson.loads(content)
                self._cache_timestamp = current_time

        return self._cache

    async def save(self, data: Dict[str, Any]) -> None:
        """ë¹„ë™ê¸° JSON ì €ì¥ (ìµœì í™”ëœ ì§ë ¬í™”)"""
        serialized = orjson.dumps(
            data,
            option=orjson.OPT_INDENT_2 | orjson.OPT_SORT_KEYS
        )

        async with aiofiles.open(self.file_path, 'wb') as f:
            await f.write(serialized)

        # ìºì‹œ ì—…ë°ì´íŠ¸
        self._cache = data
        self._cache_timestamp = time.time()
```

### 4. Watchdogë¥¼ í™œìš©í•œ íŒŒì¼ ëª¨ë‹ˆí„°ë§

```python
import asyncio
from watchdog.observers import Observer
from watchdog.events import FileSystemEventHandler

class TagFileWatcher(FileSystemEventHandler):
    """ì‹¤ì‹œê°„ íŒŒì¼ ë³€ê²½ ëª¨ë‹ˆí„°ë§"""

    def __init__(self, change_handler):
        self.change_handler = change_handler
        self.change_buffer = {}
        self.buffer_timeout = 1.0  # 1ì´ˆ ë²„í¼ë§

    def on_modified(self, event):
        if not event.is_directory and event.src_path.endswith('.py'):
            # ë²„í¼ë§ìœ¼ë¡œ ì—°ì† ë³€ê²½ í†µí•©
            self.change_buffer[event.src_path] = time.time()
            asyncio.create_task(self._process_buffered_changes())

    async def _process_buffered_changes(self):
        """ë²„í¼ë§ëœ ë³€ê²½ì‚¬í•­ ì²˜ë¦¬"""
        await asyncio.sleep(self.buffer_timeout)

        current_time = time.time()
        changes_to_process = []

        for file_path, change_time in list(self.change_buffer.items()):
            if current_time - change_time >= self.buffer_timeout:
                changes_to_process.append(file_path)
                del self.change_buffer[file_path]

        if changes_to_process:
            await self.change_handler.process_file_changes(changes_to_process)
```

## ğŸ”’ ë³´ì•ˆ ë° ë¬´ê²°ì„±

### 1. ì…ë ¥ ê²€ì¦ ë° ì •ê·œí™”

```python
class TagInputValidator:
    """TAG ì…ë ¥ ê²€ì¦ ë° ì •ê·œí™”"""

    TAG_PATTERN = re.compile(
        r'^@(REQ|DESIGN|TASK|VISION|STRUCT|TECH|ADR|FEATURE|API|TEST|DATA|PERF|SEC|DEBT|TODO):'
        r'[A-Z0-9_-]+(?:-\d{3})?$'
    )

    def validate_tag_format(self, tag: str) -> ValidationResult:
        """TAG í˜•ì‹ ê²€ì¦"""
        if not isinstance(tag, str):
            return ValidationResult.error("TAG must be string")

        if len(tag) > 100:
            return ValidationResult.error("TAG too long (max 100 chars)")

        if not self.TAG_PATTERN.match(tag):
            return ValidationResult.error(f"Invalid TAG format: {tag}")

        return ValidationResult.success()

    def sanitize_description(self, description: str) -> str:
        """ì„¤ëª… ë¬¸ìì—´ ì •ê·œí™”"""
        # HTML íƒœê·¸ ì œê±°
        description = re.sub(r'<[^>]*>', '', description)

        # íŠ¹ìˆ˜ ë¬¸ì ì´ìŠ¤ì¼€ì´í•‘
        description = html.escape(description)

        # ê¸¸ì´ ì œí•œ
        if len(description) > 500:
            description = description[:497] + "..."

        return description.strip()
```

### 2. ì ‘ê·¼ ì œì–´ ë° ê°ì‚¬ ë¡œê¹…

```python
class TagAccessControl:
    """TAG ì‹œìŠ¤í…œ ì ‘ê·¼ ì œì–´"""

    def __init__(self):
        self.audit_logger = AuditLogger()

    def check_permission(self, user: str, action: str, resource: str) -> bool:
        """ê¶Œí•œ ê²€ì‚¬"""
        permissions = self.get_user_permissions(user)

        required_permission = f"{action}:{resource}"
        has_permission = required_permission in permissions

        # ê°ì‚¬ ë¡œê·¸ ê¸°ë¡
        self.audit_logger.log_access_attempt(
            user=user,
            action=action,
            resource=resource,
            granted=has_permission,
            timestamp=datetime.now()
        )

        return has_permission

    @contextmanager
    def audit_context(self, user: str, operation: str):
        """ê°ì‚¬ ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì €"""
        operation_id = str(uuid.uuid4())
        start_time = time.time()

        self.audit_logger.log_operation_start(
            operation_id=operation_id,
            user=user,
            operation=operation,
            timestamp=datetime.now()
        )

        try:
            yield operation_id
            duration = time.time() - start_time
            self.audit_logger.log_operation_success(
                operation_id=operation_id,
                duration_ms=int(duration * 1000)
            )
        except Exception as e:
            duration = time.time() - start_time
            self.audit_logger.log_operation_failure(
                operation_id=operation_id,
                error=str(e),
                duration_ms=int(duration * 1000)
            )
            raise
```

## ğŸ“ˆ ëª¨ë‹ˆí„°ë§ ë° ê´€ì°°ê°€ëŠ¥ì„±

### 1. êµ¬ì¡°í™”ëœ ë¡œê¹…

```python
import structlog

# ë¡œê±° ì„¤ì •
logger = structlog.get_logger()

class TagSystemLogger:
    """TAG ì‹œìŠ¤í…œ ì „ìš© ë¡œê±°"""

    def __init__(self):
        self.logger = logger.bind(component="tag-system")

    def log_scan_start(self, files: List[str], user: str):
        """ìŠ¤ìº” ì‹œì‘ ë¡œê·¸"""
        self.logger.info(
            "tag_scan_started",
            file_count=len(files),
            user=user,
            operation_id=str(uuid.uuid4())
        )

    def log_validation_result(self, result: ValidationResult):
        """ê²€ì¦ ê²°ê³¼ ë¡œê·¸"""
        self.logger.info(
            "tag_validation_completed",
            validation_id=result.validation_id,
            status=result.status.value,
            total_checks=result.total_checks,
            failed_checks=result.failed_checks,
            duration_ms=result.duration_ms
        )

    def log_performance_metric(self, operation: str, duration_ms: int,
                             memory_mb: float, items_processed: int):
        """ì„±ëŠ¥ ë©”íŠ¸ë¦­ ë¡œê·¸"""
        self.logger.info(
            "performance_metric",
            operation=operation,
            duration_ms=duration_ms,
            memory_mb=memory_mb,
            items_processed=items_processed,
            throughput=items_processed / (duration_ms / 1000) if duration_ms > 0 else 0
        )
```

### 2. ë©”íŠ¸ë¦­ ìˆ˜ì§‘

```python
from prometheus_client import Counter, Histogram, Gauge

class TagSystemMetrics:
    """Prometheus ë©”íŠ¸ë¦­ ìˆ˜ì§‘"""

    def __init__(self):
        # ì¹´ìš´í„°
        self.scans_total = Counter('tag_scans_total', 'Total TAG scans')
        self.validations_total = Counter('tag_validations_total', 'Total validations')
        self.errors_total = Counter('tag_errors_total', 'Total errors', ['error_type'])

        # íˆìŠ¤í† ê·¸ë¨ (ì‘ë‹µì‹œê°„)
        self.scan_duration = Histogram('tag_scan_duration_seconds', 'Scan duration')
        self.validation_duration = Histogram('tag_validation_duration_seconds', 'Validation duration')

        # ê²Œì´ì§€ (í˜„ì¬ ìƒíƒœ)
        self.active_tags = Gauge('tag_active_total', 'Active TAGs')
        self.index_size_bytes = Gauge('tag_index_size_bytes', 'Index size in bytes')
        self.memory_usage = Gauge('tag_system_memory_bytes', 'Memory usage')

    def record_scan(self, duration_seconds: float, tags_found: int):
        """ìŠ¤ìº” ë©”íŠ¸ë¦­ ê¸°ë¡"""
        self.scans_total.inc()
        self.scan_duration.observe(duration_seconds)
        self.active_tags.set(tags_found)

    def record_error(self, error_type: str):
        """ì—ëŸ¬ ë©”íŠ¸ë¦­ ê¸°ë¡"""
        self.errors_total.labels(error_type=error_type).inc()
```

## ğŸš€ Constitution ì¤€ìˆ˜ ë° ì•„í‚¤í…ì²˜ ê²°ì •

### 1. ëª¨ë“ˆ í†µí•© (4 â†’ 3)

Constitutionì˜ Simplicity ì›ì¹™ì— ë”°ë¼ ëª¨ë“ˆì„ í†µí•©:

```python
# ê¸°ì¡´ 4ê°œ ëª¨ë“ˆ
# - tag-scanner.py
# - tag-validator.py
# - tag-indexer.py
# - tag-repair.py

# í†µí•©ëœ 3ê°œ ëª¨ë“ˆ
class CoreEngine:
    """í•µì‹¬ ì—”ì§„: ìŠ¤ìº” + ê²€ì¦ í†µí•©"""
    scanner: TagScanner
    validator: TagValidator

class IntegrationModule:
    """í†µí•© ëª¨ë“ˆ: ì¸ë±ì‹± + Git ì—°ë™"""
    indexer: TagIndexer
    git_integration: GitIntegration

class MonitoringModule:
    """ëª¨ë‹ˆí„°ë§ ëª¨ë“ˆ: ëŒ€ì‹œë³´ë“œ + ë³µêµ¬"""
    monitor: TagMonitor
    auto_repair: TagRepair
```

### 2. TDD ì¤€ë¹„ ì„¤ê³„

ëª¨ë“  ì»´í¬ë„ŒíŠ¸ì— ëª…í™•í•œ ì¸í„°í˜ì´ìŠ¤ì™€ í…ŒìŠ¤íŠ¸ ê°€ëŠ¥í•œ êµ¬ì¡°:

```python
# ì¶”ìƒ ì¸í„°í˜ì´ìŠ¤
class TagScannerInterface(ABC):
    @abstractmethod
    async def scan_files(self, file_paths: List[str]) -> ScanResult: ...

    @abstractmethod
    async def suggest_tags(self, file_content: str) -> List[Tag]: ...

# êµ¬í˜„ í´ë˜ìŠ¤
class LibCSTTagScanner(TagScannerInterface):
    async def scan_files(self, file_paths: List[str]) -> ScanResult:
        # êµ¬í˜„
        pass

# í…ŒìŠ¤íŠ¸ ê°€ëŠ¥í•œ êµ¬ì¡°
class TestableTagScanner(TagScannerInterface):
    def __init__(self, mock_responses: Dict[str, ScanResult]):
        self.mock_responses = mock_responses

    async def scan_files(self, file_paths: List[str]) -> ScanResult:
        return self.mock_responses.get(file_paths[0], ScanResult.empty())
```

### 3. êµ¬ì¡°í™”ëœ ë¡œê¹… ë° ê´€ì°°ê°€ëŠ¥ì„±

ëª¨ë“  ì»´í¬ë„ŒíŠ¸ì— ì¼ê´€ëœ ë¡œê¹… ì ìš©:

```python
class ObservableComponent:
    """ê´€ì°° ê°€ëŠ¥í•œ ì»´í¬ë„ŒíŠ¸ ë² ì´ìŠ¤ í´ë˜ìŠ¤"""

    def __init__(self, component_name: str):
        self.logger = structlog.get_logger().bind(component=component_name)
        self.metrics = ComponentMetrics(component_name)

    @contextmanager
    def operation_context(self, operation: str, **kwargs):
        """ì‘ì—… ì»¨í…ìŠ¤íŠ¸ with ë¡œê¹… ë° ë©”íŠ¸ë¦­"""
        operation_id = str(uuid.uuid4())
        start_time = time.time()

        self.logger.info(f"{operation}_started", operation_id=operation_id, **kwargs)

        try:
            yield operation_id
            duration = time.time() - start_time
            self.metrics.record_success(operation, duration)
            self.logger.info(f"{operation}_completed",
                           operation_id=operation_id, duration_ms=int(duration * 1000))
        except Exception as e:
            duration = time.time() - start_time
            self.metrics.record_error(operation, duration)
            self.logger.error(f"{operation}_failed",
                            operation_id=operation_id, error=str(e))
            raise
```

### 4. ë²„ì „ ê´€ë¦¬ ì „ëµ

MAJOR.MINOR.BUILD í˜•ì‹ìœ¼ë¡œ ì—„ê²©í•œ ë²„ì „ ê´€ë¦¬:

```python
@dataclass
class SystemVersion:
    """ì‹œìŠ¤í…œ ë²„ì „ ê´€ë¦¬"""
    major: int  # Breaking changes
    minor: int  # New features
    build: int  # Bug fixes

    def __str__(self) -> str:
        return f"{self.major}.{self.minor}.{self.build}"

    def is_compatible_with(self, other: 'SystemVersion') -> bool:
        """í•˜ìœ„ í˜¸í™˜ì„± ê²€ì‚¬"""
        return self.major == other.major

# ë²„ì „ ê¸°ë°˜ ë§ˆì´ê·¸ë ˆì´ì…˜
class VersionMigrator:
    def migrate_index(self, from_version: SystemVersion,
                     to_version: SystemVersion) -> MigrationResult:
        """ì¸ë±ìŠ¤ ë²„ì „ ë§ˆì´ê·¸ë ˆì´ì…˜"""
        migrations = self.get_migrations_between(from_version, to_version)

        for migration in migrations:
            migration.apply()

        return MigrationResult.success()
```

---

> **@DATA:TAG-MODEL** íƒœê·¸ë¥¼ í†µí•´ ì´ ë°ì´í„° ëª¨ë¸ì´ SPEC-002 êµ¬í˜„ì˜ ê¸°ë°˜ì´ ë©ë‹ˆë‹¤.
>
> **ë‹¤ìŒ ë‹¨ê³„**: `/moai:4-tasks SPEC-002`ë¡œ TDD ê¸°ë°˜ êµ¬í˜„ ì‘ì—… ë¶„í•´