#!/usr/bin/env python3
"""
JIT Context Strategy Validation Script
======================================

MoAI-ADKì˜ Phaseë³„ JIT (Just-In-Time) Context Strategyë¥¼ ì‹¤ì œë¡œ ê²€ì¦í•©ë‹ˆë‹¤.
- Phaseë³„ ì»¨í…ìŠ¤íŠ¸ ë¡œë”© íš¨ìœ¨ ì¸¡ì •
- í† í° ì‚¬ìš©ëŸ‰ ì˜ˆì‚° vs ì‹¤ì œ ë¹„êµ
- /clear ëª…ë ¹ì–´ì˜ í† í° ì ˆì•½ íš¨ê³¼ ë¶„ì„
- Dynamic Context Loading ì„±ëŠ¥ í‰ê°€

ì‹¤í–‰: uv run .moai/scripts/jit-context-validation.py
"""

import os
import json
import time
from pathlib import Path
from dataclasses import dataclass, asdict, field
from typing import List, Dict, Tuple
import re

# ============================================================================
# ë°ì´í„° êµ¬ì¡° ì •ì˜
# ============================================================================

@dataclass
class ContextMetric:
    """ê°œë³„ ë¬¸ì„œ/íŒŒì¼ì˜ ì»¨í…ìŠ¤íŠ¸ ë©”íŠ¸ë¦­"""
    name: str
    path: str
    size_bytes: int
    lines: int
    category: str  # "spec", "skill", "agent", "foundation"
    phase: str = ""  # "SPEC", "RED", "GREEN", "REFACTOR"
    estimated_tokens: int = field(default=0, init=False)

    def __post_init__(self):
        # ë¼ì¸ ìˆ˜ë¡œë¶€í„° í† í° ì¶”ì • (í‰ê·  ì•½ 1 ì¤„ = 1.3 í† í°)
        self.estimated_tokens = int(self.lines * 1.3)


@dataclass
class PhaseContextAnalysis:
    """Phaseë³„ ì»¨í…ìŠ¤íŠ¸ ë¶„ì„ ê²°ê³¼"""
    phase_name: str  # "SPEC", "RED", "GREEN", "REFACTOR"
    budget_tokens: int
    actual_tokens: int
    documents: List[ContextMetric] = field(default_factory=list)
    efficiency: float = field(default=0, init=False)  # 0-100%
    compliance: bool = field(default=True, init=False)  # ì˜ˆì‚° ì¤€ìˆ˜ ì—¬ë¶€

    def __post_init__(self):
        self.calculate_efficiency()

    def calculate_efficiency(self):
        """íš¨ìœ¨ì„± ê³„ì‚° (ì‹¤ì œ / ì˜ˆì‚°)"""
        if self.budget_tokens == 0:
            return 0
        self.efficiency = min(100, (self.actual_tokens / self.budget_tokens) * 100)
        self.compliance = self.actual_tokens <= self.budget_tokens


@dataclass
class ClearEffectAnalysis:
    """'/clear' ëª…ë ¹ì–´ íš¨ê³¼ ë¶„ì„"""
    before_tokens: int
    after_tokens: int
    saved_tokens: int = 0
    savings_percentage: float = 0

    def __post_init__(self):
        self.saved_tokens = self.before_tokens - self.after_tokens
        if self.before_tokens > 0:
            self.savings_percentage = (self.saved_tokens / self.before_tokens) * 100


@dataclass
class ValidationReport:
    """ì „ì²´ ê²€ì¦ ë³´ê³ ì„œ"""
    timestamp: str
    project_name: str
    project_version: str

    # ê¸°ì¤€ì„  ë°ì´í„°
    total_specs: int
    total_skills: int
    total_agents: int
    total_context_size_mb: float

    # Phaseë³„ ë¶„ì„
    phase_analyses: List[PhaseContextAnalysis] = field(default_factory=list)

    # /clear íš¨ê³¼
    clear_effect: ClearEffectAnalysis = None

    # ìµœì í™” ì¶”ì²œ
    recommendations: List[str] = field(default_factory=list)

    # ì„±ëŠ¥ ì§€í‘œ
    avg_token_efficiency: float = 0
    bottleneck_phases: List[str] = field(default_factory=list)


# ============================================================================
# ë°ì´í„° ìˆ˜ì§‘ í•¨ìˆ˜
# ============================================================================

def get_file_metrics(file_path: Path) -> Tuple[int, int]:
    """íŒŒì¼ì˜ ë°”ì´íŠ¸ í¬ê¸°ì™€ ë¼ì¸ ìˆ˜ ë°˜í™˜"""
    try:
        size_bytes = file_path.stat().st_size
        with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
            lines = len(f.readlines())
        return size_bytes, lines
    except Exception:
        return 0, 0


def collect_spec_metrics(project_dir: Path) -> List[ContextMetric]:
    """SPEC ë¬¸ì„œ ë©”íŠ¸ë¦­ ìˆ˜ì§‘"""
    specs = []
    specs_dir = project_dir / ".moai" / "specs"

    if not specs_dir.exists():
        return specs

    for spec_dir in specs_dir.iterdir():
        if not spec_dir.is_dir():
            continue

        spec_file = spec_dir / "spec.md"
        if spec_file.exists():
            size_bytes, lines = get_file_metrics(spec_file)

            # SPEC ID ì¶”ì¶œ
            spec_id = spec_dir.name

            # Phase ì¶”ì • (SPEC íŒŒì¼ì˜ ìƒíƒœì—ì„œ)
            phase = "SPEC"  # ëª¨ë“  SPEC íŒŒì¼ì€ SPEC phaseë¡œ ë¶„ë¥˜

            spec_metric = ContextMetric(
                name=spec_id,
                path=str(spec_file.relative_to(project_dir)),
                size_bytes=size_bytes,
                lines=lines,
                category="spec",
                phase=phase
            )
            specs.append(spec_metric)

    return specs


def collect_skill_metrics(project_dir: Path) -> List[ContextMetric]:
    """Skill ë¬¸ì„œ ë©”íŠ¸ë¦­ ìˆ˜ì§‘ (í…œí”Œë¦¿ ì œì™¸)"""
    skills = []
    skills_dir = project_dir / ".claude" / "skills"

    if not skills_dir.exists():
        return skills

    for skill_dir in skills_dir.iterdir():
        if not skill_dir.is_dir() or "template" in str(skill_dir):
            continue

        skill_file = skill_dir / "SKILL.md"
        if skill_file.exists():
            size_bytes, lines = get_file_metrics(skill_file)
            skill_name = skill_dir.name

            # Skill ì¹´í…Œê³ ë¦¬ ì‹ë³„
            if "lang-" in skill_name:
                category = "skill-lang"
            elif "domain-" in skill_name:
                category = "skill-domain"
            elif "moai-" in skill_name:
                category = "skill-moai"
            else:
                category = "skill-other"

            skill_metric = ContextMetric(
                name=skill_name,
                path=str(skill_file.relative_to(project_dir)),
                size_bytes=size_bytes,
                lines=lines,
                category=category
            )
            skills.append(skill_metric)

    return skills


def collect_agent_metrics(project_dir: Path) -> List[ContextMetric]:
    """Agent ì„¤ì • ë©”íŠ¸ë¦­ ìˆ˜ì§‘"""
    agents = []
    agents_dir = project_dir / ".claude" / "agents" / "moai"

    if not agents_dir.exists():
        return agents

    for agent_file in agents_dir.glob("*.md"):
        size_bytes, lines = get_file_metrics(agent_file)
        agent_name = agent_file.stem

        agent_metric = ContextMetric(
            name=agent_name,
            path=str(agent_file.relative_to(project_dir)),
            size_bytes=size_bytes,
            lines=lines,
            category="agent"
        )
        agents.append(agent_metric)

    return agents


def collect_foundation_metrics(project_dir: Path) -> List[ContextMetric]:
    """ê¸°ì´ˆ ë¬¸ì„œ (CLAUDE.md, config ë“±) ë©”íŠ¸ë¦­ ìˆ˜ì§‘"""
    foundation = []

    # CLAUDE.md
    claude_md = project_dir / "CLAUDE.md"
    if claude_md.exists():
        size_bytes, lines = get_file_metrics(claude_md)
        foundation.append(ContextMetric(
            name="CLAUDE.md",
            path="CLAUDE.md",
            size_bytes=size_bytes,
            lines=lines,
            category="foundation"
        ))

    # CLAUDE.local.md
    claude_local = project_dir / "CLAUDE.local.md"
    if claude_local.exists():
        size_bytes, lines = get_file_metrics(claude_local)
        foundation.append(ContextMetric(
            name="CLAUDE.local.md",
            path="CLAUDE.local.md",
            size_bytes=size_bytes,
            lines=lines,
            category="foundation"
        ))

    return foundation


# ============================================================================
# Phaseë³„ ì»¨í…ìŠ¤íŠ¸ ë¶„ì„
# ============================================================================

def analyze_phase_context(
    phase: str,
    budget: int,
    all_metrics: List[ContextMetric]
) -> PhaseContextAnalysis:
    """
    Phaseë³„ ì»¨í…ìŠ¤íŠ¸ ë¡œë”© íš¨ìœ¨ ë¶„ì„

    Phaseë³„ í•„ìš” ë¬¸ì„œ:
    - SPEC: foundation + í•´ë‹¹ SPEC íŒŒì¼
    - RED: foundation + í•´ë‹¹ SPEC + test-related skills
    - GREEN: foundation + í•´ë‹¹ SPEC + language-specific skills
    - REFACTOR: foundation + í•´ë‹¹ SPEC + refactor skills
    """

    # Phaseë³„ í•„ìš” ë¬¸ì„œ ì¹´í…Œê³ ë¦¬
    phase_requirements = {
        "SPEC": ["foundation", "spec"],
        "RED": ["foundation", "spec", "skill-moai"],  # í…ŒìŠ¤íŠ¸ ìŠ¤í‚¬
        "GREEN": ["foundation", "spec", "skill-lang"],  # ì–¸ì–´ë³„ ìŠ¤í‚¬
        "REFACTOR": ["foundation", "spec", "skill-moai"]  # ë¦¬íŒ©í† ë§ ìŠ¤í‚¬
    }

    required_categories = phase_requirements.get(phase, [])

    # í•„ìš”í•œ ë¬¸ì„œë§Œ í•„í„°ë§
    phase_docs = [
        m for m in all_metrics
        if m.category in required_categories
    ]

    # í† í° í•©ê³„ ê³„ì‚°
    total_tokens = sum(m.estimated_tokens for m in phase_docs)

    analysis = PhaseContextAnalysis(
        phase_name=phase,
        budget_tokens=budget,
        actual_tokens=total_tokens,
        documents=phase_docs
    )
    return analysis


# ============================================================================
# /clear íš¨ê³¼ ë¶„ì„
# ============================================================================

def estimate_clear_effect(all_metrics: List[ContextMetric]) -> ClearEffectAnalysis:
    """
    /clear ëª…ë ¹ì–´ì˜ ì˜ˆìƒ í† í° ì ˆì•½ íš¨ê³¼ ë¶„ì„

    /clearëŠ” ì»¨í…ìŠ¤íŠ¸ë¥¼ ì™„ì „íˆ ì´ˆê¸°í™”í•˜ë¯€ë¡œ:
    - ì´ì „: ëª¨ë“  ëˆ„ì ëœ ì»¨í…ìŠ¤íŠ¸
    - ì´í›„: ìµœì†Œ ê¸°ì´ˆ ë¬¸ì„œë§Œ (ì•½ 5K í† í°)
    """

    # ì „ì²´ ì»¨í…ìŠ¤íŠ¸
    total_tokens = sum(m.estimated_tokens for m in all_metrics)

    # /clear í›„ ìœ ì§€ë˜ëŠ” ìµœì†Œ ì»¨í…ìŠ¤íŠ¸ (ì•½ 5K í† í°)
    remaining_tokens = 5000

    effect = ClearEffectAnalysis(
        before_tokens=total_tokens,
        after_tokens=remaining_tokens
    )

    return effect


# ============================================================================
# ìµœì í™” ê¶Œì¥ì‚¬í•­
# ============================================================================

def generate_recommendations(
    phase_analyses: List[PhaseContextAnalysis],
    all_metrics: List[ContextMetric]
) -> Tuple[List[str], List[str]]:
    """
    JIT ìµœì í™” ê¶Œì¥ì‚¬í•­ ìƒì„±

    Returns:
        (recommendations, bottleneck_phases)
    """
    recommendations = []
    bottlenecks = []

    # Phaseë³„ íš¨ìœ¨ì„± ë¶„ì„
    for analysis in phase_analyses:
        if analysis.efficiency > 80:
            recommendations.append(
                f"{analysis.phase_name}: íš¨ìœ¨ì  (ì‚¬ìš©ë¥  {analysis.efficiency:.1f}%)"
            )
        elif analysis.efficiency > 60:
            recommendations.append(
                f"{analysis.phase_name}: ê°œì„  ê¶Œì¥ (ì‚¬ìš©ë¥  {analysis.efficiency:.1f}%) "
                f"- ë¶ˆí•„ìš”í•œ Skill ì œì™¸ ê³ ë ¤"
            )
            bottlenecks.append(analysis.phase_name)
        else:
            recommendations.append(
                f"{analysis.phase_name}: ì¦‰ì‹œ ìµœì í™” í•„ìš” (ì‚¬ìš©ë¥  {analysis.efficiency:.1f}%)"
            )
            bottlenecks.append(analysis.phase_name)

    # ìƒìœ„ í¬ê¸° íŒŒì¼ ì‹ë³„
    large_files = sorted(
        all_metrics,
        key=lambda m: m.estimated_tokens,
        reverse=True
    )[:5]

    if large_files:
        recommendations.append("\nìµœìƒìœ„ 5ê°œ ëŒ€ìš©ëŸ‰ ë¬¸ì„œ:")
        for f in large_files:
            recommendations.append(
                f"  - {f.name}: {f.estimated_tokens} í† í° ({f.lines} ì¤„)"
            )

    # Skill ìµœì í™” ê¶Œì¥
    skills = [m for m in all_metrics if m.category.startswith("skill-")]
    if len(skills) > 100:
        recommendations.append(
            f"\nSkill ì •ë¦¬ ê¶Œì¥: {len(skills)}ê°œ Skill ì¤‘ ë¯¸ì‚¬ìš© Skill ê²€í† "
        )

    # /clear í™œìš© ê¶Œì¥
    recommendations.append(
        "\ní† í° íš¨ìœ¨ ìµœì í™”:\n"
        "  1. ê° Phase ì™„ë£Œ í›„ /clear ì‹¤í–‰ (45-50K í† í° ì ˆì•½)\n"
        "  2. Phaseë³„ í•„ìˆ˜ Skillë§Œ í™œì„±í™”\n"
        "  3. ëŒ€ê·œëª¨ SPECì€ sub-SPECìœ¼ë¡œ ë¶„í•  ê¶Œì¥"
    )

    return recommendations, bottlenecks


# ============================================================================
# ë³´ê³ ì„œ ìƒì„±
# ============================================================================

def generate_report(
    project_dir: Path,
    all_metrics: List[ContextMetric],
    phase_analyses: List[PhaseContextAnalysis],
    clear_effect: ClearEffectAnalysis
) -> ValidationReport:
    """ì¢…í•© ê²€ì¦ ë³´ê³ ì„œ ìƒì„±"""

    # ë©”íƒ€ë°ì´í„°
    config_path = project_dir / ".moai" / "config" / "config.json"
    project_name = "MoAI-ADK"
    project_version = "0.26.0"

    if config_path.exists():
        try:
            with open(config_path) as f:
                config = json.load(f)
                project_name = config.get("project", {}).get("name", project_name)
                project_version = config.get("moai", {}).get("version", project_version)
        except:
            pass

    # ì¹´í…Œê³ ë¦¬ë³„ ì§‘ê³„
    specs = [m for m in all_metrics if m.category == "spec"]
    skills = [m for m in all_metrics if m.category.startswith("skill-")]
    agents = [m for m in all_metrics if m.category == "agent"]

    # ì „ì²´ í† í°
    total_tokens = sum(m.estimated_tokens for m in all_metrics)
    total_mb = sum(m.size_bytes for m in all_metrics) / (1024 * 1024)

    # í‰ê·  íš¨ìœ¨
    avg_efficiency = sum(a.efficiency for a in phase_analyses) / len(phase_analyses) if phase_analyses else 0

    # ë³‘ëª© Phase
    bottlenecks = [a.phase_name for a in phase_analyses if not a.compliance]

    # ê¶Œì¥ì‚¬í•­
    recommendations, bottleneck_phases = generate_recommendations(phase_analyses, all_metrics)

    report = ValidationReport(
        timestamp=time.strftime("%Y-%m-%d %H:%M:%S"),
        project_name=project_name,
        project_version=project_version,
        total_specs=len(specs),
        total_skills=len(skills),
        total_agents=len(agents),
        total_context_size_mb=total_mb,
        phase_analyses=phase_analyses,
        clear_effect=clear_effect,
        recommendations=recommendations,
        avg_token_efficiency=avg_efficiency,
        bottleneck_phases=bottleneck_phases
    )

    return report


# ============================================================================
# ë©”ì¸ ì‹¤í–‰
# ============================================================================

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""

    print("=" * 80)
    print("JIT Context Strategy Validation - ì‹œì‘")
    print("=" * 80)

    project_dir = Path(__file__).parent.parent.parent

    print(f"\nğŸ“Š í”„ë¡œì íŠ¸: {project_dir.name}")
    print(f"ğŸ“‚ ì‘ì—… ë””ë ‰í† ë¦¬: {project_dir}\n")

    # Step 1: ë©”íŠ¸ë¦­ ìˆ˜ì§‘
    print("Step 1: ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ì¤‘...")
    specs = collect_spec_metrics(project_dir)
    skills = collect_skill_metrics(project_dir)
    agents = collect_agent_metrics(project_dir)
    foundation = collect_foundation_metrics(project_dir)

    all_metrics = specs + skills + agents + foundation

    print(f"  âœ“ SPEC: {len(specs)}ê°œ")
    print(f"  âœ“ Skills: {len(skills)}ê°œ")
    print(f"  âœ“ Agents: {len(agents)}ê°œ")
    print(f"  âœ“ Foundation: {len(foundation)}ê°œ")
    print(f"  âœ“ ì´ ë¬¸ì„œ: {len(all_metrics)}ê°œ\n")

    # Step 2: Phaseë³„ ë¶„ì„
    print("Step 2: Phaseë³„ ì»¨í…ìŠ¤íŠ¸ ë¶„ì„ ì¤‘...")
    phase_budgets = {
        "SPEC": 50000,
        "RED": 60000,
        "GREEN": 60000,
        "REFACTOR": 50000
    }

    phase_analyses = []
    for phase, budget in phase_budgets.items():
        analysis = analyze_phase_context(phase, budget, all_metrics)
        phase_analyses.append(analysis)

        status = "âœ“ ì¤€ìˆ˜" if analysis.compliance else "âœ— ì´ˆê³¼"
        print(f"  {phase}: {analysis.actual_tokens:,} / {budget:,} í† í° ({analysis.efficiency:.1f}%) {status}")

    print()

    # Step 3: /clear íš¨ê³¼ ë¶„ì„
    print("Step 3: /clear íš¨ê³¼ ë¶„ì„ ì¤‘...")
    clear_effect = estimate_clear_effect(all_metrics)

    print(f"  ì ˆì•½ ì „: {clear_effect.before_tokens:,} í† í°")
    print(f"  ì ˆì•½ í›„: {clear_effect.after_tokens:,} í† í°")
    print(f"  ì ˆì•½ëŸ‰: {clear_effect.saved_tokens:,} í† í° ({clear_effect.savings_percentage:.1f}%)\n")

    # Step 4: ë³´ê³ ì„œ ìƒì„±
    print("Step 4: ì¢…í•© ë³´ê³ ì„œ ìƒì„± ì¤‘...")
    report = generate_report(
        project_dir,
        all_metrics,
        phase_analyses,
        clear_effect
    )

    # ë³´ê³ ì„œ ì €ì¥
    report_dir = project_dir / ".moai" / "reports"
    report_dir.mkdir(parents=True, exist_ok=True)

    report_file = report_dir / f"jit-context-validation-{time.strftime('%Y%m%d-%H%M%S')}.json"

    with open(report_file, 'w', encoding='utf-8') as f:
        json.dump(asdict(report), f, indent=2, ensure_ascii=False)

    print(f"  âœ“ ë³´ê³ ì„œ ì €ì¥: {report_file}\n")

    # Step 5: ê¶Œì¥ì‚¬í•­ ì¶œë ¥
    print("=" * 80)
    print("ìµœì í™” ê¶Œì¥ì‚¬í•­")
    print("=" * 80)
    for rec in report.recommendations:
        print(rec)

    print("\n" + "=" * 80)
    print("ê²€ì¦ ì™„ë£Œ")
    print("=" * 80)

    return report


if __name__ == "__main__":
    report = main()
