#!/usr/bin/env python3
"""
MoAI-ADK TAG Auto-Correction System
GPT-5 Pro ê¶Œì¥ì‚¬í•­ ê¸°ë°˜ ìë™ TAG ìˆ˜ì • ì‹œìŠ¤í…œ
"""

import json
import re
import os
import sys
import subprocess
from pathlib import Path
from typing import Dict, List, Optional, Tuple
from dataclasses import dataclass
from datetime import datetime
from tag_dedup_detector import TagDedupDetector, TagInfo, DuplicateGroup

@dataclass
class CorrectionAction:
    """ìˆ˜ì • ì•¡ì…˜ ì •ë³´"""
    action_type: str  # renumber, remove, update_reference
    file_path: str
    line_number: int
    old_tag: str
    new_tag: Optional[str]
    confidence: float
    impact: str  # low, medium, high, critical
    description: str

@dataclass 
class CorrectionResult:
    """ìˆ˜ì • ê²°ê³¼ ì •ë³´"""
    action: CorrectionAction
    success: bool
    error_message: Optional[str] = None
    backup_path: Optional[str] = None

class TagAutoCorrector:
    """TAG ìë™ ìˆ˜ì •ê¸°"""
    
    def __init__(self, config_path: str = None, dry_run: bool = True):
        self.project_root = Path.cwd()
        self.config = self._load_config(config_path)
        self.dry_run = dry_run
        self.detector = TagDedupDetector(config_path)
        self.corrections: List[CorrectionAction] = []
        self.results: List[CorrectionResult] = []
        
    def _load_config(self, config_path: str = None) -> Dict:
        """ì„¤ì • íŒŒì¼ ë¡œë“œ"""
        if config_path is None:
            config_path = self.project_root / ".moai" / "tag-policy-updated.json"
        
        try:
            with open(config_path, 'r', encoding='utf-8') as f:
                return json.load(f)
        except FileNotFoundError:
            print(f"âŒ ì„¤ì • íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {config_path}")
            sys.exit(1)
    
    def _create_backup(self) -> str:
        """ë°±ì—… ìƒì„±"""
        timestamp = datetime.now().strftime("%Y%m%d-%H%M%S")
        backup_tag = f"TAG-DEDUP-BACKUP-{timestamp}"
        
        try:
            # Git íƒœê·¸ ìƒì„±
            subprocess.run(
                ["git", "tag", backup_tag],
                check=True,
                capture_output=True,
                text=True
            )
            print(f"âœ… ë°±ì—… ìƒì„±: {backup_tag}")
            return backup_tag
        except subprocess.CalledProcessError as e:
            print(f"âš ï¸  Git íƒœê·¸ ìƒì„± ì‹¤íŒ¨: {e}")
            return None
    
    def _validate_correction(self, action: CorrectionAction) -> Tuple[bool, str]:
        """ìˆ˜ì • ì•¡ì…˜ ê²€ì¦"""
        # íŒŒì¼ ì¡´ì¬ í™•ì¸
        if not os.path.exists(action.file_path):
            return False, f"íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŒ: {action.file_path}"
        
        # ì‹ ë¢°ë„ í™•ì¸
        if action.confidence < self.config.get("auto_correction", {}).get("confidence_threshold", 0.8):
            return False, f"ì‹ ë¢°ë„ ë¶€ì¡±: {action.confidence}"
        
        # ì˜í–¥ë„ í™•ì¸
        if action.impact == "critical" and self.dry_run:
            return False, "ì¹˜ëª…ì  ì˜í–¥ë„ - dry-run ëª¨ë“œì—ì„œ ê±´ë„ˆëœ€"
        
        return True, "ê²€ì¦ í†µê³¼"
    
    def _apply_line_correction(self, action: CorrectionAction) -> bool:
        """ë¼ì¸ ë‹¨ìœ„ ìˆ˜ì • ì ìš©"""
        try:
            file_path = Path(action.file_path)
            
            # íŒŒì¼ ì½ê¸°
            with open(file_path, 'r', encoding='utf-8') as f:
                lines = f.readlines()
            
            # í•´ë‹¹ ë¼ì¸ ìˆ˜ì •
            if action.line_number <= len(lines):
                old_line = lines[action.line_number - 1]
                
                if action.new_tag:
                    # TAG êµì²´
                    new_line = old_line.replace(action.old_tag, action.new_tag)
                else:
                    # TAG ì œê±°
                    new_line = re.sub(r'\s*' + re.escape(action.old_tag), '', old_line)
                
                lines[action.line_number - 1] = new_line
                
                # íŒŒì¼ ì“°ê¸°
                with open(file_path, 'w', encoding='utf-8') as f:
                    f.writelines(lines)
                
                print(f"âœ… ìˆ˜ì • ì™„ë£Œ: {action.file_path}:{action.line_number}")
                return True
            else:
                print(f"âŒ ë¼ì¸ ë²ˆí˜¸ ì´ˆê³¼: {action.file_path}:{action.line_number}")
                return False
                
        except Exception as e:
            print(f"âŒ ìˆ˜ì • ì‹¤íŒ¨: {action.file_path}:{action.line_number} - {e}")
            return False
    
    def generate_corrections(self, duplicate_groups: List[DuplicateGroup]) -> None:
        """ìˆ˜ì • ê³„íš ìƒì„±"""
        print("ğŸ”§ ìˆ˜ì • ê³„íš ìƒì„± ì¤‘...")
        
        for group in duplicate_groups:
            primary = group.primary_candidate
            
            for duplicate in group.duplicates:
                # Topline ì¤‘ë³µ ì²˜ë¦¬
                if duplicate.is_topline:
                    # ìƒˆë¡œìš´ TAG ìƒì„±
                    new_tag = self._generate_new_tag(duplicate.tag, duplicate.domain, duplicate.tag_type)
                    
                    action = CorrectionAction(
                        action_type="renumber",
                        file_path=duplicate.file_path,
                        line_number=duplicate.line_number,
                        old_tag=duplicate.tag,
                        new_tag=new_tag,
                        confidence=0.9,
                        impact="high",
                        description=f"Topline ì¤‘ë³µ ì²˜ë¦¬: {duplicate.tag} â†’ {new_tag}"
                    )
                    self.corrections.append(action)
                    
                    # ê´€ë ¨ ì°¸ì¡° ì—…ë°ì´íŠ¸ í•„ìš” í™•ì¸
                    self._plan_reference_updates(duplicate.tag, new_tag)
                
                # ì°¸ì¡° ì¤‘ë³µ ì²˜ë¦¬ (ë†’ì€ ê¶Œí•œ íŒŒì¼ì˜ ì°¸ì¡°ë§Œ)
                elif duplicate.authority_score >= 60:
                    action = CorrectionAction(
                        action_type="update_reference",
                        file_path=duplicate.file_path,
                        line_number=duplicate.line_number,
                        old_tag=duplicate.tag,
                        new_tag=primary.tag,
                        confidence=0.8,
                        impact="medium",
                        description=f"ì°¸ì¡° ì—…ë°ì´íŠ¸: {duplicate.tag} â†’ {primary.tag}"
                    )
                    self.corrections.append(action)
        
        print(f"âœ… {len(self.corrections)}ê°œì˜ ìˆ˜ì • ì•¡ì…˜ ìƒì„± ì™„ë£Œ")
    
    def _plan_reference_updates(self, old_tag: str, new_tag: str) -> None:
        """ê´€ë ¨ ì°¸ì¡° ì—…ë°ì´íŠ¸ ê³„íš"""
        # ì „ì²´ íŒŒì¼ì—ì„œ old_tag ì°¸ì¡° ê²€ìƒ‰
        for tag_info in self.detector.all_tags:
            if tag_info.tag == old_tag and not tag_info.is_topline:
                action = CorrectionAction(
                    action_type="update_reference",
                    file_path=tag_info.file_path,
                    line_number=tag_info.line_number,
                    old_tag=old_tag,
                    new_tag=new_tag,
                    confidence=0.9,
                    impact="medium",
                    description=f"ê´€ë ¨ ì°¸ì¡° ì—…ë°ì´íŠ¸: {old_tag} â†’ {new_tag}"
                )
                self.corrections.append(action)
    
    def _generate_new_tag(self, old_tag: str, domain: str, tag_type: str) -> str:
        """ìƒˆë¡œìš´ TAG ìƒì„±"""
        # ê¸°ì¡´ ìµœëŒ€ ID ì°¾ê¸°
        max_id = 0
        tag_pattern = re.compile(rf'@{tag_type}:{domain}-(\d+)')
        
        for tag_info in self.detector.all_tags:
            match = tag_pattern.search(tag_info.tag)
            if match:
                id_num = int(match.group(1))
                max_id = max(max_id, id_num)
        
        # ìƒˆë¡œìš´ ID ìƒì„±
        new_id = max_id + 1
        new_tag = f"@{tag_type}:{domain}-{new_id:03d}"
        
        return new_tag
    
    def apply_corrections(self) -> List[CorrectionResult]:
        """ìˆ˜ì • ì ìš©"""
        print("ğŸ”§ ìˆ˜ì • ì ìš© ì¤‘...")
        
        if self.dry_run:
            print("ğŸ” DRY RUN ëª¨ë“œ - ì‹¤ì œ ìˆ˜ì •í•˜ì§€ ì•ŠìŒ")
        
        # ë°±ì—… ìƒì„±
        backup_tag = self._create_backup() if not self.dry_run else None
        
        # ìˆ˜ì • ì ìš©
        for action in self.corrections:
            # ê²€ì¦
            is_valid, message = self._validate_correction(action)
            if not is_valid:
                print(f"âš ï¸  ê²€ì¦ ì‹¤íŒ¨: {message}")
                continue
            
            # ì ìš©
            if self.dry_run:
                print(f"[DRY RUN] {action.description}")
                result = CorrectionResult(
                    action=action,
                    success=True,
                    backup_path=backup_tag
                )
            else:
                success = self._apply_line_correction(action)
                result = CorrectionResult(
                    action=action,
                    success=success,
                    backup_path=backup_tag
                )
            
            self.results.append(result)
        
        # ê²°ê³¼ ìš”ì•½
        self._print_results_summary()
        
        return self.results
    
    def _print_results_summary(self) -> None:
        """ê²°ê³¼ ìš”ì•½ ì¶œë ¥"""
        total = len(self.results)
        successful = sum(1 for r in self.results if r.success)
        failed = total - successful
        
        print(f"\nğŸ“Š ìˆ˜ì • ê²°ê³¼ ìš”ì•½:")
        print(f"ì´ ìˆ˜ì •: {total}")
        print(f"ì„±ê³µ: {successful}")
        print(f"ì‹¤íŒ¨: {failed}")
        
        if failed > 0:
            print(f"\nâŒ ì‹¤íŒ¨í•œ ìˆ˜ì •:")
            for result in self.results:
                if not result.success:
                    print(f"  â€¢ {result.action.file_path}:{result.action.line_number} - {result.error_message}")
        
        # ì˜í–¥ë„ë³„ ìš”ì•½
        impact_summary = {}
        for result in self.results:
            impact = result.action.impact
            if impact not in impact_summary:
                impact_summary[impact] = 0
            impact_summary[impact] += 1
        
        print(f"\nğŸ“ˆ ì˜í–¥ë„ë³„ ìš”ì•½:")
        for impact, count in sorted(impact_summary.items()):
            emoji = {"low": "ğŸŸ¢", "medium": "ğŸŸ¡", "high": "ğŸŸ ", "critical": "ğŸ”´"}.get(impact, "âšª")
            print(f"  {emoji} {impact}: {count}")
    
    def save_correction_report(self, output_path: str = None) -> None:
        """ìˆ˜ì • ë¦¬í¬íŠ¸ ì €ì¥"""
        if output_path is None:
            timestamp = datetime.now().strftime("%Y%m%d-%H%M%S")
            output_path = self.project_root / ".moai" / "reports" / f"tag-correction-{timestamp}.json"
        
        os.makedirs(output_path.parent, exist_ok=True)
        
        report = {
            "timestamp": datetime.now().isoformat(),
            "dry_run": self.dry_run,
            "total_corrections": len(self.corrections),
            "results": [
                {
                    "action": {
                        "type": result.action.action_type,
                        "file_path": result.action.file_path,
                        "line_number": result.action.line_number,
                        "old_tag": result.action.old_tag,
                        "new_tag": result.action.new_tag,
                        "confidence": result.action.confidence,
                        "impact": result.action.impact,
                        "description": result.action.description
                    },
                    "success": result.success,
                    "error_message": result.error_message,
                    "backup_path": result.backup_path
                }
                for result in self.results
            ],
            "summary": {
                "total": len(self.results),
                "successful": sum(1 for r in self.results if r.success),
                "failed": sum(1 for r in self.results if not r.success)
            }
        }
        
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
        
        print(f"ğŸ“Š ìˆ˜ì • ë¦¬í¬íŠ¸ ì €ì¥: {output_path}")
    
    def run_correction(self, analysis_file: str = None) -> List[CorrectionResult]:
        """ì „ì²´ ìˆ˜ì • í”„ë¡œì„¸ìŠ¤ ì‹¤í–‰"""
        print("ğŸš€ TAG ìë™ ìˆ˜ì • ì‹œì‘...")
        
        # 1. ì¤‘ë³µ íƒì§€
        analysis = self.detector.run_full_scan()
        
        # 2. ìˆ˜ì • ê³„íš ìƒì„±
        self.generate_corrections(self.detector.duplicate_groups)
        
        # 3. ìˆ˜ì • ì ìš©
        results = self.apply_corrections()
        
        # 4. ë¦¬í¬íŠ¸ ì €ì¥
        self.save_correction_report()
        
        return results

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    import argparse
    
    parser = argparse.ArgumentParser(description="MoAI-ADK TAG ìë™ ìˆ˜ì •ê¸°")
    parser.add_argument("--config", help="ì„¤ì • íŒŒì¼ ê²½ë¡œ")
    parser.add_argument("--analysis", help="ë¶„ì„ íŒŒì¼ ê²½ë¡œ")
    parser.add_argument("--output", help="ì¶œë ¥ íŒŒì¼ ê²½ë¡œ")
    parser.add_argument("--apply", action="store_true", help="ì‹¤ì œ ìˆ˜ì • ì ìš© (dry-run ì•„ë‹˜)")
    
    args = parser.parse_args()
    
    try:
        corrector = TagAutoCorrector(
            config_path=args.config,
            dry_run=not args.apply
        )
        
        results = corrector.run_correction(args.analysis)
        
        # ì‹¤íŒ¨í•œ ìˆ˜ì •ì´ ìˆìœ¼ë©´ ë¹„ì œë¡œ ë¦¬í„´
        failed_count = sum(1 for r in results if not r.success)
        if failed_count > 0:
            print(f"\nâš ï¸  {failed_count}ê°œì˜ ìˆ˜ì • ì‹¤íŒ¨")
            return 1
        else:
            print(f"\nâœ… ëª¨ë“  ìˆ˜ì • ì„±ê³µ")
            return 0
            
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return 1

if __name__ == "__main__":
    sys.exit(main())
