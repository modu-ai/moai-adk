#!/usr/bin/env python3
"""
MoAI-ADK TAG De-duplication Manager (Unified)

Merged from:
  - tag_dedup_detector.py: TAG ì¤‘ë³µ íƒì§€
  - tag_auto_corrector.py: TAG ìë™ ìˆ˜ì •

í†µí•©ëœ ë‹¨ì¼ ëª…ë ¹ì–´ë¡œ TAG ì‹œìŠ¤í…œì˜ ì¤‘ë³µì„ ê°ì§€í•˜ê³  ìˆ˜ì •í•©ë‹ˆë‹¤.
"""

import json
import re
import os
import sys
import subprocess
from pathlib import Path
from typing import Dict, List, Tuple, Set, Optional
from collections import defaultdict, Counter
from dataclasses import dataclass, field
from datetime import datetime


# ============================================================================
# Data Structures (ê³µìœ  ë°ì´í„° êµ¬ì¡°)
# ============================================================================

@dataclass
class TagInfo:
    """TAG ì •ë³´ êµ¬ì¡°ì²´"""
    tag: str
    file_path: str
    line_number: int
    line_content: str
    is_topline: bool
    tag_type: str  # SPEC, TEST, CODE, DOC
    domain: str
    id_number: str
    authority_score: int


@dataclass
class DuplicateGroup:
    """ì¤‘ë³µ ê·¸ë£¹ ì •ë³´"""
    tag_pattern: str
    occurrences: List[TagInfo] = field(default_factory=list)
    primary_candidate: Optional[TagInfo] = None
    duplicates: List[TagInfo] = field(default_factory=list)


@dataclass
class CorrectionAction:
    """ìˆ˜ì • ì•¡ì…˜ ì •ë³´"""
    action_type: str  # renumber, remove, update_reference
    file_path: str
    line_number: int
    old_tag: str
    new_tag: Optional[str]
    confidence: float
    impact: str  # low, medium, high, critical
    description: str


@dataclass
class CorrectionResult:
    """ìˆ˜ì • ê²°ê³¼ ì •ë³´"""
    action: CorrectionAction
    success: bool
    error_message: Optional[str] = None
    backup_path: Optional[str] = None


# ============================================================================
# TAG íƒì§€ê¸° (Detection Engine)
# ============================================================================

class TagDetectionEngine:
    """TAG ì¤‘ë³µ íƒì§€ ì—”ì§„"""

    def __init__(self, config_path: str = None):
        self.project_root = Path.cwd()
        self.config = self._load_config(config_path)
        self.tag_pattern = re.compile(r'@([A-Z]+):([A-Z_]+)-([0-9]{3,})')
        self.all_tags: List[TagInfo] = []
        self.duplicate_groups: List[DuplicateGroup] = []

    def _load_config(self, config_path: str = None) -> Dict:
        """ì„¤ì • íŒŒì¼ ë¡œë“œ"""
        if config_path is None:
            config_path = self.project_root / ".moai" / "tag-policy.json"

        try:
            with open(config_path, 'r', encoding='utf-8') as f:
                return json.load(f)
        except FileNotFoundError:
            return self._default_config()

    def _default_config(self) -> Dict:
        """ê¸°ë³¸ ì„¤ì •"""
        return {
            "scan_paths": ["src/", ".moai/", ".claude/"],
            "exclude_paths": ["node_modules/", ".git/", "__pycache__/"],
            "tag_types": ["SPEC", "TEST", "CODE", "DOC"],
            "min_duplicates": 2,
        }

    def _calculate_authority_score(self, file_path: str, line_number: int) -> int:
        """ê¶Œí•œ ì ìˆ˜ ê³„ì‚°"""
        score = 50

        if ".moai/specs/" in str(file_path):
            score += 30
        elif ".claude/" in str(file_path):
            score += 20
        elif "src/" in str(file_path):
            score += 10

        if line_number < 10:
            score += 10

        return min(score, 100)

    def _is_topline_tag(self, line_content: str, line_number: int) -> bool:
        """í—¤ë”ë¼ì¸ TAG ì—¬ë¶€"""
        return bool(re.match(r'^#+ ', line_content))

    def _extract_tags_from_file(self, file_path: str) -> List[TagInfo]:
        """íŒŒì¼ì—ì„œ TAG ì¶”ì¶œ"""
        tags = []
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                for line_num, line_content in enumerate(f, 1):
                    for match in self.tag_pattern.finditer(line_content):
                        tag_type = match.group(1)
                        domain = match.group(2)
                        id_number = match.group(3)
                        full_tag = match.group(0)

                        tag_info = TagInfo(
                            tag=full_tag,
                            file_path=str(file_path),
                            line_number=line_num,
                            line_content=line_content.strip(),
                            is_topline=self._is_topline_tag(line_content, line_num),
                            tag_type=tag_type,
                            domain=domain,
                            id_number=id_number,
                            authority_score=self._calculate_authority_score(
                                str(file_path), line_num
                            ),
                        )
                        tags.append(tag_info)
        except (UnicodeDecodeError, IOError):
            pass

        return tags

    def scan_all_files(self) -> None:
        """ëª¨ë“  íŒŒì¼ ìŠ¤ìº”"""
        exclude_dirs = {
            d.lower() for d in self.config.get("exclude_paths", [])
        }

        for root, dirs, files in os.walk(self.project_root):
            dirs[:] = [
                d for d in dirs if d.lower() not in exclude_dirs
            ]

            for file in files:
                if file.endswith((".py", ".md", ".sh", ".js", ".ts")):
                    file_path = Path(root) / file
                    tags = self._extract_tags_from_file(file_path)
                    self.all_tags.extend(tags)

    def find_duplicates(self) -> None:
        """ì¤‘ë³µ íƒì§€"""
        tag_occurrences: Dict[str, List[TagInfo]] = defaultdict(list)

        for tag in self.all_tags:
            pattern = f"{tag.tag_type}:{tag.domain}-*"
            tag_occurrences[pattern].append(tag)

        for pattern, occurrences in tag_occurrences.items():
            if len(occurrences) >= self.config.get("min_duplicates", 2):
                dup_group = DuplicateGroup(
                    tag_pattern=pattern,
                    occurrences=occurrences,
                )

                sorted_tags = sorted(
                    occurrences,
                    key=lambda t: (-t.authority_score, t.line_number),
                )
                dup_group.primary_candidate = sorted_tags[0]
                dup_group.duplicates = sorted_tags[1:]

                self.duplicate_groups.append(dup_group)

    def analyze_duplicates(self) -> Dict:
        """ì¤‘ë³µ ë¶„ì„"""
        analysis = {
            "total_tags": len(self.all_tags),
            "duplicate_groups": len(self.duplicate_groups),
            "total_duplicates": sum(
                len(group.duplicates) for group in self.duplicate_groups
            ),
            "details": [],
        }

        for group in self.duplicate_groups:
            group_detail = {
                "pattern": group.tag_pattern,
                "count": len(group.occurrences),
                "primary": {
                    "tag": group.primary_candidate.tag,
                    "file": group.primary_candidate.file_path,
                    "line": group.primary_candidate.line_number,
                },
                "duplicates": [
                    {
                        "tag": dup.tag,
                        "file": dup.file_path,
                        "line": dup.line_number,
                    }
                    for dup in group.duplicates
                ],
            }
            analysis["details"].append(group_detail)

        return analysis


# ============================================================================
# TAG ìˆ˜ì •ê¸° (Correction Engine)
# ============================================================================

class TagCorrectionEngine:
    """TAG ìë™ ìˆ˜ì • ì—”ì§„"""

    def __init__(self, config_path: str = None, dry_run: bool = True):
        self.project_root = Path.cwd()
        self.config = self._load_config(config_path)
        self.dry_run = dry_run
        self.detector = TagDetectionEngine(config_path)
        self.corrections: List[CorrectionAction] = []
        self.results: List[CorrectionResult] = []

    def _load_config(self, config_path: str = None) -> Dict:
        """ì„¤ì • íŒŒì¼ ë¡œë“œ"""
        if config_path is None:
            config_path = self.project_root / ".moai" / "tag-policy.json"

        try:
            with open(config_path, 'r', encoding='utf-8') as f:
                return json.load(f)
        except FileNotFoundError:
            return {}

    def _create_backup(self) -> str:
        """ë°±ì—… ìƒì„±"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        backup_dir = self.project_root / ".moai" / "backups" / "tag_corrections"
        backup_dir.mkdir(parents=True, exist_ok=True)

        backup_path = backup_dir / f"backup_{timestamp}.tar.gz"
        os.system(f"tar -czf {backup_path} .moai/specs/ src/ .claude/")

        return str(backup_path)

    def _validate_correction(
        self, action: CorrectionAction
    ) -> Tuple[bool, str]:
        """ìˆ˜ì • ê²€ì¦"""
        if not action.new_tag:
            return True, "ì œê±° ì‘ì—…"

        tag_pattern = re.compile(r'^@[A-Z]+:[A-Z_]+-\d{3,}$')
        if not tag_pattern.match(action.new_tag):
            return False, f"ìœ íš¨í•˜ì§€ ì•Šì€ TAG í˜•ì‹: {action.new_tag}"

        return True, "ê²€ì¦ ì™„ë£Œ"

    def _apply_line_correction(self, action: CorrectionAction) -> bool:
        """ë¼ì¸ ìˆ˜ì • ì ìš©"""
        try:
            file_path = Path(action.file_path)

            with open(file_path, 'r', encoding='utf-8') as f:
                lines = f.readlines()

            if action.line_number > len(lines):
                return False

            target_line = lines[action.line_number - 1]

            if action.new_tag:
                new_line = target_line.replace(
                    action.old_tag, action.new_tag
                )
            else:
                new_line = target_line.replace(action.old_tag, "")

            if not self.dry_run:
                lines[action.line_number - 1] = new_line
                with open(file_path, 'w', encoding='utf-8') as f:
                    f.writelines(lines)

            return True
        except Exception as e:
            return False

    def generate_corrections(
        self, duplicate_groups: List[DuplicateGroup]
    ) -> None:
        """ìˆ˜ì • ê³„íš ìƒì„±"""
        for group in duplicate_groups:
            for dup in group.duplicates:
                new_tag = self._generate_new_tag(
                    dup.tag, dup.domain, dup.tag_type
                )

                action = CorrectionAction(
                    action_type="renumber",
                    file_path=dup.file_path,
                    line_number=dup.line_number,
                    old_tag=dup.tag,
                    new_tag=new_tag,
                    confidence=0.95,
                    impact="high",
                    description=f"ì¤‘ë³µ TAG ì œê±°: {dup.tag} â†’ {new_tag}",
                )

                self.corrections.append(action)

    def _generate_new_tag(
        self, old_tag: str, domain: str, tag_type: str
    ) -> str:
        """ìƒˆ TAG ìƒì„±"""
        next_num = 1

        for tag in self.detector.all_tags:
            if tag.domain == domain and tag.tag_type == tag_type:
                try:
                    num = int(tag.id_number)
                    next_num = max(next_num, num + 1)
                except ValueError:
                    pass

        return f"@{tag_type}:{domain}-{next_num:03d}"

    def apply_corrections(self) -> List[CorrectionResult]:
        """ìˆ˜ì • ì ìš©"""
        backup_path = None

        if not self.dry_run and self.corrections:
            backup_path = self._create_backup()

        for action in self.corrections:
            is_valid, validation_msg = self._validate_correction(action)

            if not is_valid:
                result = CorrectionResult(
                    action=action,
                    success=False,
                    error_message=validation_msg,
                    backup_path=backup_path,
                )
                self.results.append(result)
                continue

            success = self._apply_line_correction(action)

            result = CorrectionResult(
                action=action,
                success=success,
                error_message=None if success else "ì ìš© ì‹¤íŒ¨",
                backup_path=backup_path,
            )
            self.results.append(result)

        return self.results

    def save_correction_report(
        self, output_path: str = None
    ) -> None:
        """ìˆ˜ì • ë¦¬í¬íŠ¸ ì €ì¥"""
        if output_path is None:
            output_path = (
                self.project_root
                / ".moai"
                / "reports"
                / f"tag_corrections_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
            )

        Path(output_path).parent.mkdir(parents=True, exist_ok=True)

        report = {
            "timestamp": datetime.now().isoformat(),
            "total_corrections": len(self.corrections),
            "successful": sum(1 for r in self.results if r.success),
            "failed": sum(1 for r in self.results if not r.success),
            "dry_run": self.dry_run,
            "results": [
                {
                    "action": action.action_type,
                    "file": action.file_path,
                    "line": action.line_number,
                    "old_tag": action.old_tag,
                    "new_tag": action.new_tag,
                    "success": result.success,
                    "error": result.error_message,
                }
                for action, result in zip(self.corrections, self.results)
            ],
        }

        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)

        print(f"ğŸ“„ ë¦¬í¬íŠ¸ ì €ì¥: {output_path}")


# ============================================================================
# í†µí•© ê´€ë¦¬ì (Unified Manager)
# ============================================================================

class TagDedupManager:
    """TAG ì¤‘ë³µ ê´€ë¦¬ì (í†µí•©)"""

    def __init__(self, config_path: str = None):
        self.config_path = config_path
        self.detector = TagDetectionEngine(config_path)
        self.corrector = None

    def scan_only(self) -> Dict:
        """ìŠ¤ìº” ì „ìš© ëª¨ë“œ"""
        print("ğŸ” TAG ì¤‘ë³µ ìŠ¤ìº” ì¤‘...")
        self.detector.scan_all_files()
        self.detector.find_duplicates()

        analysis = self.detector.analyze_duplicates()

        if analysis["duplicate_groups"] > 0:
            print(f"\nâš ï¸  ì¤‘ë³µ ê·¸ë£¹ ë°œê²¬: {analysis['duplicate_groups']}")
            print(f"   ì´ ì¤‘ë³µ TAG ìˆ˜: {analysis['total_duplicates']}")
        else:
            print("\nâœ… ì¤‘ë³µ TAGê°€ ì—†ìŠµë‹ˆë‹¤!")

        return analysis

    def dry_run(self) -> Dict:
        """ê²€í†  ëª¨ë“œ"""
        print("ğŸ“‹ TAG ì¤‘ë³µ ê²€í†  ì¤‘ (ë³€ê²½ ì—†ìŒ)...")
        self.detector.scan_all_files()
        self.detector.find_duplicates()

        self.corrector = TagCorrectionEngine(self.config_path, dry_run=True)
        self.corrector.detector = self.detector
        self.corrector.generate_corrections(self.detector.duplicate_groups)

        analysis = self.detector.analyze_duplicates()

        print(f"\nğŸ“Š ìˆ˜ì • ê³„íš:")
        print(f"   ì ìš©ë  ìˆ˜ì •: {len(self.corrector.corrections)}")

        for action in self.corrector.corrections[:5]:
            print(
                f"   - {action.old_tag} â†’ {action.new_tag} ({action.file_path}:{action.line_number})"
            )

        if len(self.corrector.corrections) > 5:
            print(f"   ... ì™¸ {len(self.corrector.corrections) - 5}ê°œ")

        return analysis

    def apply(self) -> List[CorrectionResult]:
        """ì ìš© ëª¨ë“œ"""
        print("âœï¸  TAG ì¤‘ë³µ ìˆ˜ì • ì¤‘...")
        self.detector.scan_all_files()
        self.detector.find_duplicates()

        self.corrector = TagCorrectionEngine(self.config_path, dry_run=False)
        self.corrector.detector = self.detector
        self.corrector.generate_corrections(self.detector.duplicate_groups)

        results = self.corrector.apply_corrections()

        successful = sum(1 for r in results if r.success)
        failed = len(results) - successful

        print(f"\nâœ… ìˆ˜ì • ì™„ë£Œ:")
        print(f"   ì„±ê³µ: {successful}")
        print(f"   ì‹¤íŒ¨: {failed}")

        if results and results[0].backup_path:
            print(f"   ë°±ì—…: {results[0].backup_path}")

        self.corrector.save_correction_report()

        return results

    def full_workflow(self) -> Dict:
        """ì „ì²´ ì›Œí¬í”Œë¡œìš°"""
        print("ğŸš€ ì „ì²´ TAG ì¤‘ë³µ ì •ë¦¬ ì‹œì‘...\n")

        analysis = self.scan_only()
        print()

        if analysis["duplicate_groups"] > 0:
            self.dry_run()
            print()
            self.apply()
        else:
            print("\nâœ… ì •ë¦¬í•  ì¤‘ë³µì´ ì—†ìŠµë‹ˆë‹¤!")

        return analysis


# ============================================================================
# CLI
# ============================================================================

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    import argparse

    parser = argparse.ArgumentParser(
        description="MoAI-ADK TAG ì¤‘ë³µ ê´€ë¦¬ ë„êµ¬ (í†µí•©)",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ì‚¬ìš© ì˜ˆì‹œ:
  # ìŠ¤ìº” ì „ìš© (ë³€ê²½ ì—†ìŒ)
  python3 tag_dedup_manager.py --scan-only

  # ê²€í†  ëª¨ë“œ (ìˆ˜ì • ê³„íšë§Œ í‘œì‹œ)
  python3 tag_dedup_manager.py --dry-run

  # ìˆ˜ì • ì ìš©
  python3 tag_dedup_manager.py --apply

  # ì „ì²´ ì›Œí¬í”Œë¡œìš° (ìŠ¤ìº” â†’ ê²€í†  â†’ ì ìš©)
  python3 tag_dedup_manager.py --full

  # ì„¤ì • íŒŒì¼ ì§€ì •
  python3 tag_dedup_manager.py --config .moai/my-config.json --apply
        """,
    )

    parser.add_argument(
        "--config",
        type=str,
        help="ì„¤ì • íŒŒì¼ ê²½ë¡œ",
        default=None,
    )

    # ëª¨ë“œ ì„ íƒ
    mode_group = parser.add_mutually_exclusive_group(required=True)
    mode_group.add_argument(
        "--scan-only",
        action="store_true",
        help="ì¤‘ë³µ ìŠ¤ìº”ë§Œ ìˆ˜í–‰ (ë³€ê²½ ì—†ìŒ)",
    )
    mode_group.add_argument(
        "--dry-run",
        action="store_true",
        help="ìˆ˜ì • ê³„íšì„ ë³´ê³  ë³€ê²½í•˜ì§€ ì•ŠìŒ",
    )
    mode_group.add_argument(
        "--apply",
        action="store_true",
        help="ì¤‘ë³µ TAG ìˆ˜ì • ì ìš©",
    )
    mode_group.add_argument(
        "--full",
        action="store_true",
        help="ì „ì²´ ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ (ìŠ¤ìº” â†’ ê²€í†  â†’ ì ìš©)",
    )

    args = parser.parse_args()

    manager = TagDedupManager(config_path=args.config)

    if args.scan_only:
        manager.scan_only()
    elif args.dry_run:
        manager.dry_run()
    elif args.apply:
        manager.apply()
    elif args.full:
        manager.full_workflow()


if __name__ == "__main__":
    main()
