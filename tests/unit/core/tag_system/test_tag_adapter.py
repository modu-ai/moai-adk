"""
@TEST:SPEC-009-TAG-ADAPTER-001 - TAG JSON API í˜¸í™˜ì„± ì–´ëŒ‘í„° ì‹¤íŒ¨ í…ŒìŠ¤íŠ¸

RED ë‹¨ê³„: SQLite ë°±ì—”ë“œì™€ ê¸°ì¡´ JSON API 100% í˜¸í™˜ì„± ì‹¤íŒ¨ í…ŒìŠ¤íŠ¸
"""

import pytest
import json
import tempfile
from pathlib import Path
from typing import Dict, List, Any
from unittest.mock import Mock, patch, MagicMock

# ì•„ì§ êµ¬í˜„ë˜ì§€ ì•Šì€ ëª¨ë“ˆë“¤ - ì‹¤íŒ¨í•  ì˜ˆì •
from moai_adk.core.tag_system.adapter import (
    TagIndexAdapter,
    ApiCompatibilityError,
    AdapterConfiguration,
)
from moai_adk.core.tag_system.database import TagDatabaseManager


class TestTagIndexAdapter:
    """TAG JSON API í˜¸í™˜ì„± ì–´ëŒ‘í„° í…ŒìŠ¤íŠ¸ ìŠ¤ìœ„íŠ¸"""

    def setup_method(self):
        """ê° í…ŒìŠ¤íŠ¸ ì „ ì´ˆê¸°í™”"""
        self.temp_db = Path(tempfile.mktemp(suffix=".db"))
        self.temp_json = Path(tempfile.mktemp(suffix=".json"))

        # ì–´ëŒ‘í„° ì´ˆê¸°í™” (SQLite ë°±ì—”ë“œ ì‚¬ìš©)
        self.adapter = TagIndexAdapter(
            database_path=self.temp_db, json_fallback_path=self.temp_json
        )

    def teardown_method(self):
        """ê° í…ŒìŠ¤íŠ¸ í›„ ì •ë¦¬"""
        self.adapter.close()
        if self.temp_db.exists():
            self.temp_db.unlink()
        if self.temp_json.exists():
            self.temp_json.unlink()

    def test_should_maintain_exact_json_api_compatibility(self):
        """
        Given: ê¸°ì¡´ TagIndexManagerì˜ JSON API êµ¬ì¡°
        When: TagIndexAdapterë¥¼ í†µí•´ ë™ì¼í•œ ë©”ì„œë“œë¥¼ í˜¸ì¶œí•  ë•Œ
        Then: ì™„ì „íˆ ë™ì¼í•œ JSON êµ¬ì¡°ë¥¼ ë°˜í™˜í•´ì•¼ í•¨
        """
        # GIVEN: ê¸°ì¡´ JSON API í˜¸í™˜ ë°ì´í„° ì¤€ë¹„
        self.adapter.initialize()

        # ê¸°ì¡´ APIì™€ ë™ì¼í•œ ë©”ì„œë“œ ì¡´ì¬ í™•ì¸
        expected_methods = [
            "load_index",
            "save_index",
            "initialize_index",
            "validate_index_schema",
            "process_file_change",
            "start_watching",
            "stop_watching",
        ]

        # WHEN: ì–´ëŒ‘í„° ë©”ì„œë“œ ì¡´ì¬ í™•ì¸
        for method_name in expected_methods:
            assert hasattr(self.adapter, method_name), f"Missing method: {method_name}"

        # THEN: load_index ë°˜í™˜ êµ¬ì¡°ê°€ ê¸°ì¡´ê³¼ ë™ì¼í•´ì•¼ í•¨
        index_data = self.adapter.load_index()

        # ê¸°ì¡´ JSON êµ¬ì¡°ì™€ ì •í™•íˆ ì¼ì¹˜í•´ì•¼ í•¨
        expected_structure_keys = ["metadata", "categories", "chains", "files"]
        for key in expected_structure_keys:
            assert key in index_data, f"Missing key: {key}"

        # metadata êµ¬ì¡° ê²€ì¦
        metadata = index_data["metadata"]
        expected_metadata_keys = ["created_at", "updated_at", "version", "total_tags"]
        for key in expected_metadata_keys:
            assert key in metadata, f"Missing metadata key: {key}"

        # categories êµ¬ì¡° ê²€ì¦ (16-Core TAG ì‹œìŠ¤í…œ)
        categories = index_data["categories"]
        expected_category_groups = ["PRIMARY", "STEERING", "IMPLEMENTATION", "QUALITY"]
        for group in expected_category_groups:
            assert group in categories, f"Missing category group: {group}"

    def test_should_process_file_change_like_original_api(self):
        """
        Given: ê¸°ì¡´ TagIndexManager.process_file_changeì™€ ë™ì¼í•œ ì‹œê·¸ë‹ˆì²˜
        When: íŒŒì¼ ë³€ê²½ì„ ì²˜ë¦¬í•  ë•Œ
        Then: ë™ì¼í•œ ë°©ì‹ìœ¼ë¡œ ì¸ë±ìŠ¤ê°€ ì—…ë°ì´íŠ¸ë˜ì–´ì•¼ í•¨
        """
        # GIVEN: ì–´ëŒ‘í„° ì´ˆê¸°í™” ë° í…ŒìŠ¤íŠ¸ íŒŒì¼
        self.adapter.initialize()
        test_file = Path(tempfile.mktemp(suffix=".md"))
        test_content = """
        # ìš”êµ¬ì‚¬í•­ ë¬¸ì„œ

        @REQ:USER-AUTH-001 ì‚¬ìš©ì ì¸ì¦ ê¸°ëŠ¥
        @DESIGN:JWT-SYSTEM-001 JWT ê¸°ë°˜ ì¸ì¦ ì‹œìŠ¤í…œ
        """
        test_file.write_text(test_content)

        # WHEN: íŒŒì¼ ë³€ê²½ ì²˜ë¦¬ (ê¸°ì¡´ APIì™€ ë™ì¼í•œ ì‹œê·¸ë‹ˆì²˜)
        self.adapter.process_file_change(test_file, "created")

        # THEN: ê¸°ì¡´ JSON í˜•ì‹ê³¼ ë™ì¼í•œ ê²°ê³¼ ìƒì„±
        index_data = self.adapter.load_index()

        # ì´ TAG ìˆ˜ í™•ì¸
        assert index_data["metadata"]["total_tags"] == 2

        # categories êµ¬ì¡°ê°€ ê¸°ì¡´ê³¼ ë™ì¼í•´ì•¼ í•¨
        primary_categories = index_data["categories"]["PRIMARY"]

        # REQ ì¹´í…Œê³ ë¦¬ í™•ì¸
        assert "REQ" in primary_categories
        req_tags = primary_categories["REQ"]
        assert "USER-AUTH-001" in req_tags
        assert req_tags["USER-AUTH-001"]["description"] == "ì‚¬ìš©ì ì¸ì¦ ê¸°ëŠ¥"
        assert req_tags["USER-AUTH-001"]["file"] == str(test_file)

        # DESIGN ì¹´í…Œê³ ë¦¬ í™•ì¸
        assert "DESIGN" in primary_categories
        design_tags = primary_categories["DESIGN"]
        assert "JWT-SYSTEM-001" in design_tags

        # files êµ¬ì¡° í™•ì¸ (ê¸°ì¡´ê³¼ ë™ì¼)
        files = index_data["files"]
        assert str(test_file) in files
        file_tags = files[str(test_file)]
        assert len(file_tags) == 2
        assert file_tags[0]["category"] == "REQ"
        assert file_tags[1]["category"] == "DESIGN"

        # ì •ë¦¬
        test_file.unlink()

    def test_should_support_callback_system_like_original(self):
        """
        Given: ê¸°ì¡´ TagIndexManagerì˜ ì½œë°± ì‹œìŠ¤í…œ
        When: on_file_changed ì½œë°±ì„ ì„¤ì •í•  ë•Œ
        Then: ê¸°ì¡´ê³¼ ë™ì¼í•˜ê²Œ ì´ë²¤íŠ¸ê°€ í˜¸ì¶œë˜ì–´ì•¼ í•¨
        """
        # GIVEN: ì½œë°± í•¨ìˆ˜ ì„¤ì •
        self.adapter.initialize()
        received_events = []

        def callback_handler(event):
            received_events.append(event)

        self.adapter.on_file_changed = callback_handler

        # WHEN: íŒŒì¼ ë³€ê²½ ì´ë²¤íŠ¸ ë°œìƒ
        test_file = Path(tempfile.mktemp(suffix=".md"))
        test_file.write_text("@REQ:CALLBACK-TEST-001 ì½œë°± í…ŒìŠ¤íŠ¸")

        self.adapter.process_file_change(test_file, "created")

        # THEN: ì½œë°±ì´ ê¸°ì¡´ í˜•ì‹ìœ¼ë¡œ í˜¸ì¶œë¨
        assert len(received_events) == 1

        event = received_events[0]
        # ê¸°ì¡´ IndexUpdateEventì™€ ë™ì¼í•œ êµ¬ì¡°
        assert hasattr(event, "event_type")
        assert hasattr(event, "file_path")
        assert hasattr(event, "timestamp")

        assert event.event_type == "created"
        assert event.file_path == test_file

        # ì •ë¦¬
        test_file.unlink()

    def test_should_validate_schema_exactly_like_original(self):
        """
        Given: ê¸°ì¡´ TagIndexManagerì˜ ìŠ¤í‚¤ë§ˆ ê²€ì¦ ë¡œì§
        When: validate_index_schemaë¥¼ í˜¸ì¶œí•  ë•Œ
        Then: ë™ì¼í•œ ìŠ¤í‚¤ë§ˆ ê²€ì¦ ê²°ê³¼ë¥¼ ë°˜í™˜í•´ì•¼ í•¨
        """
        # GIVEN: ì˜¬ë°”ë¥¸ ìŠ¤í‚¤ë§ˆì™€ ì˜ëª»ëœ ìŠ¤í‚¤ë§ˆ
        valid_schema = {
            "metadata": {
                "created_at": "2024-01-01T00:00:00Z",
                "updated_at": "2024-01-01T00:00:00Z",
                "version": "1.0",
                "total_tags": 0,
            },
            "categories": {
                "PRIMARY": {},
                "STEERING": {},
                "IMPLEMENTATION": {},
                "QUALITY": {},
            },
            "chains": [],
            "files": {},
        }

        invalid_schema = {
            "metadata": {
                "version": "1.0"  # í•„ìˆ˜ í•„ë“œ ëˆ„ë½
            },
            "categories": "invalid_type",  # ì˜ëª»ëœ íƒ€ì…
        }

        # WHEN & THEN: ìŠ¤í‚¤ë§ˆ ê²€ì¦ì´ ê¸°ì¡´ê³¼ ë™ì¼í•´ì•¼ í•¨
        assert self.adapter.validate_index_schema(valid_schema) is True
        assert self.adapter.validate_index_schema(invalid_schema) is False

    def test_should_handle_json_fallback_mode(self):
        """
        Given: SQLite ë°ì´í„°ë² ì´ìŠ¤ê°€ ì‚¬ìš© ë¶ˆê°€ëŠ¥í•œ ìƒí™©
        When: JSON fallback ëª¨ë“œë¡œ ë™ì‘í•  ë•Œ
        Then: ê¸°ì¡´ JSON íŒŒì¼ ê¸°ë°˜ ë™ì‘ê³¼ ì™„ì „íˆ ë™ì¼í•´ì•¼ í•¨
        """
        # GIVEN: SQLite ì‚¬ìš© ë¶ˆê°€ëŠ¥ ì‹œë®¬ë ˆì´ì…˜
        with patch.object(self.adapter, "_sqlite_available", False):
            self.adapter.initialize()

            # WHEN: JSON fallback ëª¨ë“œë¡œ ë™ì‘
            test_file = Path(tempfile.mktemp(suffix=".md"))
            test_file.write_text("@REQ:FALLBACK-001 fallback ëª¨ë“œ í…ŒìŠ¤íŠ¸")

            self.adapter.process_file_change(test_file, "created")

            # THEN: JSON íŒŒì¼ì´ ìƒì„±ë˜ê³  ê¸°ì¡´ í˜•ì‹ê³¼ ë™ì¼
            assert self.temp_json.exists()

            with open(self.temp_json) as f:
                json_data = json.load(f)

            # ê¸°ì¡´ JSON êµ¬ì¡°ì™€ ì™„ì „ ë™ì¼
            assert "metadata" in json_data
            assert "categories" in json_data
            assert "chains" in json_data
            assert "files" in json_data

            assert json_data["metadata"]["total_tags"] == 1

            # ì •ë¦¬
            test_file.unlink()

    def test_should_maintain_watching_interface_compatibility(self):
        """
        Given: ê¸°ì¡´ íŒŒì¼ ê°ì‹œ ì¸í„°í˜ì´ìŠ¤
        When: start_watching/stop_watchingì„ í˜¸ì¶œí•  ë•Œ
        Then: ê¸°ì¡´ê³¼ ë™ì¼í•œ ë™ì‘ì„ ìˆ˜í–‰í•´ì•¼ í•¨
        """
        # GIVEN: ì–´ëŒ‘í„° ì´ˆê¸°í™”
        self.adapter.initialize()

        # WHEN: ê°ì‹œ ìƒíƒœ í™•ì¸ (ê¸°ì¡´ APIì™€ ë™ì¼)
        assert hasattr(self.adapter, "is_watching")
        assert self.adapter.is_watching is False

        # ê°ì‹œ ì‹œì‘
        self.adapter.start_watching()
        assert self.adapter.is_watching is True

        # ê°ì‹œ ì¤‘ì§€
        self.adapter.stop_watching()
        assert self.adapter.is_watching is False

    def test_should_preserve_performance_characteristics(self):
        """
        Given: ì„±ëŠ¥ì´ ì¤‘ìš”í•œ ëŒ€ìš©ëŸ‰ TAG ì²˜ë¦¬
        When: SQLite ë°±ì—”ë“œë¥¼ í†µí•´ ì²˜ë¦¬í•  ë•Œ
        Then: ê¸°ì¡´ JSON ë°©ì‹ë³´ë‹¤ ë¹ ë¥´ë©´ì„œë„ API í˜¸í™˜ì„± ìœ ì§€í•´ì•¼ í•¨
        """
        import time

        # GIVEN: ëŒ€ìš©ëŸ‰ TAG ë°ì´í„° ì¤€ë¹„
        self.adapter.initialize()

        # 1000ê°œ TAGê°€ í¬í•¨ëœ íŒŒì¼ ìƒì„±
        large_content = []
        for i in range(1000):
            category = ["REQ", "DESIGN", "TASK", "TEST"][i % 4]
            large_content.append(f"@{category}:PERF-TEST-{i:04d} ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ TAG {i}")

        test_file = Path(tempfile.mktemp(suffix=".md"))
        test_file.write_text("\n".join(large_content))

        # WHEN: ëŒ€ìš©ëŸ‰ íŒŒì¼ ì²˜ë¦¬ ì„±ëŠ¥ ì¸¡ì •
        start_time = time.time()
        self.adapter.process_file_change(test_file, "created")
        processing_time = time.time() - start_time

        # THEN: ì„±ëŠ¥ ìš”êµ¬ì‚¬í•­ ë§Œì¡±
        # JSON ë°©ì‹ ëŒ€ë¹„ 10x ì„±ëŠ¥ ê°œì„  ëª©í‘œ (2ì´ˆ â†’ 0.2ì´ˆ)
        assert processing_time < 0.5, f"ì²˜ë¦¬ ì‹œê°„ {processing_time:.3f}ì´ˆê°€ ëª©í‘œë¥¼ ì´ˆê³¼"

        # API í˜¸í™˜ì„± í™•ì¸ - ì •í™•í•œ ê²°ê³¼ ë°˜í™˜
        index_data = self.adapter.load_index()
        assert index_data["metadata"]["total_tags"] == 1000

        # ê¸°ì¡´ í˜•ì‹ê³¼ ë™ì¼í•œ êµ¬ì¡°
        assert "categories" in index_data
        assert "files" in index_data
        assert str(test_file) in index_data["files"]

        # ì •ë¦¬
        test_file.unlink()

    def test_should_support_migration_between_backends(self):
        """
        Given: ê¸°ì¡´ JSON ë°ì´í„°ì™€ ìƒˆë¡œìš´ SQLite ë°±ì—”ë“œ
        When: ë°±ì—”ë“œ ê°„ ì „í™˜ì´ í•„ìš”í•  ë•Œ
        Then: ë°ì´í„° ì†ì‹¤ ì—†ì´ ì „í™˜ë˜ê³  API í˜¸í™˜ì„± ìœ ì§€í•´ì•¼ í•¨
        """
        # GIVEN: ê¸°ì¡´ JSON í˜•ì‹ ë°ì´í„° ì¤€ë¹„
        json_data = {
            "metadata": {
                "created_at": "2024-01-01T00:00:00Z",
                "updated_at": "2024-01-01T00:00:00Z",
                "version": "1.0",
                "total_tags": 2,
            },
            "categories": {
                "PRIMARY": {
                    "REQ": {
                        "USER-MIGRATION-001": {
                            "description": "ë§ˆì´ê·¸ë ˆì´ì…˜ í…ŒìŠ¤íŠ¸",
                            "file": "/test/migration.md",
                        }
                    },
                    "DESIGN": {
                        "ARCH-MIGRATION-001": {
                            "description": "ì•„í‚¤í…ì²˜ ë§ˆì´ê·¸ë ˆì´ì…˜",
                            "file": "/test/migration.md",
                        }
                    },
                }
            },
            "chains": [],
            "files": {
                "/test/migration.md": [
                    {
                        "category": "REQ",
                        "identifier": "USER-MIGRATION-001",
                        "description": "ë§ˆì´ê·¸ë ˆì´ì…˜ í…ŒìŠ¤íŠ¸",
                    },
                    {
                        "category": "DESIGN",
                        "identifier": "ARCH-MIGRATION-001",
                        "description": "ì•„í‚¤í…ì²˜ ë§ˆì´ê·¸ë ˆì´ì…˜",
                    },
                ]
            },
        }

        with open(self.temp_json, "w", encoding="utf-8") as f:
            json.dump(json_data, f, indent=2, ensure_ascii=False)

        # WHEN: JSONì—ì„œ SQLiteë¡œ ë§ˆì´ê·¸ë ˆì´ì…˜
        self.adapter.migrate_from_json(self.temp_json)

        # THEN: ë°ì´í„° ì†ì‹¤ ì—†ì´ ë§ˆì´ê·¸ë ˆì´ì…˜ ì™„ë£Œ
        migrated_data = self.adapter.load_index()

        # ê¸°ì¡´ ë°ì´í„°ì™€ ì™„ì „íˆ ë™ì¼
        assert migrated_data["metadata"]["total_tags"] == 2
        assert "USER-MIGRATION-001" in migrated_data["categories"]["PRIMARY"]["REQ"]
        assert "ARCH-MIGRATION-001" in migrated_data["categories"]["PRIMARY"]["DESIGN"]

        # ì—­ë°©í–¥ ë§ˆì´ê·¸ë ˆì´ì…˜ í…ŒìŠ¤íŠ¸
        export_json = Path(tempfile.mktemp(suffix=".json"))
        self.adapter.export_to_json(export_json)

        with open(export_json, "r", encoding="utf-8") as f:
            exported_data = json.load(f)

        # ì›ë³¸ ë°ì´í„°ì™€ ë™ì¼í•´ì•¼ í•¨
        assert exported_data["metadata"]["total_tags"] == 2
        assert (
            exported_data["categories"]["PRIMARY"]["REQ"]["USER-MIGRATION-001"][
                "description"
            ]
            == "ë§ˆì´ê·¸ë ˆì´ì…˜ í…ŒìŠ¤íŠ¸"
        )

        # ì •ë¦¬
        export_json.unlink()

    def test_should_handle_concurrent_access_transparently(self):
        """
        Given: ê¸°ì¡´ API ì‚¬ìš© ì½”ë“œì—ì„œ ë™ì‹œ ì ‘ê·¼
        When: ì—¬ëŸ¬ ìŠ¤ë ˆë“œì—ì„œ ì–´ëŒ‘í„°ë¥¼ ì‚¬ìš©í•  ë•Œ
        Then: ê¸°ì¡´ API ë™ì‘ ë°©ì‹ê³¼ ë™ì¼í•˜ê²Œ ë™ì‹œì„± ì²˜ë¦¬í•´ì•¼ í•¨
        """
        import threading
        import queue

        # GIVEN: ë™ì‹œ ì ‘ê·¼ í…ŒìŠ¤íŠ¸ ì¤€ë¹„
        self.adapter.initialize()
        results = queue.Queue()
        errors = queue.Queue()

        def worker_thread(thread_id: int):
            try:
                # ê° ìŠ¤ë ˆë“œì—ì„œ íŒŒì¼ ìƒì„± ë° ì²˜ë¦¬
                for i in range(50):
                    test_file = Path(tempfile.mktemp(suffix=".md"))
                    test_file.write_text(
                        f"@REQ:CONCURRENT-{thread_id:02d}-{i:02d} ë™ì‹œ ì ‘ê·¼ í…ŒìŠ¤íŠ¸"
                    )

                    # ê¸°ì¡´ APIì™€ ë™ì¼í•œ ë°©ì‹ìœ¼ë¡œ í˜¸ì¶œ
                    self.adapter.process_file_change(test_file, "created")

                    results.put((thread_id, i))
                    test_file.unlink()

            except Exception as e:
                errors.put(e)

        # WHEN: 5ê°œ ìŠ¤ë ˆë“œì—ì„œ ë™ì‹œ ì‹¤í–‰
        threads = []
        for thread_id in range(5):
            t = threading.Thread(target=worker_thread, args=(thread_id,))
            threads.append(t)
            t.start()

        for t in threads:
            t.join()

        # THEN: ê¸°ì¡´ APIì²˜ëŸ¼ ì•ˆì „í•œ ë™ì‹œì„± ì²˜ë¦¬
        assert errors.qsize() == 0, f"ë™ì‹œì„± ì˜¤ë¥˜ ë°œìƒ: {list(errors.queue)}"
        assert results.qsize() == 250  # 5 * 50

        # ìµœì¢… ìƒíƒœ í™•ì¸
        final_index = self.adapter.load_index()
        # ëª¨ë“  ìŠ¤ë ˆë“œ ì™„ë£Œ í›„ ì¼ê´€ëœ ìƒíƒœì—¬ì•¼ í•¨
        assert "metadata" in final_index
        assert "categories" in final_index

    def test_should_provide_debugging_and_introspection_like_original(self):
        """
        Given: ê¸°ì¡´ ë””ë²„ê¹… ë° ë‚´ë¶€ ìƒíƒœ ì¡°íšŒ ê¸°ëŠ¥
        When: ì–´ëŒ‘í„° ë‚´ë¶€ ìƒíƒœë¥¼ ì¡°íšŒí•  ë•Œ
        Then: ê¸°ì¡´ê³¼ ë™ì¼í•œ ë””ë²„ê¹… ì¸í„°í˜ì´ìŠ¤ë¥¼ ì œê³µí•´ì•¼ í•¨
        """
        # GIVEN: ì–´ëŒ‘í„° ì´ˆê¸°í™” ë° ë°ì´í„° ì¤€ë¹„
        self.adapter.initialize()

        test_file = Path(tempfile.mktemp(suffix=".md"))
        test_file.write_text("@REQ:DEBUG-001 ë””ë²„ê¹… í…ŒìŠ¤íŠ¸")
        self.adapter.process_file_change(test_file, "created")

        # WHEN: ë‚´ë¶€ ìƒíƒœ ì¡°íšŒ (ê¸°ì¡´ API ë©”ì„œë“œë“¤)
        # í”„ë¡œí¼í‹° ê¸°ë°˜ ìƒíƒœ í™•ì¸
        assert hasattr(self.adapter, "is_watching")

        # ì„¤ì • ì •ë³´ ì¡°íšŒ (ìƒˆë¡œìš´ ë””ë²„ê¹… ê¸°ëŠ¥)
        config_info = self.adapter.get_configuration_info()

        # THEN: ìœ ìš©í•œ ë””ë²„ê¹… ì •ë³´ ì œê³µ
        assert "backend_type" in config_info  # 'sqlite' ë˜ëŠ” 'json'
        assert "database_path" in config_info
        assert "performance_stats" in config_info

        # ì„±ëŠ¥ í†µê³„ í™•ì¸
        perf_stats = config_info["performance_stats"]
        assert "total_tags" in perf_stats
        assert "query_count" in perf_stats
        assert "avg_query_time" in perf_stats

        # ì •ë¦¬
        test_file.unlink()

    def test_should_gracefully_degrade_on_errors(self):
        """
        Given: SQLite ë°±ì—”ë“œì—ì„œ ì˜¤ë¥˜ ë°œìƒ ìƒí™©
        When: ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì‹¤íŒ¨ë‚˜ ì†ìƒì´ ë°œìƒí•  ë•Œ
        Then: ê¸°ì¡´ APIì²˜ëŸ¼ JSON fallbackìœ¼ë¡œ graceful degradation ìˆ˜í–‰í•´ì•¼ í•¨
        """
        # GIVEN: SQLite ì˜¤ë¥˜ ì‹œë®¬ë ˆì´ì…˜
        self.adapter.initialize()

        # WHEN: ë°ì´í„°ë² ì´ìŠ¤ ì†ìƒ ì‹œë®¬ë ˆì´ì…˜
        with patch.object(self.adapter, "_database") as mock_db:
            mock_db.insert_tag.side_effect = Exception("Database connection lost")

            # ì˜¤ë¥˜ ë°œìƒ ì‹œì—ë„ JSON fallbackìœ¼ë¡œ ë™ì‘í•´ì•¼ í•¨
            test_file = Path(tempfile.mktemp(suffix=".md"))
            test_file.write_text("@REQ:ERROR-HANDLING-001 ì˜¤ë¥˜ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸")

            # ì˜ˆì™¸ ë°œìƒí•˜ì§€ ì•Šê³  fallbackìœ¼ë¡œ ì²˜ë¦¬
            self.adapter.process_file_change(test_file, "created")

        # THEN: ê¸°ë³¸ ê¸°ëŠ¥ì€ ê³„ì† ë™ì‘
        # JSON fallbackì´ ì‘ë™í–ˆëŠ”ì§€ í™•ì¸
        assert self.temp_json.exists()

        index_data = self.adapter.load_index()
        assert "metadata" in index_data
        assert index_data["metadata"]["total_tags"] >= 0  # ìµœì†Œí•œ êµ¬ì¡°ëŠ” ìœ ì§€

        # ì •ë¦¬
        test_file.unlink()

    def test_should_search_by_category_method_works(self):
        """
        ğŸŸ¢ GREEN: search_by_category ë©”ì„œë“œê°€ êµ¬í˜„ë˜ì–´ ë™ì‘í•´ì•¼ í•¨

        Given: TagIndexAdapter ì¸ìŠ¤í„´ìŠ¤
        When: search_by_category ë©”ì„œë“œë¥¼ í˜¸ì¶œí•  ë•Œ
        Then: ì •ìƒì ìœ¼ë¡œ ë¹ˆ ê²°ê³¼ ë˜ëŠ” ë°ì´í„°ë¥¼ ë°˜í™˜í•´ì•¼ í•¨
        """
        # GIVEN: ì´ˆê¸°í™”ëœ ì–´ëŒ‘í„°
        self.adapter.initialize()

        # WHEN: ë©”ì„œë“œ í˜¸ì¶œ (ë¹ˆ ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ)
        results = self.adapter.search_by_category("REQ")

        # THEN: ë©”ì„œë“œê°€ ì¡´ì¬í•˜ê³  ë¹ˆ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜
        assert isinstance(results, list)
        assert len(results) == 0  # ë¹ˆ ë°ì´í„°ë² ì´ìŠ¤ì´ë¯€ë¡œ ë¹ˆ ê²°ê³¼

    def test_should_get_traceability_chain_method_works(self):
        """
        ğŸŸ¢ GREEN: get_traceability_chain ë©”ì„œë“œê°€ êµ¬í˜„ë˜ì–´ ë™ì‘í•´ì•¼ í•¨

        Given: TagIndexAdapter ì¸ìŠ¤í„´ìŠ¤
        When: get_traceability_chain ë©”ì„œë“œë¥¼ í˜¸ì¶œí•  ë•Œ
        Then: ì •ìƒì ìœ¼ë¡œ ì²´ì¸ êµ¬ì¡°ë¥¼ ë°˜í™˜í•´ì•¼ í•¨
        """
        # GIVEN: ì´ˆê¸°í™”ëœ ì–´ëŒ‘í„°
        self.adapter.initialize()

        # WHEN: ë©”ì„œë“œ í˜¸ì¶œ (ì¡´ì¬í•˜ì§€ ì•ŠëŠ” TAGì— ëŒ€í•´)
        chain = self.adapter.get_traceability_chain("REQ:NONEXISTENT-001")

        # THEN: ë©”ì„œë“œê°€ ì¡´ì¬í•˜ê³  ê¸°ë³¸ êµ¬ì¡° ë°˜í™˜
        assert isinstance(chain, dict)
        assert "nodes" in chain
        assert "edges" in chain
        assert "direction" in chain
        # ì¡´ì¬í•˜ì§€ ì•ŠëŠ” TAGì´ë¯€ë¡œ ë¹ˆ ë…¸ë“œ ë˜ëŠ” ì—ëŸ¬ ì •ë³´
        assert len(chain["nodes"]) == 0 or "error" in chain

    def test_should_search_by_category_return_correct_format(self):
        """
        ğŸ”´ RED: search_by_categoryê°€ JSON API í˜•ì‹ìœ¼ë¡œ ê²°ê³¼ë¥¼ ë°˜í™˜í•´ì•¼ í•¨ (ì‹¤íŒ¨ ì˜ˆìƒ)

        Given: REQ ì¹´í…Œê³ ë¦¬ì˜ TAGë“¤ì´ ìˆëŠ” SQLite ë°ì´í„°ë² ì´ìŠ¤
        When: search_by_category("REQ")ë¥¼ í˜¸ì¶œí•  ë•Œ
        Then: JSON API í˜•ì‹ì˜ íƒœê·¸ ëª©ë¡ì„ ë°˜í™˜í•´ì•¼ í•¨
        """
        # GIVEN: REQ ì¹´í…Œê³ ë¦¬ TAGë“¤ì„ í¬í•¨í•œ í…ŒìŠ¤íŠ¸ ë°ì´í„°
        test_index = {
            "metadata": {
                "created_at": "2024-01-01T00:00:00",
                "version": "1.0",
                "total_tags": 2,
            },
            "categories": {
                "PRIMARY": {
                    "REQ": {
                        "REQ:USER-AUTH-001": {
                            "description": "ì‚¬ìš©ì ì¸ì¦",
                            "file": "auth.py",
                        },
                        "REQ:USER-PROFILE-001": {
                            "description": "ì‚¬ìš©ì í”„ë¡œí•„",
                            "file": "profile.py",
                        },
                    }
                }
            },
            "chains": [],
            "files": {},
        }

        self.adapter.initialize()
        self.adapter.save_index(test_index)

        # WHEN: search_by_category í˜¸ì¶œ
        results = self.adapter.search_by_category("REQ")

        # THEN: JSON API í˜•ì‹ì˜ ê²°ê³¼ ê²€ì¦
        assert isinstance(results, list)
        assert len(results) == 2
        assert all("category" in tag for tag in results)
        assert all("identifier" in tag for tag in results)
        assert all("description" in tag for tag in results)
        assert all("file_path" in tag for tag in results)

        # êµ¬ì²´ì ì¸ ë°ì´í„° ê²€ì¦
        identifiers = [tag["identifier"] for tag in results]
        assert "REQ:USER-AUTH-001" in identifiers
        assert "REQ:USER-PROFILE-001" in identifiers

    def test_should_get_traceability_chain_build_forward_chain(self):
        """
        ğŸ”´ RED: get_traceability_chainì´ ìˆœë°©í–¥ ì²´ì¸ì„ ë¹Œë“œí•´ì•¼ í•¨ (ì‹¤íŒ¨ ì˜ˆìƒ)

        Given: REQ â†’ DESIGN â†’ TASK â†’ TEST ì²´ì¸ êµ¬ì¡°
        When: get_traceability_chain("REQ:USER-AUTH-001", direction="forward")ë¥¼ í˜¸ì¶œí•  ë•Œ
        Then: ì™„ì „í•œ ìˆœë°©í–¥ ì¶”ì ì„± ì²´ì¸ì„ ë°˜í™˜í•´ì•¼ í•¨
        """
        # GIVEN: ì²´ì¸ êµ¬ì¡°ì˜ í…ŒìŠ¤íŠ¸ ë°ì´í„° (ì•„ì§ ì°¸ì¡° ê´€ê³„ëŠ” êµ¬í˜„ë˜ì§€ ì•ŠìŒ)
        test_index = {
            "metadata": {
                "created_at": "2024-01-01T00:00:00",
                "version": "1.0",
                "total_tags": 4,
            },
            "categories": {
                "PRIMARY": {
                    "REQ": {
                        "REQ:USER-AUTH-001": {
                            "description": "ì‚¬ìš©ì ì¸ì¦",
                            "file": "spec.md",
                        }
                    },
                    "DESIGN": {
                        "DESIGN:JWT-001": {
                            "description": "JWT í† í° ì„¤ê³„",
                            "file": "design.md",
                        }
                    },
                    "TASK": {
                        "TASK:API-001": {"description": "API êµ¬í˜„", "file": "api.py"}
                    },
                    "TEST": {
                        "TEST:UNIT-001": {
                            "description": "ë‹¨ìœ„ í…ŒìŠ¤íŠ¸",
                            "file": "test_api.py",
                        }
                    },
                }
            },
            "chains": [],
            "files": {},
        }

        self.adapter.initialize()
        self.adapter.save_index(test_index)

        # WHEN: get_traceability_chain í˜¸ì¶œ
        chain = self.adapter.get_traceability_chain(
            "REQ:USER-AUTH-001", direction="forward"
        )

        # THEN: ì²´ì¸ êµ¬ì¡° ê²€ì¦
        assert isinstance(chain, dict)
        assert "nodes" in chain
        assert "edges" in chain
        assert "direction" in chain
        assert chain["direction"] == "forward"

        # ì‹œì‘ ë…¸ë“œ ê²€ì¦
        if len(chain["nodes"]) > 0:
            assert chain["nodes"][0]["identifier"] == "REQ:USER-AUTH-001"
            assert chain["nodes"][0]["category"] == "REQ"
