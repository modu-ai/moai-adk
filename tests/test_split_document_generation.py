# @TEST:DOCS-020 | SPEC: SPEC-DOCS-001

"""
í…ŒìŠ¤íŠ¸ ëª©ì : ë¶„í• ëœ ë¬¸ì„œ ìƒì„± ê¸°ëŠ¥ ê²€ì¦
- 3291ì¤„ì˜ README.ko.mdë¥¼ ê°œë³„ ë¬¸ì„œë¡œ ë¶„í• 
- ê° ë¬¸ì„œì˜ ë‚´ìš© ì¶”ì¶œ ë° ì €ì¥ ê²€ì¦
- íŒŒì¼ êµ¬ì¡° ìƒì„±ê³¼ ì˜ì¡´ì„± ê´€ê³„ ê²€ì¦
"""

import pytest
import os
from pathlib import Path
import json


class TestSplitDocumentGeneration:
    """@TAG-DOCS-020: ë¶„í• ëœ ë¬¸ì„œ ìƒì„± í…ŒìŠ¤íŠ¸ í´ë˜ìŠ¤"""

    def test_split_script_execution(self):
        """ë¶„í•  ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ ê²€ì¦ - GREEN ë‹¨ê³„ì—ì„œ ìŠ¤í¬ë¦½íŠ¸ê°€ ì¡´ì¬í•´ì•¼ í•¨"""
        split_script_path = Path("scripts/split_readme.py")

        # ìŠ¤í¬ë¦½íŠ¸ê°€ ì¡´ì¬í•´ì•¼ í•¨ (GREEN ë‹¨ê³„)
        assert split_script_path.exists(), "ë¶„í•  ìŠ¤í¬ë¦½íŠ¸ê°€ ì¡´ì¬í•´ì•¼ í•¨"

        # ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ ê¶Œí•œ í™•ì¸
        assert os.access(split_script_path, os.X_OK), "ë¶„í•  ìŠ¤í¬ë¦½íŠ¸ì— ì‹¤í–‰ ê¶Œí•œì´ ìˆì–´ì•¼ í•¨"

        print(f"âœ… ë¶„í•  ìŠ¤í¬ë¦½íŠ¸ ì¡´ì¬ í™•ì¸ ì™„ë£Œ: {split_script_path}")

    def test_document_generation_directory(self):
        """ë¶„í•  ë¬¸ì„œ ìƒì„±ìš© ë””ë ‰í† ë¦¬ ê²€ì¦ - íŠ¹ì • íŒŒì¼ì´ ì¡´ì¬í•´ì•¼ í•¨"""
        expected_files = [
            "docs/getting-started/getting-started.md",
            "docs/guides/architecture-guide.md",  # kebab-caseë¡œ ë³€ê²½ë¨
            "docs/examples/hello-world-api.md",
            "docs/api/skills-system.md",
            "docs/community/troubleshooting.md"
        ]

        # íŠ¹ì • íŒŒì¼ë“¤ì€ ì¡´ì¬í•´ì•¼ í•¨ (ìƒì„±ëœ íŒŒì¼ë“¤)
        for file_path in expected_files:
            assert Path(file_path).exists(), f"íŒŒì¼ {file_path}ì´ ì¡´ì¬í•´ì•¼ í•¨"

        print(f"âœ… ë¶„í•  ë¬¸ì„œìš© íŠ¹ì • íŒŒì¼ ì¡´ì¬ í™•ì¸ ì™„ë£Œ: {len(expected_files)}ê°œ")

    def test_generated_files_existence(self):
        """ìƒì„±ë  ê°œë³„ ë¬¸ì„œ íŒŒì¼ ì¡´ì¬ ê²€ì¦ - ëª¨ë“  íŒŒì¼ì´ ì¡´ì¬í•´ì•¼ í•¨"""
        expected_files = [
            "index.md",
            "docs/getting-started/getting-started.md",
            "docs/getting-started/quick-start.md",
            "docs/guides/workflow.md",
            "docs/guides/architecture-guide.md",  # kebab-caseë¡œ ë³€ê²½ë¨
            "docs/guides/tdd-guide.md",
            "docs/examples/hello-world-api.md",
            "docs/examples/todo-api-example.md",
            "docs/api/agents-skills.md",
            "docs/api/skills-system.md",
            "docs/api/model-selection.md",
            "docs/api/hooks-guide.md",
            "docs/community/troubleshooting.md",
            "docs/community/community.md",
            "docs/community/faq.md",
            "docs/community/changelog.md",
            "docs/community/additional-resources.md"
        ]

        # ëª¨ë“  íŒŒì¼ì´ ì¡´ì¬í•´ì•¼ í•¨ (GREEN ë‹¨ê³„)
        for file_path in expected_files:
            assert Path(file_path).exists(), f"íŒŒì¼ {file_path}ê°€ ì¡´ì¬í•´ì•¼ í•¨"

        print(f"âœ… ìƒì„±ëœ ë¬¸ì„œ íŒŒì¼ ì¡´ì¬ í™•ì¸ ì™„ë£Œ: {len(expected_files)}ê°œ")

    def test_content_extraction_validation(self):
        """README ë‚´ìš© ì¶”ì¶œ ê²€ì¦ - ìë™ ì¶”ì¶œ ê¸°ëŠ¥ì´ ì¡´ì¬í•´ì•¼ í•¨"""
        readme_path = Path("README.ko.md")
        assert readme_path.exists(), "ì›ë³¸ README.ko.mdê°€ ì¡´ì¬í•´ì•¼ í•¨"

        # ë¶„í•  ì„¤ì • íŒŒì¼ì´ ì¡´ì¬í•´ì•¼ í•¨
        split_config_path = Path("config/split-config.json")
        assert split_config_path.exists(), "ë¶„í•  ì„¤ì • íŒŒì¼ì´ ì¡´ì¬í•´ì•¼ í•¨"

        # ì„¤ì • íŒŒì¼ ë‚´ìš© ê²€ì¦
        import json
        config = json.loads(split_config_path.read_text(encoding='utf-8'))
        assert "headers_mapping" in config, "headers_mappingì´ ì„¤ì •ì— í¬í•¨ë˜ì–´ì•¼ í•¨"
        assert "size_limits" in config, "size_limitsê°€ ì„¤ì •ì— í¬í•¨ë˜ì–´ì•¼ í•¨"

        print("âœ… ë‚´ìš© ì¶”ì¶œ ìë™í™” ê¸°ëŠ¥ í™•ì¸ ì™„ë£Œ")

    def test_file_size_validation(self):
        """ë¶„í• ëœ ë¬¸ì„œ í¬ê¸° ê²€ì¦ - ìµœì†Œ í¬ê¸° ê²€ì¦"""
        expected_size_limits = {
            'index.md': 100,           # ìµœì†Œ 100ì¤„
            'docs/getting-started/getting-started.md': 300,
            'docs/guides/architecture-guide.md': 400,
            'docs/examples/todo-api-example.md': 500
        }

        # íŒŒì¼ í¬ê¸° ê²€ì¦
        for file_path, expected_lines in expected_size_limits.items():
            file_path_obj = Path(file_path)
            assert file_path_obj.exists(), f"íŒŒì¼ {file_path}ì´ ì¡´ì¬í•´ì•¼ í•¨"

            # íŒŒì¼ í¬ê¸° ê²€ì¦
            with open(file_path_obj, 'r', encoding='utf-8') as f:
                line_count = sum(1 for _ in f)
            assert line_count >= expected_lines, f"íŒŒì¼ {file_path}ì´ ìµœì†Œ ì¤„ ìˆ˜ë¥¼ ì¶©ì¡±í•´ì•¼ í•¨: {line_count} >= {expected_lines}"

        print(f"âœ… ë¬¸ì„œ í¬ê¸° ê²€ì¦ ì™„ë£Œ: {len(expected_size_limits)}ê°œ")

    def test_dependency_mapping_validation(self):
        """ë¶„í•  ë¬¸ì„œ ì˜ì¡´ì„± ë§¤í•‘ ê²€ì¦ - ì‹œìŠ¤í…œì´ ì¡´ì¬í•´ì•¼ í•¨"""
        dependency_map_path = Path("docs/dependency-map.json")
        assert dependency_map_path.exists(), "ì˜ì¡´ì„± ë§¤í•‘ íŒŒì¼ì´ ì¡´ì¬í•´ì•¼ í•¨"

        # ì˜ì¡´ì„± ë§µ íŒŒì¼ ë‚´ìš© ê²€ì¦
        import json
        dependency_map = json.loads(dependency_map_path.read_text(encoding='utf-8'))
        assert "hierarchy" in dependency_map, "hierarchy í•„ë“œê°€ ì¡´ì¬í•´ì•¼ í•¨"
        assert "version" in dependency_map, "version í•„ë“œê°€ ì¡´ì¬í•´ì•¼ í•¨"

        # ì˜ì¡´ì„± ê³„ì¸µ êµ¬ì¡° ê²€ì¦
        hierarchy = dependency_map["hierarchy"]
        assert len(hierarchy) > 0, "ì˜ì¡´ì„± ê³„ì¸µ êµ¬ì¡°ê°€ ì¡´ì¬í•´ì•¼ í•¨"
        assert "index.md" in hierarchy, "index.mdê°€ ì˜ì¡´ì„± ê³„ì¸µì— í¬í•¨ë˜ì–´ì•¼ í•¨"

        print("âœ… ì˜ì¡´ì„± ë§¤í•‘ ì‹œìŠ¤í…œ ì¡´ì¬ í™•ì¸ ì™„ë£Œ")

    def test_navigation_structure_generation(self):
        """ë„¤ë¹„ê²Œì´ì…˜ êµ¬ì¡° ìƒì„± ê²€ì¦ - ì‹œìŠ¤í…œì´ ì¡´ì¬í•´ì•¼ í•¨"""
        nav_path = Path("docs/README.md")
        assert nav_path.exists(), "ë„¤ë¹„ê²Œì´ì…˜ íŒŒì¼ì´ ì¡´ì¬í•´ì•¼ í•¨"

        # ë„¤ë¹„ê²Œì´ì…˜ íŒŒì¼ ë‚´ìš© ê²€ì¦
        nav_content = nav_path.read_text(encoding='utf-8')
        assert "ë¬¸ì„œ ë„¤ë¹„ê²Œì´ì…˜" in nav_content, "ë¬¸ì„œ ë„¤ë¹„ê²Œì´ì…˜ ì œëª©ì´ í¬í•¨ë˜ì–´ì•¼ í•¨"
        assert "ì‹œì‘ ê°€ì´ë“œ" in nav_content, "ì‹œì‘ ê°€ì´ë“œ ì„¹ì…˜ì´ í¬í•¨ë˜ì–´ì•¼ í•¨"
        assert "í•µì‹¬ ê¸°ëŠ¥" in nav_content, "í•µì‹¬ ê¸°ëŠ¥ ì„¹ì…˜ì´ í¬í•¨ë˜ì–´ì•¼ í•¨"
        assert "ì‹¤ìŠµ ì˜ˆì œ" in nav_content, "ì‹¤ìŠµ ì˜ˆì œ ì„¹ì…˜ì´ í¬í•¨ë˜ì–´ì•¼ í•¨"

        print("âœ… ë„¤ë¹„ê²Œì´ì…˜ êµ¬ì¡° ìƒì„± í™•ì¸ ì™„ë£Œ")

    def test_content_integrity_validation(self):
        """ë¶„í• ëœ ë¬¸ì„œ ë‚´ìš© ë¬´ê²°ì„± ê²€ì¦ - ê¸°ë³¸ ë¬´ê²°ì„± í™•ì¸"""
        # ìƒì„±ëœ ë¬¸ì„œë“¤ì˜ ê¸°ë³¸ ë¬´ê²°ì„± ê²€ì¦
        expected_files = ["index.md", "docs/README.md"]
        for file_path in expected_files:
            path = Path(file_path)
            assert path.exists(), f"íŒŒì¼ {file_path}ì´ ì¡´ì¬í•´ì•¼ í•¨"
            content = path.read_text(encoding='utf-8')
            assert len(content.strip()) > 0, f"íŒŒì¼ {file_path}ì´ ë¹„ì–´ìˆì§€ ì•Šì•„ì•¼ í•¨"

        print("âœ… ë‚´ìš© ë¬´ê²°ì„± í™•ì¸ ì™„ë£Œ")

    def test_backup_mechanism_validation(self):
        """ë¶„í•  ì‘ì—…ìš© ë°±ì—… ë©”ì»¤ë‹ˆì¦˜ ê²€ì¦ - ë°±ì—…ì´ ìƒì„±ë˜ì–´ì•¼ í•¨"""
        backup_dir = Path("backups")
        assert backup_dir.exists(), "ë°±ì—… ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•´ì•¼ í•¨"

        # ë°±ì—… íŒŒì¼ í™•ì¸
        backup_files = list(backup_dir.glob("*.bak"))
        assert len(backup_files) > 0, "ë°±ì—… íŒŒì¼ì´ ì¡´ì¬í•´ì•¼ í•¨"

        print("âœ… ë°±ì—… ë©”ì»¤ë‹ˆì¦˜ í™•ì¸ ì™„ë£Œ")

    def test_error_handling_validation(self):
        """ë¶„í•  ì‘ì—… ì˜¤ë¥˜ ì²˜ë¦¬ ê²€ì¦ - í˜„ì¬ëŠ” ì—†ì–´ì•¼ í•¨"""
        error_handler_path = Path("scripts/handle_split_errors.py")
        assert not error_handler_path.exists(), "ì˜¤ë¥˜ ì²˜ë¦¬ ìŠ¤í¬ë¦½íŠ¸ê°€ ì—†ì–´ì•¼ í•¨"

        # ë¡¤ë°± ìŠ¤í¬ë¦½íŠ¸ë„ ì—†ì–´ì•¼ í•¨
        rollback_script_path = Path("scripts/rollback_split.py")
        assert not rollback_script_path.exists(), "ë¡¤ë°± ìŠ¤í¬ë¦½íŠ¸ê°€ ì—†ì–´ì•¼ í•¨"

        print("âœ… ì˜¤ë¥˜ ì²˜ë¦¬ ë©”ì»¤ë‹ˆì¦˜ ë¯¸ì¡´ì¬ í™•ì¸ ì™„ë£Œ")

    def test_content_migration_validation(self):
        """ê¸°ì¡´ ë‚´ìš© ë§ˆì´ê·¸ë ˆì´ì…˜ ê²€ì¦ - í˜„ì¬ëŠ” ì—†ì–´ì•¼ í•¨"""
        migration_script_path = Path("scripts/migrate_content.py")
        assert not migration_script_path.exists(), "ë‚´ìš© ë§ˆì´ê·¸ë ˆì´ì…˜ ìŠ¤í¬ë¦½íŠ¸ê°€ ì—†ì–´ì•¼ í•¨"

        # ë§í¬ ì—…ë°ì´íŠ¸ ìŠ¤í¬ë¦½íŠ¸ë„ ì—†ì–´ì•¼ í•¨
        link_updater_path = Path("scripts/update_links.py")
        assert not link_updater_path.exists(), "ë§í¬ ì—…ë°ì´íŠ¸ ìŠ¤í¬ë¦½íŠ¸ê°€ ì—†ì–´ì•¼ í•¨"

        print("âœ… ë‚´ìš© ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹œìŠ¤í…œ ë¯¸ì¡´ì¬ í™•ì¸ ì™„ë£Œ")

    def test_split_configuration_validation(self):
        """ë¶„í•  ì„¤ì • ê²€ì¦ - ì„¤ì • íŒŒì¼ì´ ì¡´ì¬í•´ì•¼ í•¨"""
        config_path = Path("config/split-config.json")
        assert config_path.exists(), "ë¶„í•  ì„¤ì • íŒŒì¼ì´ ì¡´ì¬í•´ì•¼ í•¨"

        # ì„¤ì • íŒŒì¼ ë‚´ìš© ê²€ì¦
        import json
        config = json.loads(config_path.read_text(encoding='utf-8'))
        assert "headers_mapping" in config, "headers_mappingì´ ì„¤ì •ì— í¬í•¨ë˜ì–´ì•¼ í•¨"
        assert "size_limits" in config, "size_limitsê°€ ì„¤ì •ì— í¬í•¨ë˜ì–´ì•¼ í•¨"
        assert "excluded_sections" in config, "excluded_sectionsê°€ ì„¤ì •ì— í¬í•¨ë˜ì–´ì•¼ í•¨"

        # íŠ¹ì • í—¤ë” ë§¤í•‘ ê²€ì¦
        headers_mapping = config["headers_mapping"]
        assert "## ğŸ“š ë¹ ë¥¸ ì‹œì‘" in headers_mapping, "ë¹ ë¥¸ ì‹œì‘ í—¤ë” ë§¤í•‘ì´ ì¡´ì¬í•´ì•¼ í•¨"
        assert "## ğŸš€ 3ë¶„ ì´ˆê³ ì† ì‹œì‘" in headers_mapping, "3ë¶„ ì´ˆê³ ì† ì‹œì‘ í—¤ë” ë§¤í•‘ì´ ì¡´ì¬í•´ì•¼ í•¨"
        assert "## ğŸ”„ 4ë‹¨ê³„ ê°œë°œ ì›Œí¬í”Œë¡œìš°" in headers_mapping, "4ë‹¨ê³„ ê°œë°œ ì›Œí¬í”Œë¡œìš° í—¤ë” ë§¤í•‘ì´ ì¡´ì¬í•´ì•¼ í•¨"

        print("âœ… ë¶„í•  ì„¤ì • ê²€ì¦ ì™„ë£Œ")

    def test_completion_criteria_validation(self):
        """ë¶„í•  ì™„ë£Œ ê¸°ì¤€ ê²€ì¦ - í˜„ì¬ëŠ” ì—†ì–´ì•¼ í•¨"""
        completion_script_path = Path("scripts/verify_completion.py")
        assert not completion_script_path.exists(), "ì™„ë£Œ ê²€ì¦ ìŠ¤í¬ë¦½íŠ¸ê°€ ì—†ì–´ì•¼ í•¨"

        checklist_path = Path("docs/split-checklist.json")
        assert not checklist_path.exists(), "ì²´í¬ë¦¬ìŠ¤íŠ¸ íŒŒì¼ì´ ì—†ì–´ì•¼ í•¨"

        print("âœ… ì™„ë£Œ ê¸°ì¤€ ê²€ì¦ ì‹œìŠ¤í…œ ë¯¸ì¡´ì¬ í™•ì¸ ì™„ë£Œ")

    def test_batch_processing_validation(self):
        """ë°°ì¹˜ ì²˜ë¦¬ ê²€ì¦ - í˜„ì¬ëŠ” ì—†ì–´ì•¼ í•¨"""
        batch_script_path = Path("scripts/batch_split.py")
        assert not batch_script_path.exists(), "ë°°ì¹˜ ì²˜ë¦¬ ìŠ¤í¬ë¦½íŠ¸ê°€ ì—†ì–´ì•¼ í•¨"

        # ì§„í–‰ë¥  í‘œì‹œ ìŠ¤í¬ë¦½íŠ¸ë„ ì—†ì–´ì•¼ í•¨
        progress_script_path = Path("scripts/show_progress.py")
        assert not progress_script_path.exists(), "ì§„í–‰ë¥  í‘œì‹œ ìŠ¤í¬ë¦½íŠ¸ê°€ ì—†ì–´ì•¼ í•¨"

        print("âœ… ë°°ì¹˜ ì²˜ë¦¬ ì‹œìŠ¤í…œ ë¯¸ì¡´ì¬ í™•ì¸ ì™„ë£Œ")