#!/usr/bin/env python3
# @CODE:HOOK-RESEARCH-002 | @SPEC:HOOK-RESEARCH-STRATEGY-001 | @TEST: tests/hooks/test_research_strategy.py
"""ì‹¤ì‹œê°„ ì—°êµ¬ ì „ëµ ì„ íƒ Hook

PreToolUse ë‹¨ê³„ì—ì„œ ì‘ì—… ìœ í˜•ì— ë§ëŠ” ì—°êµ¬ ì „ëµì„ ìë™ìœ¼ë¡œ ì„ íƒí•˜ê³  ìµœì í™”.
ì‘ì—… ì „ ì—°êµ¬ ì»¨í…ìŠ¤íŠ¸ë¥¼ ì„¤ì •í•˜ê³  ìì›ì„ í• ë‹¹.

ê¸°ëŠ¥:
- ì‘ì—… ìœ í˜• ë¶„ì„ ê¸°ë°˜ ì—°êµ¬ ì „ëµ ì„ íƒ
- ìë™ ì—°êµ¬ ì»¨í…ìŠ¤íŠ¸ ì„¤ì •
- ìì› ìµœì í™” ë° ë©”ëª¨ë¦¬ ê´€ë¦¬
- ë³‘ë ¬ ì—°êµ¬ ì²˜ë¦¬ ì¤€ë¹„
- ì—°êµ¬ ì§€ì‹ JIT ë¡œë”©

ì‚¬ìš©ë²•:
    python3 pre_tool__research_strategy.py <tool_name> <tool_args_json>
"""

import os

import json
import sys
import time
from pathlib import Path
from typing import Any, Dict, List, Optional, Tuple

# ëª¨ë“ˆ ê²½ë¡œ ì¶”ê°€
sys.path.insert(0, str(Path(__file__).parent.parent.parent.parent / "src"))

from moai_adk.core.tags.validator import CentralValidationResult, CentralValidator, ValidationConfig
from moai_adk.statusline.version_reader import VersionReader

# Local hook configuration functions
def get_graceful_degradation() -> bool:
    """ìš°ì•„í•œ ì €í•˜ degrade ëª¨ë“œ ì„¤ì • ë°˜í™˜"""
    return os.environ.get("MOAI_GRACEFUL_DEGRADATION", "true").lower() == "true"

def load_hook_timeout() -> int:
    """Hook íƒ€ì„ì•„ì›ƒ ë¡œë“œ (ë°€ë¦¬ì´ˆ ë‹¨ìœ„)"""
    try:
        return int(os.environ.get("MOAI_HOOK_TIMEOUT_MS", "30000"))
    except ValueError:
        return 30000


def load_research_config() -> Dict[str, Any]:
    """ì—°êµ¬ ì„¤ì • ë¡œë“œ

    Returns:
        ì—°êµ¬ ì„¤ì • ë”•ì…”ë„ˆë¦¬
    """
    try:
        config_file = Path(".moai/config.json")
        if config_file.exists():
            with open(config_file, 'r', encoding='utf-8') as f:
                config = json.load(f)
                return config.get("tags", {}).get("research_tags", {})
    except Exception:
        pass

    return {
        "auto_discovery": True,
        "pattern_matching": True,
        "cross_reference": True,
        "knowledge_graph": True,
        "research_categories": ["RESEARCH", "ANALYSIS", "KNOWLEDGE", "INSIGHT"],
        "research_patterns": {
            "RESEARCH": ["@RESEARCH:", "research", "investigate", "analyze"],
            "ANALYSIS": ["@ANALYSIS:", "analysis", "evaluate", "assess"],
            "KNOWLEDGE": ["@KNOWLEDGE:", "knowledge", "learn", "pattern"],
            "INSIGHT": ["@INSIGHT:", "insight", "innovate", "optimize"]
        }
    }


def classify_tool_type(tool_name: str, tool_args: Dict[str, Any]) -> str:
    """ë„êµ¬ ìœ í˜• ë¶„ë¥˜

    Args:
        tool_name: ë„êµ¬ ì´ë¦„
        tool_args: ë„êµ¬ ì¸ì

    Returns:
        ë¶„ë¥˜ëœ ë„êµ¬ ìœ í˜•
    """
    # ì½”ë“œ ì‘ì—… ë„êµ¬
    code_tools = {"Edit", "Write", "MultiEdit", "Read", "Grep", "Glob"}

    # í…ŒìŠ¤íŠ¸ ê´€ë ¨ ë„êµ¬
    test_tools = {"Bash"}

    # ë¬¸ì„œ ì‘ì—… ë„êµ¬
    doc_tools = {"NotebookEdit"}

    # íƒìƒ‰ ë° ë¶„ì„ ë„êµ¬
    explore_tools = {"Task", "Explore", "Plan", "WebFetch", "WebSearch"}

    # í”„ë¡œì íŠ¸ ê´€ë¦¬ ë„êµ¬
    project_tools = {"Bash(git:*)", "Bash(gh:*)"}

    if tool_name in code_tools:
        return "code"
    elif tool_name in test_tools:
        return "test"
    elif tool_name in doc_tools:
        return "documentation"
    elif tool_name in explore_tools:
        return "exploration"
    elif tool_name in project_tools:
        return "project"
    else:
        return "general"


def get_research_strategies_for_tool(tool_type: str) -> Dict[str, Any]:
    """ë„êµ¬ ìœ í˜•ì— ì í•©í•œ ì—°êµ¬ ì „ëµ ì„ íƒ

    Args:
        tool_type: ë„êµ¬ ìœ í˜•

    Returns:
        ì„ íƒëœ ì—°êµ¬ ì „ëµ
    """
    config = load_research_config()

    # ì „ëµ ë§¤í•‘ (ë„êµ¬ ìœ í˜• -> ì í•©í•œ ì „ëµ)
    strategy_mapping = {
        "code": {
            "primary_strategies": [
                "pattern_recognition",
                "systematic_elimination",
                "first_principles"
            ],
            "secondary_strategies": [
                "root_cause_analysis",
                "cross_domain_analysis"
            ],
            "focus_areas": [
                "code_quality",
                "architecture_consistency",
                "performance_optimization"
            ],
            "knowledge_categories": ["KNOWLEDGE", "INSIGHT"]
        },
        "test": {
            "primary_strategies": [
                "probabilistic_thinking",
                "systematic_elimination",
                "resource_optimization"
            ],
            "secondary_strategies": [
                "pattern_recognition",
                "continuous_learning"
            ],
            "focus_areas": [
                "test_coverage",
                "edge_case_coverage",
                "performance_testing"
            ],
            "knowledge_categories": ["ANALYSIS", "RESEARCH"]
        },
        "documentation": {
            "primary_strategies": [
                "pattern_recognition",
                "cross_domain_analysis",
                "first_principles"
            ],
            "secondary_strategies": [
                "knowledge_graph_building",
                "continuous_learning"
            ],
            "focus_areas": [
                "clarity",
                "completeness",
                "consistency"
            ],
            "knowledge_categories": ["KNOWLEDGE", "INSIGHT"]
        },
        "exploration": {
            "primary_strategies": [
                "cross_domain_analysis",
                "pattern_recognition",
                "first_principles"
            ],
            "secondary_strategies": [
                "probabilistic_thinking",
                "continuous_learning"
            ],
            "focus_areas": [
                "comprehensive_analysis",
                "deep_understanding",
                "insight_generation"
            ],
            "knowledge_categories": ["RESEARCH", "ANALYSIS", "KNOWLEDGE", "INSIGHT"]
        },
        "project": {
            "primary_strategies": [
                "resource_optimization",
                "systematic_elimination",
                "probabilistic_thinking"
            ],
            "secondary_strategies": [
                "cross_domain_analysis",
                "continuous_learning"
            ],
            "focus_areas": [
                "efficiency",
                "scalability",
                "maintainability"
            ],
            "knowledge_categories": ["ANALYSIS", "INSIGHT"]
        },
        "general": {
            "primary_strategies": [
                "pattern_recognition",
                "resource_optimization",
                "continuous_learning"
            ],
            "secondary_strategies": [
                "systematic_elimination",
                "probabilistic_thinking"
            ],
            "focus_areas": [
                "general_optimization",
                "best_practice_application"
            ],
            "knowledge_categories": ["RESEARCH", "KNOWLEDGE"]
        }
    }

    return strategy_mapping.get(tool_type, strategy_mapping["general"])


def load_jit_knowledge(tool_type: str, focus_areas: List[str]) -> Dict[str, Any]:
    """Just-In-Time ì§€ì‹ ë¡œë”©

    Args:
        tool_type: ë„êµ¬ ìœ í˜•
        focus_areas: ì´ˆì  ì˜ì—­

    Returns:
        JIT ë¡œë”©ëœ ì§€ì‹
    """
    knowledge_base = {}
    knowledge_dir = Path(".moai/research/knowledge/")

    if not knowledge_dir.exists():
        return knowledge_base

    # ë„êµ¬ ìœ í˜•ê³¼ ì´ˆì  ì˜ì—­ì— ë§ëŠ” ì§€ì‹ íŒŒì¼ ë¡œë“œ
    relevant_files = []

    # ì¼ì¹˜í•˜ëŠ” íŒŒì¼ íŒ¨í„´
    patterns = [
        f"{tool_type}_*.json",
        f"*.json"
    ]

    for pattern in patterns:
        try:
            for file_path in knowledge_dir.glob(pattern):
                if file_path.is_file():
                    relevant_files.append(file_path)
        except Exception:
            continue

    # íŒŒì¼ ë¡œë“œ
    for file_path in relevant_files:
        try:
            import json as json_module
            with open(file_path, 'r', encoding='utf-8') as f:
                knowledge_data = json_module.load(f)

                # ì´ˆì  ì˜ì—­ê³¼ ê´€ë ¨ëœ ì§€ì‹ë§Œ í•„í„°ë§
                if focus_areas:
                    relevant_knowledge = {}
                    for area in focus_areas:
                        if area.lower() in str(file_path).lower() or area.lower() in json.dumps(knowledge_data).lower():
                            relevant_knowledge.update(knowledge_data)
                    knowledge_base[file_path.stem] = relevant_knowledge
                else:
                    knowledge_base[file_path.stem] = knowledge_data

        except Exception:
            continue

    return knowledge_base


def optimize_resources(tool_type: str, strategies: List[str]) -> Dict[str, Any]:
    """ìì› ìµœì í™” ì„¤ì •

    Args:
        tool_type: ë„êµ¬ ìœ í˜•
        strategies: ì„ íƒëœ ì „ëµ

    Returns:
        ìµœì í™”ëœ ìì› ì„¤ì •
    """
    # ë„êµ¬ ìœ í˜•ì— ë”°ë¥¸ ìì› í• ë‹¹
    resource_configs = {
        "code": {
            "memory_limit": "512MB",
            "timeout_seconds": 45,
            "priority": "high",
            "parallel_processing": False,
            "cache_enabled": True
        },
        "test": {
            "memory_limit": "256MB",
            "timeout_seconds": 30,
            "priority": "medium",
            "parallel_processing": True,
            "cache_enabled": True
        },
        "documentation": {
            "memory_limit": "128MB",
            "timeout_seconds": 20,
            "priority": "low",
            "parallel_processing": False,
            "cache_enabled": False
        },
        "exploration": {
            "memory_limit": "1GB",
            "timeout_seconds": 60,
            "priority": "high",
            "parallel_processing": True,
            "cache_enabled": True
        },
        "project": {
            "memory_limit": "256MB",
            "timeout_seconds": 30,
            "priority": "medium",
            "parallel_processing": False,
            "cache_enabled": True
        },
        "general": {
            "memory_limit": "256MB",
            "timeout_seconds": 25,
            "priority": "medium",
            "parallel_processing": False,
            "cache_enabled": True
        }
    }

    config = resource_configs.get(tool_type, resource_configs["general"])

    # ì „ëµ ìˆ˜ì— ë”°ë¼ ì¶”ê°€ ìµœì í™”
    if len(strategies) > 3:
        config["memory_limit"] = f"{int(config['memory_limit'].replace('MB', '')) * 1.5:.0f}MB"
        config["parallel_processing"] = True

    return config


def create_research_context(tool_name: str, tool_args: Dict[str, Any],
                          strategy_config: Dict[str, Any],
                          knowledge_base: Dict[str, Any],
                          resource_config: Dict[str, Any]) -> Dict[str, Any]:
    """ì—°êµ¬ ì»¨í…ìŠ¤íŠ¸ ìƒì„±

    Args:
        tool_name: ë„êµ¬ ì´ë¦„
        tool_args: ë„êµ¬ ì¸ì
        strategy_config: ì „ëµ ì„¤ì •
        knowledge_base: ì§€ì‹ ë² ì´ìŠ¤
        resource_config: ìì› ì„¤ì •

    Returns:
        ì—°êµ¬ ì»¨í…ìŠ¤íŠ¸
    """
    tool_type = classify_tool_type(tool_name, tool_args)

    return {
        "tool_context": {
            "name": tool_name,
            "type": tool_type,
            "args": tool_args
        },
        "research_strategy": strategy_config,
        "knowledge_base": knowledge_base,
        "resource_config": resource_config,
        "session_id": f"research_{int(time.time())}",
        "timestamp": time.strftime("%Y-%m-%d %H:%M:%S"),
        "optimization_applied": True
    }


def format_strategy_message(context: Dict[str, Any]) -> str:
    """ì „ëµ ì„ íƒ ë©”ì‹œì§€ ìƒì„±

    Args:
        context: ì—°êµ¬ ì»¨í…ìŠ¤íŠ¸

    Returns:
        í¬ë§·ëœ ë©”ì‹œì§€
    """
    strategy_names = context["research_strategy"]["primary_strategies"]
    focus_areas = context["research_strategy"]["focus_areas"]
    resource_config = context["resource_config"]

    message = [
        f"ğŸ”¬ ì—°êµ¬ ì „ëµ ì„ íƒ ì™„ë£Œ",
        f"ğŸ“ ë„êµ¬: {context['tool_context']['name']} ({context['tool_context']['type']})",
        f"âš¡ í™œì„±í™”ëœ ì „ëµ: {', '.join(strategy_names)}",
        f"ğŸ¯ ì´ˆì  ì˜ì—­: {', '.join(focus_areas)}",
        f"ğŸ’¾ ìì› ì„¤ì •: {resource_config['memory_limit']}, íƒ€ì„ì•„ì›ƒ: {resource_config['timeout_seconds']}ì´ˆ"
    ]

    if context["knowledge_base"]:
        message.append(f"ğŸ“š JIT ì§€ì‹ ë¡œë”©: {len(context['knowledge_base'])} ê°œ í•­ëª©")

    return "\n".join(message)


def main() -> None:
    """ë©”ì¸ í•¨ìˆ˜"""
    try:
        # ì„¤ì • ë¡œë“œ
        timeout_seconds = load_hook_timeout() / 1000
        graceful_degradation = get_graceful_degradation()

        # ì¸ì íŒŒì‹±
        if len(sys.argv) < 3:
            if os.environ.get("MOAI_SILENT_RESEARCH", "false").lower() != "true":
                print(json.dumps({
                    "research_strategy_selected": False,
                    "error": "Invalid arguments. Usage: python3 pre_tool__research_strategy.py <tool_name> <tool_args_json>"
                }))
            sys.exit(0)

        tool_name = sys.argv[1]
        try:
            tool_args = json.loads(sys.argv[2])
        except json.JSONDecodeError:
            if os.environ.get("MOAI_SILENT_RESEARCH", "false").lower() != "true":
                print(json.dumps({
                    "research_strategy_selected": False,
                    "error": "Invalid tool_args JSON"
                }))
            sys.exit(0)

        # ì‹œì‘ ì‹œê°„ ê¸°ë¡
        start_time = time.time()

        # ë„êµ¬ ìœ í˜• ë¶„ë¥˜
        tool_type = classify_tool_type(tool_name, tool_args)

        # ì—°êµ¬ ì „ëµ ì„ íƒ
        strategy_config = get_research_strategies_for_tool(tool_type)

        # ì´ˆì  ì˜ì—­ ì¶”ì¶œ
        focus_areas = strategy_config.get("focus_areas", [])

        # JIT ì§€ì‹ ë¡œë”©
        knowledge_base = load_jit_knowledge(tool_type, focus_areas)

        # ìì› ìµœì í™”
        resource_config = optimize_resources(tool_type, strategy_config["primary_strategies"])

        # ì—°êµ¬ ì»¨í…ìŠ¤íŠ¸ ìƒì„±
        research_context = create_research_context(
            tool_name, tool_args, strategy_config,
            knowledge_base, resource_config
        )

        # íƒ€ì„ì•„ì›ƒ ì²´í¬
        if time.time() - start_time > timeout_seconds:
            timeout_response = {
                "research_strategy_selected": False,
                "error": "ì—°êµ¬ ì „ëµ ì„ íƒ íƒ€ì„ì•„ì›ƒ",
                "message": "ì—°êµ¬ ì „ëµ ì„ íƒ ì‹¤íŒ¨ - ê¸°ë³¸ ì „ëµìœ¼ë¡œ ì§„í–‰",
                "graceful_degradation": graceful_degradation
            }
            if os.environ.get("MOAI_SILENT_RESEARCH", "false").lower() != "true":
                print(json.dumps(timeout_response, ensure_ascii=False))
            sys.exit(0)

        # ì‹¤í–‰ ì‹œê°„ ê³„ì‚°
        execution_time_ms = (time.time() - start_time) * 1000

        # ìµœì¢… ì‘ë‹µ
        response = {
            **research_context,
            "execution_time_ms": execution_time_ms,
            "research_strategy_selected": True,
            "message": format_strategy_message(research_context)
        }

        # ì„±ëŠ¥ ê²½ê³ 
        timeout_warning_ms = timeout_seconds * 1000 * 0.8
        if execution_time_ms > timeout_warning_ms:
            response["performance_warning"] = f"ì „ëµ ì„ íƒ ì‹œê°„ì´ íƒ€ì„ì•„ì›ƒì˜ 80%ë¥¼ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤ ({execution_time_ms:.0f}ms / {timeout_warning_ms:.0f}ms)"

        if os.environ.get("MOAI_SILENT_RESEARCH", "false").lower() != "true":
            print(json.dumps(response, ensure_ascii=False, indent=2))

    except Exception as e:
        # ì˜ˆì™¸ ì²˜ë¦¬
        error_response = {
            "research_strategy_selected": False,
            "error": f"ì—°êµ¬ ì „ëµ ì„ íƒ ì˜¤ë¥˜: {str(e)}",
            "message": "ì—°êµ¬ ì „ëµ ì„ íƒ ì‹¤íŒ¨ - ê¸°ë³¸ ì „ëµìœ¼ë¡œ ì§„í–‰"
        }

        if graceful_degradation:
            error_response["graceful_degradation"] = True

        if os.environ.get("MOAI_SILENT_RESEARCH", "false").lower() != "true":
            print(json.dumps(error_response, ensure_ascii=False))
        sys.exit(1)


if __name__ == "__main__":
    main()