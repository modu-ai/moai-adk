# SPEC-009 ìˆ˜ë½ ê¸°ì¤€: TAG ì‹œìŠ¤í…œ SQLite ë§ˆì´ê·¸ë ˆì´ì…˜

**@TEST:ACCEPTANCE-CRITERIA-001** â† ìˆ˜ë½ ê¸°ì¤€ ì •ì˜  
**@TEST:PERFORMANCE-VALIDATION-001** â† ì„±ëŠ¥ ê²€ì¦ ì‹œë‚˜ë¦¬ì˜¤  
**@TEST:COMPATIBILITY-VALIDATION-001** â† í˜¸í™˜ì„± ê²€ì¦ ì‹œë‚˜ë¦¬ì˜¤

---

## ì „ì²´ ìˆ˜ë½ ê¸°ì¤€ ê°œìš”

### í•µì‹¬ ì„±ê³µ ì§€í‘œ
1. **ì„±ëŠ¥ í–¥ìƒ**: JSON ëŒ€ë¹„ 10ë°° ë¹ ë¥¸ ê²€ìƒ‰, ì‚½ì…, ì—…ë°ì´íŠ¸
2. **í˜¸í™˜ì„± ìœ ì§€**: ê¸°ì¡´ API 100% ë™ì¼í•œ ê²°ê³¼ ë°˜í™˜
3. **ì•ˆì „í•œ ë§ˆì´ê·¸ë ˆì´ì…˜**: ë°ì´í„° ì†ì‹¤ 0ê±´, ë¡¤ë°± ê°€ëŠ¥
4. **ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±**: í˜„ì¬ ëŒ€ë¹„ 50% ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ê°ì†Œ

### ë°ì´í„° ê·œëª¨
- **í˜„ì¬ ìƒíƒœ**: 441ê°œ TAG, 4,747ì¤„, 136KB JSON íŒŒì¼
- **í…ŒìŠ¤íŠ¸ ê·œëª¨**: 100ê°œ, 1,000ê°œ, 10,000ê°œ TAG ì‹œë‚˜ë¦¬ì˜¤
- **ì„±ëŠ¥ ëª©í‘œ**: 1,000ê°œ TAG ê²€ìƒ‰ ì‹œ < 10ms

---

## ì„±ëŠ¥ ê²€ì¦ ì‹œë‚˜ë¦¬ì˜¤

### @TEST:SEARCH-PERFORMANCE-001 ê²€ìƒ‰ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸

**Given**: 1,000ê°œì˜ TAGê°€ SQLite ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥ë˜ì–´ ìˆê³ 
**When**: íŠ¹ì • TAGë¥¼ ê²€ìƒ‰í•  ë•Œ
**Then**: 
- ê²€ìƒ‰ ì‹œê°„ì´ 10ms ì´ë‚´ì—¬ì•¼ í•¨
- JSON ë°©ì‹ ëŒ€ë¹„ 10ë°° ì´ìƒ ë¹ ë¥¸ ì„±ëŠ¥ì„ ë³´ì—¬ì•¼ í•¨
- ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì´ í˜„ì¬ ëŒ€ë¹„ 50% ì´í•˜ì—¬ì•¼ í•¨

**í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤**:
```python
def test_search_performance():
    # Given: 1,000ê°œ TAG ì¤€ë¹„
    db_manager = TagDatabaseManager(":memory:")
    tags = generate_test_tags(1000)
    db_manager.bulk_insert(tags)
    
    # When: íŠ¹ì • TAG ê²€ìƒ‰
    start_time = time.perf_counter()
    result = db_manager.search_tag("@SPEC:USER-AUTH-001")
    end_time = time.perf_counter()
    
    # Then: ì„±ëŠ¥ ê¸°ì¤€ ê²€ì¦
    search_time = (end_time - start_time) * 1000  # ms
    assert search_time < 10.0, f"Search took {search_time}ms, expected < 10ms"
    assert len(result) > 0, "Search result should not be empty"
    assert result[0]['tag_key'] == "@SPEC:USER-AUTH-001"
```

### @TEST:INSERT-PERFORMANCE-001 ì‚½ì… ì„±ëŠ¥ í…ŒìŠ¤íŠ¸

**Given**: ë¹„ì–´ìˆëŠ” SQLite ë°ì´í„°ë² ì´ìŠ¤ê°€ ì¤€ë¹„ë˜ê³ 
**When**: 100ê°œì˜ ìƒˆë¡œìš´ TAGë¥¼ ì‚½ì…í•  ë•Œ
**Then**: 
- ì „ì²´ ì‚½ì… ì‹œê°„ì´ 500ms ì´ë‚´ì—¬ì•¼ í•¨
- ê°œë³„ TAG ì‚½ì… ì‹œê°„ì´ 5ms ì´ë‚´ì—¬ì•¼ í•¨
- ì¤‘ë³µ TAG ì‚½ì… ì‹œ ì ì ˆí•œ ì˜¤ë¥˜ ì²˜ë¦¬ê°€ ë˜ì–´ì•¼ í•¨

**í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤**:
```python
def test_insert_performance():
    # Given: ë¹ˆ ë°ì´í„°ë² ì´ìŠ¤
    db_manager = TagDatabaseManager(":memory:")
    new_tags = generate_test_tags(100)
    
    # When: 100ê°œ TAG ì‚½ì…
    start_time = time.perf_counter()
    for tag in new_tags:
        db_manager.insert_tag(tag)
    end_time = time.perf_counter()
    
    # Then: ì„±ëŠ¥ ê¸°ì¤€ ê²€ì¦
    total_time = (end_time - start_time) * 1000
    avg_time_per_tag = total_time / 100
    
    assert total_time < 500.0, f"Total insert time {total_time}ms > 500ms"
    assert avg_time_per_tag < 5.0, f"Avg insert time {avg_time_per_tag}ms > 5ms"
    assert db_manager.count_tags() == 100, "All tags should be inserted"
```

### @TEST:MEMORY-USAGE-001 ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í…ŒìŠ¤íŠ¸

**Given**: 10,000ê°œì˜ TAGê°€ ìˆëŠ” í° ë°ì´í„°ì…‹ì´ ì¤€ë¹„ë˜ê³ 
**When**: SQLite ì‹œìŠ¤í…œê³¼ JSON ì‹œìŠ¤í…œì„ ê°ê° ë¡œë”©í•  ë•Œ
**Then**: 
- SQLite ì‹œìŠ¤í…œì˜ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì´ JSON ëŒ€ë¹„ 50% ì´í•˜ì—¬ì•¼ í•¨
- ì§€ì—° ë¡œë”©ìœ¼ë¡œ ì´ˆê¸° ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì´ ìµœì†Œí™”ë˜ì–´ì•¼ í•¨
- ê°€ë¹„ì§€ ì»¬ë ‰ì…˜ í›„ì—ë„ ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ê°€ ì—†ì–´ì•¼ í•¨

**í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤**:
```python
def test_memory_usage():
    # Given: ëŒ€ìš©ëŸ‰ í…ŒìŠ¤íŠ¸ ë°ì´í„°
    large_tags = generate_test_tags(10000)
    
    # When: JSON vs SQLite ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ë¹„êµ
    json_memory = measure_json_memory_usage(large_tags)
    sqlite_memory = measure_sqlite_memory_usage(large_tags)
    
    # Then: ë©”ëª¨ë¦¬ íš¨ìœ¨ì„± ê²€ì¦
    memory_reduction = (json_memory - sqlite_memory) / json_memory
    assert memory_reduction >= 0.5, f"Memory reduction {memory_reduction:.1%} < 50%"
    
    # ê°€ë¹„ì§€ ì»¬ë ‰ì…˜ í›„ ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ í™•ì¸
    gc.collect()
    final_memory = get_current_memory_usage()
    assert final_memory < sqlite_memory * 1.1, "Memory leak detected"
```

---

## í˜¸í™˜ì„± ê²€ì¦ ì‹œë‚˜ë¦¬ì˜¤

### @TEST:API-COMPATIBILITY-001 ê¸°ì¡´ API í˜¸í™˜ì„± í…ŒìŠ¤íŠ¸

**Given**: ê¸°ì¡´ JSON ì‹œìŠ¤í…œê³¼ ìƒˆë¡œìš´ SQLite ì‹œìŠ¤í…œì´ ê°™ì€ ë°ì´í„°ë¡œ ì´ˆê¸°í™”ë˜ê³ 
**When**: ë™ì¼í•œ API í˜¸ì¶œì„ ê°ê° ì‹¤í–‰í•  ë•Œ
**Then**: 
- ë°˜í™˜ ê²°ê³¼ê°€ 100% ë™ì¼í•´ì•¼ í•¨
- JSON êµ¬ì¡°ì™€ í‚¤ ì´ë¦„ì´ ì™„ì „íˆ ì¼ì¹˜í•´ì•¼ í•¨
- íƒ€ì„ìŠ¤íƒ¬í”„ í˜•ì‹ì´ ê¸°ì¡´ê³¼ ë™ì¼í•´ì•¼ í•¨

**í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤**:
```python
def test_api_compatibility():
    # Given: ë™ì¼í•œ ë°ì´í„°ë¡œ ì´ˆê¸°í™”
    json_system = JsonTagSystem("tags.json")
    sqlite_system = TagIndexAdapter("tags.db")
    
    test_data = load_test_tags()
    json_system.load_data(test_data)
    sqlite_system.migrate_from_json(test_data)
    
    # When: ë™ì¼í•œ API í˜¸ì¶œ
    json_result = json_system.get_tags()
    sqlite_result = sqlite_system.get_tags()
    
    # Then: ê²°ê³¼ 100% ì¼ì¹˜
    assert json_result.keys() == sqlite_result.keys()
    assert json_result['version'] == sqlite_result['version']
    assert json_result['statistics'] == sqlite_result['statistics']
    
    # ê°œë³„ TAG ë°ì´í„° ë¹„êµ
    for tag_key in json_result['index']:
        json_refs = json_result['index'][tag_key]
        sqlite_refs = sqlite_result['index'][tag_key]
        assert len(json_refs) == len(sqlite_refs)
        
        for json_ref, sqlite_ref in zip(json_refs, sqlite_refs):
            assert json_ref['file'] == sqlite_ref['file']
            assert json_ref['line'] == sqlite_ref['line']
            assert json_ref['context'] == sqlite_ref['context']
```

### @TEST:EXISTING-TOOLS-001 ê¸°ì¡´ ë„êµ¬ í˜¸í™˜ì„± í…ŒìŠ¤íŠ¸

**Given**: `validate_tags.py` ìŠ¤í¬ë¦½íŠ¸ê°€ SQLite ì‹œìŠ¤í…œê³¼ í†µí•©ë˜ê³ 
**When**: ë™ì¼í•œ TAG ë°ì´í„°ì— ëŒ€í•´ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì‹¤í–‰í•  ë•Œ
**Then**: 
- JSON ë²„ì „ê³¼ ë™ì¼í•œ ì¶œë ¥ í˜•ì‹ì´ì–´ì•¼ í•¨
- ëª¨ë“  ê²€ì¦ ê·œì¹™ì´ ë™ì¼í•˜ê²Œ ì ìš©ë˜ì–´ì•¼ í•¨
- ì˜¤ë¥˜ ë©”ì‹œì§€ì™€ ê²½ê³ ê°€ ì¼ì¹˜í•´ì•¼ í•¨

**í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤**:
```python
def test_validate_tags_compatibility():
    # Given: JSONê³¼ SQLite ë²„ì „ ì¤€ë¹„
    setup_test_environment()
    
    # When: validate_tags.py ì‹¤í–‰
    json_output = run_validate_script("--backend=json")
    sqlite_output = run_validate_script("--backend=sqlite")
    
    # Then: ì¶œë ¥ ê²°ê³¼ ë¹„êµ
    assert json_output['summary'] == sqlite_output['summary']
    assert json_output['errors'] == sqlite_output['errors']
    assert json_output['warnings'] == sqlite_output['warnings']
```

### @TEST:MOAI-SYNC-001 `/moai:3-sync` ëª…ë ¹ì–´ í˜¸í™˜ì„±

**Given**: SQLiteë¡œ ì „í™˜ëœ TAG ì‹œìŠ¤í…œì´ í™œì„±í™”ë˜ê³ 
**When**: `/moai:3-sync` ëª…ë ¹ì–´ë¥¼ ì‹¤í–‰í•  ë•Œ
**Then**: 
- ê¸°ì¡´ê³¼ ë™ì¼í•œ sync-report.mdê°€ ìƒì„±ë˜ì–´ì•¼ í•¨
- TAG í†µê³„ ì •ë³´ê°€ ì •í™•í•´ì•¼ í•¨
- ëª¨ë“  TAG ì°¸ì¡°ê°€ ì˜¬ë°”ë¥´ê²Œ ì¶”ì ë˜ì–´ì•¼ í•¨

**í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤**:
```python
def test_moai_sync_compatibility():
    # Given: SQLite ì‹œìŠ¤í…œ í™œì„±í™”
    migrate_to_sqlite()
    
    # When: sync ëª…ë ¹ ì‹¤í–‰
    result = execute_moai_sync()
    
    # Then: ë³´ê³ ì„œ ë‚´ìš© ê²€ì¦
    report = load_sync_report()
    assert report['total_tags'] == 441
    assert report['total_references'] == 770
    assert 'migration_info' in report
    assert report['performance_improvement'] > 10.0
```

---

## ë§ˆì´ê·¸ë ˆì´ì…˜ ê²€ì¦ ì‹œë‚˜ë¦¬ì˜¤

### @TEST:MIGRATION-INTEGRITY-001 ë°ì´í„° ë¬´ê²°ì„± í…ŒìŠ¤íŠ¸

**Given**: 441ê°œ TAGë¥¼ í¬í•¨í•œ ì‹¤ì œ `tags.json` íŒŒì¼ì´ ìˆê³ 
**When**: JSON â†’ SQLite â†’ JSON ì™„ì „í•œ ë¼ìš´ë“œíŠ¸ë¦½ì„ ìˆ˜í–‰í•  ë•Œ
**Then**: 
- ì›ë³¸ê³¼ ê²°ê³¼ê°€ 100% ë™ì¼í•´ì•¼ í•¨
- TAG ê°œìˆ˜, ì°¸ì¡° ê°œìˆ˜ê°€ ì •í™•í•´ì•¼ í•¨
- ëª¨ë“  ë©”íƒ€ë°ì´í„°ê°€ ë³´ì¡´ë˜ì–´ì•¼ í•¨

**í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤**:
```python
def test_migration_integrity():
    # Given: ì›ë³¸ JSON íŒŒì¼
    original_data = load_json("tags.json")
    original_hash = calculate_data_hash(original_data)
    
    # When: JSON â†’ SQLite â†’ JSON ë¼ìš´ë“œíŠ¸ë¦½
    migration_tool = TagMigrationTool()
    migration_tool.migrate_json_to_sqlite("tags.json", "test.db")
    migration_tool.migrate_sqlite_to_json("test.db", "restored.json")
    
    restored_data = load_json("restored.json")
    restored_hash = calculate_data_hash(restored_data)
    
    # Then: ë°ì´í„° ì™„ì „ì„± ê²€ì¦
    assert original_hash == restored_hash, "Data integrity check failed"
    assert original_data['statistics'] == restored_data['statistics']
    
    # ê°œë³„ TAG ê²€ì¦
    for tag_key in original_data['index']:
        assert tag_key in restored_data['index']
        assert len(original_data['index'][tag_key]) == len(restored_data['index'][tag_key])
```

### @TEST:ATOMIC-MIGRATION-001 ì›ìì  ë§ˆì´ê·¸ë ˆì´ì…˜ í…ŒìŠ¤íŠ¸

**Given**: ë§ˆì´ê·¸ë ˆì´ì…˜ì´ ì¤‘ê°„ì— ì¤‘ë‹¨ë˜ëŠ” ìƒí™©ì„ ì‹œë®¬ë ˆì´ì…˜í•˜ê³ 
**When**: ë¶€ë¶„ì ìœ¼ë¡œ ì™„ë£Œëœ ë§ˆì´ê·¸ë ˆì´ì…˜ ìƒíƒœì—ì„œ
**Then**: 
- ì›ë³¸ ë°ì´í„°ê°€ ì†ìƒë˜ì§€ ì•Šì•„ì•¼ í•¨
- ì¤‘ê°„ ìƒíƒœì˜ SQLite íŒŒì¼ì´ ì˜¬ë°”ë¥´ê²Œ ì •ë¦¬ë˜ì–´ì•¼ í•¨
- ì¬ì‹œì‘ ì‹œ ì²˜ìŒë¶€í„° ë‹¤ì‹œ ë§ˆì´ê·¸ë ˆì´ì…˜ì´ ê°€ëŠ¥í•´ì•¼ í•¨

**í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤**:
```python
def test_atomic_migration():
    # Given: ë§ˆì´ê·¸ë ˆì´ì…˜ ì¤‘ë‹¨ ì‹œë®¬ë ˆì´ì…˜
    original_backup = backup_file("tags.json")
    
    # When: ë§ˆì´ê·¸ë ˆì´ì…˜ ì¤‘ ì˜ˆì™¸ ë°œìƒ
    migration_tool = TagMigrationTool()
    try:
        with simulate_interruption(after_tags=200):
            migration_tool.migrate_json_to_sqlite("tags.json", "test.db")
    except MigrationInterrupted:
        pass
    
    # Then: ì›ìì„± ê²€ì¦
    assert file_unchanged("tags.json", original_backup), "Original file was modified"
    assert not os.path.exists("test.db"), "Partial database file should be cleaned up"
    
    # ì¬ì‹œì‘ ê°€ëŠ¥ì„± ê²€ì¦
    migration_result = migration_tool.migrate_json_to_sqlite("tags.json", "test.db")
    assert migration_result.success, "Migration should succeed on retry"
    assert migration_result.tags_migrated == 441
```

### @TEST:ROLLBACK-FUNCTIONALITY-001 ë¡¤ë°± ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸

**Given**: SQLiteë¡œ ì„±ê³µì ìœ¼ë¡œ ë§ˆì´ê·¸ë ˆì´ì…˜ì´ ì™„ë£Œëœ ìƒíƒœì—ì„œ
**When**: ì‚¬ìš©ìê°€ JSONìœ¼ë¡œ ë¡¤ë°±ì„ ìš”ì²­í•  ë•Œ
**Then**: 
- 10ì´ˆ ì´ë‚´ì— ë¡¤ë°±ì´ ì™„ë£Œë˜ì–´ì•¼ í•¨
- ì›ë³¸ JSONê³¼ 100% ë™ì¼í•œ ë°ì´í„°ê°€ ë³µì›ë˜ì–´ì•¼ í•¨
- ì‹œìŠ¤í…œì´ JSON ëª¨ë“œë¡œ ìë™ ì „í™˜ë˜ì–´ì•¼ í•¨

**í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤**:
```python
def test_rollback_functionality():
    # Given: ë§ˆì´ê·¸ë ˆì´ì…˜ ì™„ë£Œ ìƒíƒœ
    original_json = load_json("tags.json")
    migrate_to_sqlite()
    
    # When: ë¡¤ë°± ì‹¤í–‰
    start_time = time.time()
    rollback_result = execute_rollback("--to-json")
    rollback_time = time.time() - start_time
    
    # Then: ë¡¤ë°± ì„±ëŠ¥ ë° ì •í™•ì„± ê²€ì¦
    assert rollback_time < 10.0, f"Rollback took {rollback_time}s > 10s"
    assert rollback_result.success, "Rollback should succeed"
    
    restored_json = load_json("tags.json")
    assert original_json == restored_json, "Rollback data mismatch"
    
    # ì‹œìŠ¤í…œ ëª¨ë“œ ì „í™˜ í™•ì¸
    current_backend = get_current_backend()
    assert current_backend == "json", "System should switch back to JSON mode"
```

---

## ì˜ˆì™¸ ìƒí™© ì²˜ë¦¬ ì‹œë‚˜ë¦¬ì˜¤

### @TEST:ERROR-HANDLING-001 ë°ì´í„°ë² ì´ìŠ¤ ì ê¸ˆ ìƒí™© í…ŒìŠ¤íŠ¸

**Given**: SQLite ë°ì´í„°ë² ì´ìŠ¤ê°€ ë‹¤ë¥¸ í”„ë¡œì„¸ìŠ¤ì— ì˜í•´ ì ê²¨ìˆê³ 
**When**: TAG ì½ê¸°/ì“°ê¸° ì‘ì—…ì„ ì‹œë„í•  ë•Œ
**Then**: 
- ì ì ˆí•œ ì˜¤ë¥˜ ë©”ì‹œì§€ê°€ í‘œì‹œë˜ì–´ì•¼ í•¨
- 3íšŒ ì¬ì‹œë„ í›„ graceful failure ì²˜ë¦¬
- ì½ê¸° ì „ìš© ëª¨ë“œë¡œ fallback ê°€ëŠ¥í•´ì•¼ í•¨

**í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤**:
```python
def test_database_lock_handling():
    # Given: ë°ì´í„°ë² ì´ìŠ¤ ì ê¸ˆ ìƒí™©
    with database_lock_simulation("test.db"):
        db_manager = TagDatabaseManager("test.db")
        
        # When: ì“°ê¸° ì‘ì—… ì‹œë„
        with pytest.raises(DatabaseLockError) as exc_info:
            db_manager.insert_tag(create_test_tag())
        
        # Then: ì ì ˆí•œ ì˜¤ë¥˜ ì²˜ë¦¬
        assert "database is locked" in str(exc_info.value)
        assert exc_info.value.retry_count == 3
        
        # ì½ê¸° ì „ìš© ëª¨ë“œ fallback í™•ì¸
        readonly_manager = db_manager.get_readonly_mode()
        assert readonly_manager.can_read(), "Should allow read operations"
```

### @TEST:DISK-SPACE-001 ë””ìŠ¤í¬ ê³µê°„ ë¶€ì¡± ìƒí™© í…ŒìŠ¤íŠ¸

**Given**: ë””ìŠ¤í¬ ê³µê°„ì´ ë¶€ì¡±í•œ ìƒí™©ì´ê³ 
**When**: ëŒ€ìš©ëŸ‰ ë§ˆì´ê·¸ë ˆì´ì…˜ì„ ì‹œë„í•  ë•Œ
**Then**: 
- ë§ˆì´ê·¸ë ˆì´ì…˜ì´ ì‹œì‘ë˜ê¸° ì „ì— ê³µê°„ ê²€ì‚¬ë¥¼ í•´ì•¼ í•¨
- ê³µê°„ ë¶€ì¡± ì‹œ ëª…í™•í•œ ì˜¤ë¥˜ ë©”ì‹œì§€ ì œê³µ
- ë¶€ë¶„ì ìœ¼ë¡œ ìƒì„±ëœ íŒŒì¼ì´ ìë™ìœ¼ë¡œ ì •ë¦¬ë˜ì–´ì•¼ í•¨

**í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤**:
```python
def test_disk_space_handling():
    # Given: ë””ìŠ¤í¬ ê³µê°„ ë¶€ì¡± ì‹œë®¬ë ˆì´ì…˜
    with limited_disk_space(available_mb=10):
        migration_tool = TagMigrationTool()
        
        # When: ëŒ€ìš©ëŸ‰ ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹œë„
        with pytest.raises(InsufficientDiskSpaceError) as exc_info:
            migration_tool.migrate_json_to_sqlite("large_tags.json", "test.db")
        
        # Then: ì ì ˆí•œ ì˜¤ë¥˜ ì²˜ë¦¬
        assert "insufficient disk space" in str(exc_info.value)
        assert exc_info.value.required_mb > 10
        assert not os.path.exists("test.db"), "Partial file should be cleaned up"
```

### @TEST:CORRUPTED-DATABASE-001 ì†ìƒëœ ë°ì´í„°ë² ì´ìŠ¤ ë³µêµ¬ í…ŒìŠ¤íŠ¸

**Given**: SQLite ë°ì´í„°ë² ì´ìŠ¤ íŒŒì¼ì´ ì†ìƒëœ ìƒíƒœì—ì„œ
**When**: ì‹œìŠ¤í…œì´ ë°ì´í„°ë² ì´ìŠ¤ì— ì ‘ê·¼ì„ ì‹œë„í•  ë•Œ
**Then**: 
- ì†ìƒ ê°ì§€ê°€ ì¦‰ì‹œ ì´ë£¨ì–´ì ¸ì•¼ í•¨
- ìë™ ë°±ì—…ì—ì„œ ë³µêµ¬ ì‹œë„
- ë³µêµ¬ ë¶ˆê°€ëŠ¥ ì‹œ JSON ëª¨ë“œë¡œ ì•ˆì „í•˜ê²Œ fallback

**í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤**:
```python
def test_corrupted_database_recovery():
    # Given: ì†ìƒëœ ë°ì´í„°ë² ì´ìŠ¤
    create_corrupted_database("corrupted.db")
    
    # When: ë°ì´í„°ë² ì´ìŠ¤ ì ‘ê·¼ ì‹œë„
    db_manager = TagDatabaseManager("corrupted.db")
    
    with pytest.raises(DatabaseCorruptionError) as exc_info:
        db_manager.get_tags()
    
    # Then: ë³µêµ¬ ì‹œë„ í™•ì¸
    assert exc_info.value.corruption_detected, "Should detect corruption"
    assert exc_info.value.backup_attempted, "Should attempt backup recovery"
    
    # Fallback ëª¨ë“œ í™•ì¸
    fallback_system = db_manager.get_fallback_system()
    assert fallback_system.backend == "json", "Should fallback to JSON"
    assert fallback_system.is_operational(), "Fallback should be operational"
```

---

## ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ ì‹œë‚˜ë¦¬ì˜¤

### @TEST:SCALABILITY-001 í™•ì¥ì„± í…ŒìŠ¤íŠ¸

**Given**: 100ê°œ, 1,000ê°œ, 10,000ê°œ TAGë¥¼ ê°€ì§„ ë°ì´í„°ì…‹ì´ ì¤€ë¹„ë˜ê³ 
**When**: ê° ê·œëª¨ì—ì„œ ê²€ìƒ‰ ì„±ëŠ¥ì„ ì¸¡ì •í•  ë•Œ
**Then**: 
- ëª¨ë“  ê·œëª¨ì—ì„œ ì„ í˜• ì„±ëŠ¥ì„ ìœ ì§€í•´ì•¼ í•¨
- 10,000ê°œ TAGì—ì„œë„ 100ms ì´ë‚´ ì‘ë‹µ
- ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì´ ì˜ˆì¸¡ ê°€ëŠ¥í•˜ê²Œ ì¦ê°€í•´ì•¼ í•¨

**í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤**:
```python
def test_scalability():
    test_sizes = [100, 1000, 10000]
    performance_results = {}
    
    for size in test_sizes:
        # Given: ê° í¬ê¸°ë³„ ë°ì´í„°ì…‹
        db_manager = create_test_database(size)
        
        # When: ê²€ìƒ‰ ì„±ëŠ¥ ì¸¡ì •
        search_times = []
        for _ in range(10):  # 10íšŒ ë°˜ë³µ ì¸¡ì •
            start_time = time.perf_counter()
            result = db_manager.search_random_tag()
            end_time = time.perf_counter()
            search_times.append((end_time - start_time) * 1000)
        
        avg_time = sum(search_times) / len(search_times)
        performance_results[size] = avg_time
    
    # Then: í™•ì¥ì„± ê²€ì¦
    assert performance_results[100] < 5.0, "100 tags: should be < 5ms"
    assert performance_results[1000] < 10.0, "1000 tags: should be < 10ms"
    assert performance_results[10000] < 100.0, "10000 tags: should be < 100ms"
    
    # ì„ í˜•ì„± ê²€ì¦ (10ë°° ë°ì´í„°ê°€ 10ë°° ì´ìƒ ëŠë ¤ì§€ì§€ ì•Šì•„ì•¼ í•¨)
    ratio_1k_100 = performance_results[1000] / performance_results[100]
    ratio_10k_1k = performance_results[10000] / performance_results[1000]
    assert ratio_1k_100 < 5.0, "Performance should scale sub-linearly"
    assert ratio_10k_1k < 5.0, "Performance should scale sub-linearly"
```

### @TEST:CONCURRENT-ACCESS-001 ë™ì‹œ ì ‘ê·¼ í…ŒìŠ¤íŠ¸

**Given**: ì—¬ëŸ¬ ìŠ¤ë ˆë“œê°€ ë™ì‹œì— SQLite ë°ì´í„°ë² ì´ìŠ¤ì— ì ‘ê·¼í•˜ê³ 
**When**: ë™ì‹œì— ì½ê¸°/ì“°ê¸° ì‘ì—…ì„ ìˆ˜í–‰í•  ë•Œ
**Then**: 
- ë°ì´í„° ë¬´ê²°ì„±ì´ ë³´ì¥ë˜ì–´ì•¼ í•¨
- ë°ë“œë½ì´ ë°œìƒí•˜ì§€ ì•Šì•„ì•¼ í•¨
- ì„±ëŠ¥ ì €í•˜ê°€ í•©ë¦¬ì ì¸ ìˆ˜ì¤€ ì´ë‚´ì—¬ì•¼ í•¨

**í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤**:
```python
def test_concurrent_access():
    # Given: ê³µìœ  ë°ì´í„°ë² ì´ìŠ¤
    db_path = "concurrent_test.db"
    setup_test_database(db_path, 1000)
    
    # When: ë™ì‹œ ì•¡ì„¸ìŠ¤ ì‹œë®¬ë ˆì´ì…˜
    def worker_thread(thread_id, results):
        db_manager = TagDatabaseManager(db_path)
        start_time = time.time()
        
        for i in range(50):  # ê° ìŠ¤ë ˆë“œê°€ 50ê°œ ì‘ì—… ìˆ˜í–‰
            if i % 2 == 0:
                # ì½ê¸° ì‘ì—…
                result = db_manager.get_random_tag()
                assert result is not None
            else:
                # ì“°ê¸° ì‘ì—…
                tag = create_test_tag(f"THREAD-{thread_id}-{i}")
                db_manager.insert_tag(tag)
        
        end_time = time.time()
        results[thread_id] = end_time - start_time
    
    # 5ê°œ ìŠ¤ë ˆë“œ ë™ì‹œ ì‹¤í–‰
    threads = []
    results = {}
    
    for i in range(5):
        thread = threading.Thread(
            target=worker_thread, 
            args=(i, results)
        )
        threads.append(thread)
        thread.start()
    
    # ëª¨ë“  ìŠ¤ë ˆë“œ ì™„ë£Œ ëŒ€ê¸°
    for thread in threads:
        thread.join()
    
    # Then: ë™ì‹œì„± ê²€ì¦
    assert len(results) == 5, "All threads should complete"
    avg_time = sum(results.values()) / len(results)
    assert avg_time < 10.0, f"Average thread time {avg_time}s too slow"
    
    # ë°ì´í„° ë¬´ê²°ì„± í™•ì¸
    db_manager = TagDatabaseManager(db_path)
    final_count = db_manager.count_tags()
    expected_count = 1000 + (5 * 25)  # ì›ë³¸ + ìƒˆë¡œ ì¶”ê°€ëœ TAG
    assert final_count == expected_count, "Data integrity violation detected"
```

---

## ìµœì¢… ìˆ˜ë½ ì¡°ê±´

### @TEST:FINAL-ACCEPTANCE-001 ì „ì²´ ì‹œìŠ¤í…œ ìˆ˜ë½ í…ŒìŠ¤íŠ¸

**Given**: ì™„ì „íˆ êµ¬í˜„ëœ SQLite ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹œìŠ¤í…œì´ ìˆê³ 
**When**: ì‹¤ì œ production ë°ì´í„°(441ê°œ TAG)ë¡œ ì „ì²´ ì›Œí¬í”Œë¡œìš°ë¥¼ ìˆ˜í–‰í•  ë•Œ
**Then**: ëª¨ë“  ìˆ˜ë½ ê¸°ì¤€ì„ ë§Œì¡±í•´ì•¼ í•¨

**ìµœì¢… ì²´í¬ë¦¬ìŠ¤íŠ¸**:

#### âœ… ì„±ëŠ¥ ìš”êµ¬ì‚¬í•­
- [ ] JSON ëŒ€ë¹„ 10ë°° ë¹ ë¥¸ ê²€ìƒ‰ ì†ë„ ë‹¬ì„±
- [ ] 1,000ê°œ TAG ê²€ìƒ‰ì´ 10ms ì´ë‚´ ì™„ë£Œ
- [ ] TAG ì‚½ì…ì´ 5ms ì´ë‚´ ì™„ë£Œ
- [ ] ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ 50% ê°ì†Œ ë‹¬ì„±

#### âœ… í˜¸í™˜ì„± ìš”êµ¬ì‚¬í•­
- [ ] ê¸°ì¡´ JSON APIì™€ 100% ë™ì¼í•œ ê²°ê³¼ ë°˜í™˜
- [ ] `validate_tags.py` ìŠ¤í¬ë¦½íŠ¸ ì •ìƒ ë™ì‘
- [ ] `/moai:3-sync` ëª…ë ¹ì–´ ì •ìƒ ë™ì‘
- [ ] ëª¨ë“  ê¸°ì¡´ ë„êµ¬ í˜¸í™˜ì„± ìœ ì§€

#### âœ… ì•ˆì •ì„± ìš”êµ¬ì‚¬í•­
- [ ] 441ê°œ TAG ë§ˆì´ê·¸ë ˆì´ì…˜ 100% ì„±ê³µë¥ 
- [ ] ë¼ìš´ë“œíŠ¸ë¦½ ë§ˆì´ê·¸ë ˆì´ì…˜ ë°ì´í„° ì†ì‹¤ 0ê±´
- [ ] ë¡¤ë°± ê¸°ëŠ¥ 10ì´ˆ ì´ë‚´ ì™„ë£Œ
- [ ] ì˜ˆì™¸ ìƒí™© ì ì ˆí•œ ì²˜ë¦¬ ë° ë³µêµ¬

#### âœ… ì‚¬ìš©ì„± ìš”êµ¬ì‚¬í•­
- [ ] ë§ˆì´ê·¸ë ˆì´ì…˜ ì§„í–‰ë¥  ì‹¤ì‹œê°„ í‘œì‹œ
- [ ] ëª…í™•í•œ ì˜¤ë¥˜ ë©”ì‹œì§€ ë° í•´ê²° ë°©ì•ˆ ì œê³µ
- [ ] ì‚¬ìš©ì ë¬¸ì„œ ì™„ì„±ë„ 90% ì´ìƒ
- [ ] ìƒˆë¡œìš´ ì‚¬ìš©ìë„ ë¬¸ì„œë§Œìœ¼ë¡œ ë§ˆì´ê·¸ë ˆì´ì…˜ ì„±ê³µ

**ìµœì¢… ê²€ì¦ ì‹œë‚˜ë¦¬ì˜¤**:
```python
def test_final_system_acceptance():
    # ì „ì²´ ì›Œí¬í”Œë¡œìš° í…ŒìŠ¤íŠ¸
    original_system = JsonTagSystem("tags.json")
    
    # 1. ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤í–‰
    migration_tool = TagMigrationTool()
    migration_result = migration_tool.migrate_json_to_sqlite(
        "tags.json", "production.db"
    )
    assert migration_result.success
    assert migration_result.tags_migrated == 441
    
    # 2. ì„±ëŠ¥ ê²€ì¦
    sqlite_system = TagIndexAdapter("production.db")
    performance = measure_performance_improvement(original_system, sqlite_system)
    assert performance.search_speedup >= 10.0
    assert performance.memory_reduction >= 0.5
    
    # 3. í˜¸í™˜ì„± ê²€ì¦
    compatibility = verify_api_compatibility(original_system, sqlite_system)
    assert compatibility.match_percentage == 100.0
    
    # 4. ì•ˆì •ì„± ê²€ì¦
    rollback_result = migration_tool.migrate_sqlite_to_json(
        "production.db", "restored.json"
    )
    assert rollback_result.success
    assert files_identical("tags.json", "restored.json")
    
    print("ğŸ‰ SPEC-009 SQLite ë§ˆì´ê·¸ë ˆì´ì…˜ ëª¨ë“  ìˆ˜ë½ ê¸°ì¤€ í†µê³¼!")
```

---

**ìˆ˜ë½ ê¸°ì¤€ ìš”ì•½**: ì„±ëŠ¥ 10ë°° í–¥ìƒ, í˜¸í™˜ì„± 100% ìœ ì§€, ì•ˆì „í•œ ë§ˆì´ê·¸ë ˆì´ì…˜, ì™„ì „í•œ ë¡¤ë°± ê¸°ëŠ¥ì„ ëª¨ë‘ ë§Œì¡±í•˜ëŠ” TAG ì‹œìŠ¤í…œ SQLite ë§ˆì´ê·¸ë ˆì´ì…˜ì´ ì„±ê³µì ìœ¼ë¡œ êµ¬í˜„ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.